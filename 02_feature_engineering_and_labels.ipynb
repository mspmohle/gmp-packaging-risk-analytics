{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8bd1ef-8045-4ea4-91ae-cd0db376b0de",
   "metadata": {},
   "source": [
    "# 02 – Feature Engineering & Risk Labels\n",
    "\n",
    "This notebook consumes the synthetic IIoT event stream and master data generated in `01_synthetic_iot_data_generator.ipynb` and turns it into model-ready features and labels.\n",
    "\n",
    "**Goals**\n",
    "\n",
    "- Join **event logs** with **asset** and **site** metadata.\n",
    "- Engineer time-based features at an `asset_id × local_date` grain (counts, durations, severities).\n",
    "- Create **risk labels**, for example:\n",
    "  - *next-day failure* (binary)\n",
    "  - *high-risk operating window* based on recent anomalies.\n",
    "- Produce tidy feature tables saved under `data/interim/` and `data/results/` for:\n",
    "  - downstream model notebooks (e.g., classification, survival),\n",
    "  - and dashboard backends (FastAPI + DuckDB).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbf58a9-39b1-4949-a2ba-241ff0f27d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /home/parallels/projects/gmp-packaging-risk-analytics\n",
      "OUT_DIR: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z\n",
      "{\n",
      "  \"run_ts_utc\": \"20251212T181645Z\",\n",
      "  \"project_root\": \"/home/parallels/projects/gmp-packaging-risk-analytics\",\n",
      "  \"python\": \"3.11.14 | packaged by conda-forge | (main, Oct 22 2025, 22:39:18) [GCC 14.3.0]\",\n",
      "  \"pandas\": \"2.3.3\",\n",
      "  \"numpy\": \"2.3.5\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 1 — Setup: imports, RNG seed, project paths, and run metadata\n",
    "#============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn (feature engineering + reproducible preprocessing)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# optional: artifact persistence\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# Resolve project root robustly\n",
    "# -----------------------------\n",
    "# Strategy:\n",
    "# 1) Prefer current working directory if it looks like the repo root\n",
    "# 2) Otherwise, walk upward looking for common repo markers\n",
    "cwd = Path.cwd()\n",
    "\n",
    "REPO_MARKERS = [\"pyproject.toml\", \"environment.yml\", \".git\", \"README.md\"]\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(10):\n",
    "        if any((cur / m).exists() for m in REPO_MARKERS):\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(cwd)\n",
    "\n",
    "# -----------------------------\n",
    "# Standard directories\n",
    "# -----------------------------\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "INTERIM_DIR = DATA_DIR / \"interim\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "RESULTS_DIR = DATA_DIR / \"results\"\n",
    "\n",
    "RUN_TS = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "OUT_DIR = PROCESSED_DIR / \"feature_engineering\" / RUN_TS\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Basic environment diagnostics (lightweight, helpful for reproducibility)\n",
    "# -----------------------------\n",
    "env_info = {\n",
    "    \"run_ts_utc\": RUN_TS,\n",
    "    \"project_root\": str(PROJECT_ROOT),\n",
    "    \"python\": sys.version.replace(\"\\n\", \" \"),\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"numpy\": np.__version__,\n",
    "}\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "print(json.dumps(env_info, indent=2))\n",
    "\n",
    "# Persist run metadata for later audit/debug\n",
    "with open(OUT_DIR / \"run_metadata.json\", \"w\") as f:\n",
    "    json.dump(env_info, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adf2c2-f5bd-491d-996a-a827ff41f1dd",
   "metadata": {},
   "source": [
    "### What Cell 1 Just Did\n",
    "\n",
    "This cell initialized the notebook’s execution environment and created a reproducible “run context” for everything that follows. It imported the core packages used throughout the workflow (NumPy and pandas for data handling; scikit-learn components for preprocessing and feature engineering; and `joblib` for saving fitted pipelines). It set a fixed random seed to ensure consistent splits and transformations across reruns. Next, it robustly detected the repository root (`/home/parallels/projects/gmp-packaging-risk-analytics`) and defined standard project folders under `data/` plus a timestamped output directory for this run. Finally, it printed a compact environment summary (Python 3.11.14, pandas 2.3.3, NumPy 2.3.5) and saved the same metadata to `run_metadata.json` inside the run output directory so results are auditable and repeatable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f38538-8d00-489c-a301-2b0d1866a369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR exists: True -> /home/parallels/projects/gmp-packaging-risk-analytics/data/raw\n",
      "INTERIM_DIR exists: True -> /home/parallels/projects/gmp-packaging-risk-analytics/data/interim\n",
      "PROCESSED_DIR exists: True -> /home/parallels/projects/gmp-packaging-risk-analytics/data/processed\n",
      "\n",
      "Top files in data/raw:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>bytes</th>\n",
       "      <th>modified_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/raw/iot_events.parquet</td>\n",
       "      <td>11644913</td>\n",
       "      <td>2025-12-11 00:05:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/raw/assets_master.csv</td>\n",
       "      <td>6521</td>\n",
       "      <td>2025-12-11 00:05:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/raw/sites_master.csv</td>\n",
       "      <td>208</td>\n",
       "      <td>2025-12-11 00:05:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          path     bytes         modified_utc\n",
       "1  data/raw/iot_events.parquet  11644913  2025-12-11 00:05:29\n",
       "0   data/raw/assets_master.csv      6521  2025-12-11 00:05:29\n",
       "2    data/raw/sites_master.csv       208  2025-12-11 00:05:29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top files in data/interim:\n",
      "  (no files found)\n",
      "\n",
      "Top files in data/processed:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>bytes</th>\n",
       "      <th>modified_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/processed/feature_engineering/20251212T18...</td>\n",
       "      <td>248</td>\n",
       "      <td>2025-12-12 18:16:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  bytes  \\\n",
       "0  data/processed/feature_engineering/20251212T18...    248   \n",
       "\n",
       "          modified_utc  \n",
       "0  2025-12-12 18:16:45  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 CSV/Parquet candidate(s) across data/ folders.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>bytes</th>\n",
       "      <th>modified_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/raw/iot_events.parquet</td>\n",
       "      <td>11644913</td>\n",
       "      <td>2025-12-11 00:05:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/raw/assets_master.csv</td>\n",
       "      <td>6521</td>\n",
       "      <td>2025-12-11 00:05:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/raw/sites_master.csv</td>\n",
       "      <td>208</td>\n",
       "      <td>2025-12-11 00:05:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          path     bytes         modified_utc\n",
       "1  data/raw/iot_events.parquet  11644913  2025-12-11 00:05:29\n",
       "0   data/raw/assets_master.csv      6521  2025-12-11 00:05:29\n",
       "2    data/raw/sites_master.csv       208  2025-12-11 00:05:29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Auto-selecting newest candidate file:\n",
      " -> /home/parallels/projects/gmp-packaging-risk-analytics/data/raw/assets_master.csv\n",
      "Shape: (120, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>vendor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id site_id line_id             asset_type  is_legacy   connectivity  \\\n",
       "0    A0001      S1   S1-L2         blister_packer      False     mqtt_opcua   \n",
       "1    A0002      S2   S2-L5            print_apply       True  legacy_serial   \n",
       "2    A0003      S4   S4-L2         blister_packer       True  legacy_serial   \n",
       "3    A0004      S1   S1-L2             sterilizer       True  legacy_serial   \n",
       "4    A0005      S4   S4-L2  environmental_monitor       True  legacy_serial   \n",
       "\n",
       "    vendor  \n",
       "0  VendorB  \n",
       "1  VendorA  \n",
       "2  VendorB  \n",
       "3  VendorD  \n",
       "4  VendorA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 2 — Data discovery (robust): inventory data folders and load the newest CSV/Parquet\n",
    "#   Fix: handle empty folders gracefully (avoid sorting on missing columns)\n",
    "#============================================================\n",
    "\n",
    "def safe_tree(dir_path: Path, max_items: int = 500) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return an inventory of files under dir_path (recursive), including size + mtime.\n",
    "    If the folder is empty, return an empty DF with the expected columns.\n",
    "    \"\"\"\n",
    "    cols = [\"path\", \"bytes\", \"modified_utc\"]\n",
    "    if not dir_path.exists():\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    rows = []\n",
    "    for i, p in enumerate(dir_path.rglob(\"*\")):\n",
    "        if i >= max_items:\n",
    "            break\n",
    "        if p.is_file():\n",
    "            st = p.stat()\n",
    "            rows.append({\n",
    "                \"path\": str(p.relative_to(PROJECT_ROOT)),\n",
    "                \"bytes\": int(st.st_size),\n",
    "                \"modified_utc\": datetime.fromtimestamp(st.st_mtime, tz=timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            })\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    return pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "def show_top(inv: pd.DataFrame, title: str, n: int = 20) -> None:\n",
    "    print(f\"\\nTop files in {title}:\")\n",
    "    if inv.empty:\n",
    "        print(\"  (no files found)\")\n",
    "        return\n",
    "    display(inv.sort_values([\"modified_utc\", \"bytes\"], ascending=[False, False]).head(n))\n",
    "\n",
    "# Inventory the expected data dirs so we can see what's actually present\n",
    "inv_raw = safe_tree(RAW_DIR)\n",
    "inv_interim = safe_tree(INTERIM_DIR)\n",
    "inv_processed = safe_tree(PROCESSED_DIR)\n",
    "\n",
    "print(\"RAW_DIR exists:\", RAW_DIR.exists(), \"->\", RAW_DIR)\n",
    "print(\"INTERIM_DIR exists:\", INTERIM_DIR.exists(), \"->\", INTERIM_DIR)\n",
    "print(\"PROCESSED_DIR exists:\", PROCESSED_DIR.exists(), \"->\", PROCESSED_DIR)\n",
    "\n",
    "show_top(inv_raw, \"data/raw\")\n",
    "show_top(inv_interim, \"data/interim\")\n",
    "show_top(inv_processed, \"data/processed\")\n",
    "\n",
    "# Collect all candidate CSV/Parquet files we could load\n",
    "all_inv = pd.concat([inv_raw, inv_interim, inv_processed], ignore_index=True)\n",
    "candidates = all_inv[all_inv[\"path\"].str.lower().str.endswith((\".csv\", \".parquet\"))].copy()\n",
    "\n",
    "print(f\"\\nFound {len(candidates)} CSV/Parquet candidate(s) across data/ folders.\")\n",
    "if not candidates.empty:\n",
    "    display(candidates.sort_values([\"modified_utc\", \"bytes\"], ascending=[False, False]).head(30))\n",
    "\n",
    "# Choose the newest (mtime) as default input\n",
    "if candidates.empty:\n",
    "    raise FileNotFoundError(\n",
    "        \"No CSV/Parquet files found under data/raw, data/interim, or data/processed.\\n\"\n",
    "        \"Add your base dataset to one of those folders (CSV or Parquet), then rerun Cell 2.\"\n",
    "    )\n",
    "\n",
    "latest_rel = candidates.sort_values(\"modified_utc\", ascending=False).iloc[0][\"path\"]\n",
    "latest_path = PROJECT_ROOT / latest_rel\n",
    "\n",
    "print(\"\\nAuto-selecting newest candidate file:\")\n",
    "print(\" ->\", latest_path)\n",
    "\n",
    "# Load it\n",
    "if latest_path.suffix.lower() == \".csv\":\n",
    "    base_df = pd.read_csv(latest_path)\n",
    "elif latest_path.suffix.lower() == \".parquet\":\n",
    "    base_df = pd.read_parquet(latest_path)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported file type: {latest_path.suffix}\")\n",
    "\n",
    "print(\"Shape:\", base_df.shape)\n",
    "display(base_df.head(5))\n",
    "\n",
    "# Persist for audit\n",
    "with open(OUT_DIR / \"input_base_dataset_path.txt\", \"w\") as f:\n",
    "    f.write(str(latest_path) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e96730-b68d-4ceb-960d-e9bb54daf235",
   "metadata": {},
   "source": [
    "### What Cell 2 Just Did\n",
    "\n",
    "This cell discovered which datasets are actually available in this project and loaded a sensible default input without relying on hard-coded filenames. It recursively inventoried `data/raw/`, `data/interim/`, and `data/processed/`, collecting each file’s relative path, size, and last-modified timestamp. It also handled empty folders safely (so we don’t crash when there are no files to sort). After showing the most recent files in each folder, it filtered the inventory down to CSV and Parquet files (formats pandas can load directly). It then auto-selected the newest candidate file as the base dataset for feature engineering and loaded it into `base_df`, printing its shape and a small preview for validation. Finally, it saved the resolved input dataset path to `input_base_dataset_path.txt` inside the run output directory to keep this run reproducible and auditable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2549384e-fce7-4969-aa79-155d878a0c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No obvious timestamp column found. Proceeding without time-derived features.\n",
      "Joined assets_master.csv on asset_id. Added 6 column(s).\n",
      "Joined sites_master.csv on site_id. Added 2 column(s).\n",
      "Shape after standardization/enrichment: (120, 15)\n",
      "asset_id nulls: 0\n",
      "site_id nulls: 0\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/events_standardized_enriched.parquet\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 3 — Standardize schema, parse timestamps, and enrich with master data (assets/sites)\n",
    "#============================================================\n",
    "\n",
    "df = base_df.copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: find a column by a list of candidate names (case-insensitive)\n",
    "# -----------------------------\n",
    "def find_col(cols: list[str], candidates: list[str]) -> str | None:\n",
    "    cols_norm = {c.lower().strip(): c for c in cols}\n",
    "    for cand in candidates:\n",
    "        key = cand.lower().strip()\n",
    "        if key in cols_norm:\n",
    "            return cols_norm[key]\n",
    "    return None\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Parse an event timestamp (best-effort)\n",
    "# -----------------------------\n",
    "ts_candidates = [\n",
    "    \"event_ts\", \"event_time\", \"timestamp\", \"ts\", \"time\", \"datetime\",\n",
    "    \"created_at\", \"ingest_time\", \"received_at\"\n",
    "]\n",
    "ts_col = find_col(df.columns.tolist(), ts_candidates)\n",
    "\n",
    "if ts_col is not None:\n",
    "    df = df.rename(columns={ts_col: \"event_ts\"})\n",
    "    df[\"event_ts\"] = pd.to_datetime(df[\"event_ts\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "    # Time-derived features (safe even if some timestamps are NaT)\n",
    "    df[\"event_hour\"] = df[\"event_ts\"].dt.hour\n",
    "    df[\"event_dow\"] = df[\"event_ts\"].dt.dayofweek  # 0=Mon\n",
    "    df[\"event_month\"] = df[\"event_ts\"].dt.month\n",
    "    df[\"event_is_weekend\"] = df[\"event_dow\"].isin([5, 6]).astype(\"int8\")\n",
    "else:\n",
    "    print(\"No obvious timestamp column found. Proceeding without time-derived features.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Normalize common identifier columns (best-effort)\n",
    "# -----------------------------\n",
    "# These do not force a rename unless we find a match.\n",
    "asset_id_col = find_col(df.columns.tolist(), [\"asset_id\", \"assetid\", \"equipment_id\", \"device_id\", \"asset\"])\n",
    "site_id_col  = find_col(df.columns.tolist(), [\"site_id\", \"siteid\", \"location_id\", \"plant_id\", \"site\"])\n",
    "\n",
    "if asset_id_col is not None and asset_id_col != \"asset_id\":\n",
    "    df = df.rename(columns={asset_id_col: \"asset_id\"})\n",
    "if site_id_col is not None and site_id_col != \"site_id\":\n",
    "    df = df.rename(columns={site_id_col: \"site_id\"})\n",
    "\n",
    "# Standardize ID dtypes to string to reduce join mismatches\n",
    "for c in [\"asset_id\", \"site_id\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Enrich with master data if available\n",
    "# -----------------------------\n",
    "assets_path = RAW_DIR / \"assets_master.csv\"\n",
    "sites_path  = RAW_DIR / \"sites_master.csv\"\n",
    "\n",
    "if assets_path.exists() and \"asset_id\" in df.columns:\n",
    "    assets_master = pd.read_csv(assets_path)\n",
    "\n",
    "    # Detect asset id column in master\n",
    "    am_asset_col = find_col(assets_master.columns.tolist(), [\"asset_id\", \"assetid\", \"asset\", \"equipment_id\", \"device_id\"])\n",
    "    if am_asset_col is not None and am_asset_col != \"asset_id\":\n",
    "        assets_master = assets_master.rename(columns={am_asset_col: \"asset_id\"})\n",
    "    if \"asset_id\" in assets_master.columns:\n",
    "        assets_master[\"asset_id\"] = assets_master[\"asset_id\"].astype(str).str.strip()\n",
    "\n",
    "        # Drop duplicate master rows by key to keep join deterministic\n",
    "        assets_master = assets_master.drop_duplicates(subset=[\"asset_id\"], keep=\"last\")\n",
    "\n",
    "        before_cols = set(df.columns)\n",
    "        df = df.merge(assets_master, how=\"left\", on=\"asset_id\", suffixes=(\"\", \"_asset\"))\n",
    "        added = sorted(list(set(df.columns) - before_cols))\n",
    "        print(f\"Joined assets_master.csv on asset_id. Added {len(added)} column(s).\")\n",
    "    else:\n",
    "        print(\"assets_master.csv found, but no usable asset key detected. Skipping asset enrichment.\")\n",
    "else:\n",
    "    if not assets_path.exists():\n",
    "        print(\"assets_master.csv not found under data/raw; skipping asset enrichment.\")\n",
    "    elif \"asset_id\" not in df.columns:\n",
    "        print(\"asset_id not present in event data; skipping asset enrichment.\")\n",
    "\n",
    "if sites_path.exists() and \"site_id\" in df.columns:\n",
    "    sites_master = pd.read_csv(sites_path)\n",
    "\n",
    "    # Detect site id column in master\n",
    "    sm_site_col = find_col(sites_master.columns.tolist(), [\"site_id\", \"siteid\", \"site\", \"location_id\", \"plant_id\"])\n",
    "    if sm_site_col is not None and sm_site_col != \"site_id\":\n",
    "        sites_master = sites_master.rename(columns={sm_site_col: \"site_id\"})\n",
    "    if \"site_id\" in sites_master.columns:\n",
    "        sites_master[\"site_id\"] = sites_master[\"site_id\"].astype(str).str.strip()\n",
    "\n",
    "        # Drop duplicate master rows by key to keep join deterministic\n",
    "        sites_master = sites_master.drop_duplicates(subset=[\"site_id\"], keep=\"last\")\n",
    "\n",
    "        before_cols = set(df.columns)\n",
    "        df = df.merge(sites_master, how=\"left\", on=\"site_id\", suffixes=(\"\", \"_site\"))\n",
    "        added = sorted(list(set(df.columns) - before_cols))\n",
    "        print(f\"Joined sites_master.csv on site_id. Added {len(added)} column(s).\")\n",
    "    else:\n",
    "        print(\"sites_master.csv found, but no usable site key detected. Skipping site enrichment.\")\n",
    "else:\n",
    "    if not sites_path.exists():\n",
    "        print(\"sites_master.csv not found under data/raw; skipping site enrichment.\")\n",
    "    elif \"site_id\" not in df.columns:\n",
    "        print(\"site_id not present in event data; skipping site enrichment.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Quick sanity checks + save standardized/enriched snapshot\n",
    "# -----------------------------\n",
    "print(\"Shape after standardization/enrichment:\", df.shape)\n",
    "\n",
    "# Show a compact profile of nulls for key columns (if present)\n",
    "for c in [\"event_ts\", \"asset_id\", \"site_id\"]:\n",
    "    if c in df.columns:\n",
    "        print(f\"{c} nulls:\", int(df[c].isna().sum()))\n",
    "\n",
    "std_path = OUT_DIR / \"events_standardized_enriched.parquet\"\n",
    "df.to_parquet(std_path, index=False)\n",
    "print(\"Saved:\", std_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef198fff-a193-4f22-acbc-58610f17c6b6",
   "metadata": {},
   "source": [
    "### What Cell 3 Just Did\n",
    "\n",
    "This cell prepared the raw event dataset for feature engineering by standardizing key fields and enriching it with reference data. First, it searched for a likely timestamp column (for example `timestamp`, `event_time`, or `created_at`), renamed it to `event_ts`, parsed it as a UTC datetime, and generated basic time features (hour, day-of-week, month, weekend flag). Next, it searched for common identifier columns for assets and sites, normalizing them to `asset_id` and `site_id` and coercing them to cleaned strings to reduce join mismatches. If `data/raw/assets_master.csv` and/or `data/raw/sites_master.csv` were available and compatible keys existed, it left-joined those master tables to add descriptive attributes that can improve model signal. Finally, it printed sanity checks (shape and key null counts) and saved a standardized/enriched snapshot to `events_standardized_enriched.parquet` in the run output directory for repeatable downstream processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec907343-b3d5-48f1-a408-717255005fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy label definition:\n",
      "  legacy_col = is_legacy\n",
      "  conn_col   = connectivity\n",
      "\n",
      "Target distribution:\n",
      "target\n",
      "1    67\n",
      "0    53\n",
      "Name: count, dtype: int64\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/labeled_master_frame.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>vendor</th>\n",
       "      <th>site_id_asset</th>\n",
       "      <th>line_id_asset</th>\n",
       "      <th>asset_type_asset</th>\n",
       "      <th>is_legacy_asset</th>\n",
       "      <th>connectivity_asset</th>\n",
       "      <th>vendor_asset</th>\n",
       "      <th>site_name</th>\n",
       "      <th>tz</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id site_id line_id             asset_type  is_legacy   connectivity  \\\n",
       "0    A0001      S1   S1-L2         blister_packer      False     mqtt_opcua   \n",
       "1    A0002      S2   S2-L5            print_apply       True  legacy_serial   \n",
       "2    A0003      S4   S4-L2         blister_packer       True  legacy_serial   \n",
       "3    A0004      S1   S1-L2             sterilizer       True  legacy_serial   \n",
       "4    A0005      S4   S4-L2  environmental_monitor       True  legacy_serial   \n",
       "\n",
       "    vendor site_id_asset line_id_asset       asset_type_asset  \\\n",
       "0  VendorB            S1         S1-L2         blister_packer   \n",
       "1  VendorA            S2         S2-L5            print_apply   \n",
       "2  VendorB            S4         S4-L2         blister_packer   \n",
       "3  VendorD            S1         S1-L2             sterilizer   \n",
       "4  VendorA            S4         S4-L2  environmental_monitor   \n",
       "\n",
       "   is_legacy_asset connectivity_asset vendor_asset  \\\n",
       "0            False         mqtt_opcua      VendorB   \n",
       "1             True      legacy_serial      VendorA   \n",
       "2             True      legacy_serial      VendorB   \n",
       "3             True      legacy_serial      VendorD   \n",
       "4             True      legacy_serial      VendorA   \n",
       "\n",
       "                      site_name                            tz  target  \n",
       "0  Indianapolis Packaging Plant  America/Indiana/Indianapolis       0  \n",
       "1     San Diego Device Assembly           America/Los_Angeles       1  \n",
       "2         Singapore Sterile Ops                Asia/Singapore       1  \n",
       "3  Indianapolis Packaging Plant  America/Indiana/Indianapolis       1  \n",
       "4         Singapore Sterile Ops                Asia/Singapore       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 4 — Label engineering (proxy): define a binary risk target from available attributes\n",
    "#============================================================\n",
    "\n",
    "work_df = df.copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Choose a proxy label rule using columns we actually have\n",
    "# -----------------------------\n",
    "# Available columns (from your printout) include:\n",
    "# asset_id, site_id, line_id, asset_type, is_legacy, connectivity, vendor, site_name, tz, plus *_asset duplicates\n",
    "#\n",
    "# We'll define:\n",
    "#   target = 1 if is_legacy == 1 OR connectivity indicates lower connectivity / unknown\n",
    "# else target = 0\n",
    "#\n",
    "# NOTE: This is a placeholder label to unblock feature engineering + modeling pipeline wiring.\n",
    "#       You can later replace it with a true outcome label from iot_events or deviations logs.\n",
    "\n",
    "# Prefer \"is_legacy\" if present (fall back to is_legacy_asset if needed)\n",
    "legacy_col = \"is_legacy\" if \"is_legacy\" in work_df.columns else (\"is_legacy_asset\" if \"is_legacy_asset\" in work_df.columns else None)\n",
    "\n",
    "# Prefer \"connectivity\" if present (fall back to connectivity_asset)\n",
    "conn_col = \"connectivity\" if \"connectivity\" in work_df.columns else (\"connectivity_asset\" if \"connectivity_asset\" in work_df.columns else None)\n",
    "\n",
    "if legacy_col is None and conn_col is None:\n",
    "    raise KeyError(\n",
    "        \"No usable columns found to create a proxy label. \"\n",
    "        \"Expected at least one of: is_legacy / is_legacy_asset / connectivity / connectivity_asset.\"\n",
    "    )\n",
    "\n",
    "# Normalize legacy flag to 0/1 when available\n",
    "legacy_flag = pd.Series(0, index=work_df.index, dtype=\"int8\")\n",
    "if legacy_col is not None:\n",
    "    legacy_flag = pd.to_numeric(work_df[legacy_col], errors=\"coerce\").fillna(0).astype(\"int8\").clip(0, 1)\n",
    "\n",
    "# Normalize connectivity to a few buckets (string-based)\n",
    "conn_flag = pd.Series(0, index=work_df.index, dtype=\"int8\")\n",
    "if conn_col is not None:\n",
    "    conn_norm = work_df[conn_col].astype(str).str.strip().str.lower()\n",
    "\n",
    "    # Treat these as \"higher risk / lower observability\"\n",
    "    risky_conn = conn_norm.isin([\"none\", \"offline\", \"disconnected\", \"unknown\", \"na\", \"n/a\", \"nan\", \"\"])\n",
    "    conn_flag = risky_conn.astype(\"int8\")\n",
    "\n",
    "# Define proxy target\n",
    "work_df[\"target\"] = ((legacy_flag == 1) | (conn_flag == 1)).astype(\"int8\")\n",
    "\n",
    "print(\"Proxy label definition:\")\n",
    "print(f\"  legacy_col = {legacy_col}\")\n",
    "print(f\"  conn_col   = {conn_col}\")\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(work_df[\"target\"].value_counts(dropna=False))\n",
    "\n",
    "# Persist label definition for auditability\n",
    "label_def = {\n",
    "    \"target_name\": \"target\",\n",
    "    \"definition\": \"target=1 if is_legacy==1 OR connectivity in {none,offline,disconnected,unknown,blank}; else 0\",\n",
    "    \"legacy_col\": legacy_col,\n",
    "    \"connectivity_col\": conn_col,\n",
    "}\n",
    "with open(OUT_DIR / \"label_definition.json\", \"w\") as f:\n",
    "    json.dump(label_def, f, indent=2)\n",
    "\n",
    "# Save labeled snapshot\n",
    "labeled_path = OUT_DIR / \"labeled_master_frame.parquet\"\n",
    "work_df.to_parquet(labeled_path, index=False)\n",
    "print(\"Saved:\", labeled_path)\n",
    "\n",
    "display(work_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60d836-e014-4358-930d-74bb12e45bfb",
   "metadata": {},
   "source": [
    "### What Cell 4 Just Did\n",
    "\n",
    "This cell created a binary classification label (`target`) because the current dataset contains only asset/site attributes and no explicit outcome label yet. It implemented a transparent “proxy risk” rule using the columns that actually exist in your frame: legacy status (`is_legacy` or `is_legacy_asset`) and connectivity (`connectivity` or `connectivity_asset`). First, it normalized the legacy flag into a clean 0/1 indicator. Next, it normalized the connectivity field to lowercase strings and flagged values that imply low observability or poor connectivity (e.g., `offline`, `disconnected`, `unknown`, or blank). It then defined `target = 1` when either the asset is legacy or connectivity is in a risky/unknown state, otherwise `target = 0`. The cell printed the label distribution, saved the label rule to `label_definition.json` for auditability, and wrote a labeled snapshot (`labeled_master_frame.parquet`) into the run output directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d741a284-326b-49ad-a7f9-7d153c3cb646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 120\n",
      "ID columns excluded: ['asset_id', 'site_id']\n",
      "Numeric feature columns: ['is_legacy', 'is_legacy_asset']\n",
      "Categorical feature columns: ['line_id', 'asset_type', 'connectivity', 'vendor', 'site_id_asset', 'line_id_asset', 'asset_type_asset', 'connectivity_asset', 'vendor_asset', 'site_name', 'tz']\n",
      "\n",
      "Top missingness rates (features):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_legacy</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_legacy_asset</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_id</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset_type</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectivity</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_id_asset</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_id_asset</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset_type_asset</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectivity_asset</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor_asset</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_name</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tz</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    missing_%\n",
       "is_legacy                 0.0\n",
       "is_legacy_asset           0.0\n",
       "line_id                   0.0\n",
       "asset_type                0.0\n",
       "connectivity              0.0\n",
       "vendor                    0.0\n",
       "site_id_asset             0.0\n",
       "line_id_asset             0.0\n",
       "asset_type_asset          0.0\n",
       "connectivity_asset        0.0\n",
       "vendor_asset              0.0\n",
       "site_name                 0.0\n",
       "tz                        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/model_table.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>vendor</th>\n",
       "      <th>site_id_asset</th>\n",
       "      <th>line_id_asset</th>\n",
       "      <th>asset_type_asset</th>\n",
       "      <th>is_legacy_asset</th>\n",
       "      <th>connectivity_asset</th>\n",
       "      <th>vendor_asset</th>\n",
       "      <th>site_name</th>\n",
       "      <th>tz</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id site_id line_id             asset_type  is_legacy   connectivity  \\\n",
       "0    A0001      S1   S1-L2         blister_packer      False     mqtt_opcua   \n",
       "1    A0002      S2   S2-L5            print_apply       True  legacy_serial   \n",
       "2    A0003      S4   S4-L2         blister_packer       True  legacy_serial   \n",
       "3    A0004      S1   S1-L2             sterilizer       True  legacy_serial   \n",
       "4    A0005      S4   S4-L2  environmental_monitor       True  legacy_serial   \n",
       "\n",
       "    vendor site_id_asset line_id_asset       asset_type_asset  \\\n",
       "0  VendorB            S1         S1-L2         blister_packer   \n",
       "1  VendorA            S2         S2-L5            print_apply   \n",
       "2  VendorB            S4         S4-L2         blister_packer   \n",
       "3  VendorD            S1         S1-L2             sterilizer   \n",
       "4  VendorA            S4         S4-L2  environmental_monitor   \n",
       "\n",
       "   is_legacy_asset connectivity_asset vendor_asset  \\\n",
       "0            False         mqtt_opcua      VendorB   \n",
       "1             True      legacy_serial      VendorA   \n",
       "2             True      legacy_serial      VendorB   \n",
       "3             True      legacy_serial      VendorD   \n",
       "4             True      legacy_serial      VendorA   \n",
       "\n",
       "                      site_name                            tz  target  \n",
       "0  Indianapolis Packaging Plant  America/Indiana/Indianapolis       0  \n",
       "1     San Diego Device Assembly           America/Los_Angeles       1  \n",
       "2         Singapore Sterile Ops                Asia/Singapore       1  \n",
       "3  Indianapolis Packaging Plant  America/Indiana/Indianapolis       1  \n",
       "4         Singapore Sterile Ops                Asia/Singapore       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 5 — Feature set definition: exclude IDs, split numeric vs categorical, and persist lists\n",
    "#============================================================\n",
    "\n",
    "# Start from the labeled frame produced in Cell 4\n",
    "model_df = work_df.copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Define ID-like columns to exclude from modeling features\n",
    "# -----------------------------\n",
    "id_like = [\"asset_id\", \"site_id\", \"event_id\", \"id\", \"uuid\"]\n",
    "id_cols = [c for c in id_like if c in model_df.columns]\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Separate feature columns by dtype\n",
    "# -----------------------------\n",
    "exclude = set(id_cols + [\"target\"])\n",
    "\n",
    "numeric_cols = [\n",
    "    c for c in model_df.columns\n",
    "    if c not in exclude and pd.api.types.is_numeric_dtype(model_df[c])\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    c for c in model_df.columns\n",
    "    if c not in exclude and not pd.api.types.is_numeric_dtype(model_df[c])\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Sanity checks\n",
    "# -----------------------------\n",
    "if len(numeric_cols) + len(categorical_cols) == 0:\n",
    "    raise ValueError(\n",
    "        \"No feature columns detected after excluding IDs and target. \"\n",
    "        \"Check your input schema or adjust exclusions.\"\n",
    "    )\n",
    "\n",
    "print(\"Rows:\", len(model_df))\n",
    "print(\"ID columns excluded:\", id_cols)\n",
    "print(\"Numeric feature columns:\", numeric_cols)\n",
    "print(\"Categorical feature columns:\", categorical_cols)\n",
    "\n",
    "# Peek at missingness for features (helps choose imputers)\n",
    "missing = model_df[numeric_cols + categorical_cols].isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nTop missingness rates (features):\")\n",
    "display((missing * 100).round(2).head(15).to_frame(\"missing_%\"))\n",
    "\n",
    "# Persist column lists for reproducibility\n",
    "cols_out = {\n",
    "    \"id_cols\": id_cols,\n",
    "    \"numeric_cols\": numeric_cols,\n",
    "    \"categorical_cols\": categorical_cols,\n",
    "    \"feature_cols\": numeric_cols + categorical_cols,\n",
    "    \"target_col\": \"target\",\n",
    "}\n",
    "with open(OUT_DIR / \"feature_columns.json\", \"w\") as f:\n",
    "    json.dump(cols_out, f, indent=2)\n",
    "\n",
    "# Save a tidy “modeling table” snapshot (with IDs + target intact)\n",
    "model_table_path = OUT_DIR / \"model_table.parquet\"\n",
    "model_df.to_parquet(model_table_path, index=False)\n",
    "print(\"Saved:\", model_table_path)\n",
    "\n",
    "display(model_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bb7d53-c719-4d0d-bfd1-792bf703e9e3",
   "metadata": {},
   "source": [
    "### What Cell 5 Just Did\n",
    "\n",
    "This cell defined the feature set that will be used for preprocessing and modeling. It started from the labeled dataset (`work_df`) and identified “ID-like” columns (such as `asset_id` and `site_id`) that should be excluded from the feature matrix to avoid leakage or meaningless identifier effects. It then split the remaining columns (excluding `target`) into numeric and categorical feature lists based on pandas dtypes. To help us pick appropriate preprocessing steps, it computed and displayed the feature missingness rates, highlighting which columns may need imputation. Finally, it persisted the feature/target column configuration to `feature_columns.json` for reproducibility and saved a snapshot of the modeling table (`model_table.parquet`) to the run output directory so later notebooks or reruns can reference the exact same input frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4971f5d7-dda1-4b62-907c-c6e65bea3010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (120, 13)\n",
      "y shape: (120,)\n",
      "Positive rate: 0.5583333333333333\n",
      "\n",
      "Split shapes:\n",
      "  X_train: (96, 13) | y_train: (96,)\n",
      "  X_test : (24, 13) | y_test : (24,)\n",
      "\n",
      "Transformed shapes:\n",
      "  X_train_tx: (96, 90)\n",
      "  X_test_tx : (24, 90)\n",
      "  # features: 90\n",
      "\n",
      "Saved artifacts to: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z\n",
      "  preprocess.joblib\n",
      "  feature_names.csv\n",
      "  X_train.npy / X_test.npy\n",
      "  y_train.npy / y_test.npy\n",
      "  ids_train.parquet / ids_test.parquet\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 6 — Train/test split + preprocessing pipeline (impute, scale, one-hot) + fit\n",
    "#============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build X/y (keep IDs separately for traceability)\n",
    "# -----------------------------\n",
    "X = model_df[numeric_cols + categorical_cols].copy()\n",
    "y = model_df[\"target\"].astype(\"int8\").copy()\n",
    "\n",
    "ids_df = model_df[id_cols].copy() if id_cols else pd.DataFrame(index=model_df.index)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Positive rate:\", float(y.mean()))\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Split (stratify to preserve class balance)\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n",
    "    X, y, ids_df,\n",
    "    test_size=0.20,\n",
    "    random_state=SEED,\n",
    "    stratify=y if y.nunique() > 1 else None\n",
    ")\n",
    "\n",
    "print(\"\\nSplit shapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \"| y_train:\", y_train.shape)\n",
    "print(\"  X_test :\", X_test.shape,  \"| y_test :\", y_test.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Define preprocessing: numeric + categorical\n",
    "# -----------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Fit preprocessing on training set only\n",
    "# -----------------------------\n",
    "preprocess.fit(X_train)\n",
    "\n",
    "# Transform train/test\n",
    "X_train_tx = preprocess.transform(X_train)\n",
    "X_test_tx = preprocess.transform(X_test)\n",
    "\n",
    "# Feature names (post-transform)\n",
    "feature_names = preprocess.get_feature_names_out()\n",
    "\n",
    "print(\"\\nTransformed shapes:\")\n",
    "print(\"  X_train_tx:\", X_train_tx.shape)\n",
    "print(\"  X_test_tx :\", X_test_tx.shape)\n",
    "print(\"  # features:\", len(feature_names))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Persist artifacts for later notebooks\n",
    "# -----------------------------\n",
    "# Save numpy arrays + labels\n",
    "np.save(OUT_DIR / \"X_train.npy\", X_train_tx)\n",
    "np.save(OUT_DIR / \"X_test.npy\", X_test_tx)\n",
    "np.save(OUT_DIR / \"y_train.npy\", y_train.to_numpy())\n",
    "np.save(OUT_DIR / \"y_test.npy\", y_test.to_numpy())\n",
    "\n",
    "# Save IDs aligned to splits (useful for later attribution)\n",
    "if not ids_df.empty:\n",
    "    ids_train.to_parquet(OUT_DIR / \"ids_train.parquet\", index=False)\n",
    "    ids_test.to_parquet(OUT_DIR / \"ids_test.parquet\", index=False)\n",
    "\n",
    "# Save feature names\n",
    "pd.Series(feature_names, name=\"feature_name\").to_csv(OUT_DIR / \"feature_names.csv\", index=False)\n",
    "\n",
    "# Save fitted preprocessor\n",
    "joblib.dump(preprocess, OUT_DIR / \"preprocess.joblib\")\n",
    "\n",
    "print(\"\\nSaved artifacts to:\", OUT_DIR)\n",
    "print(\"  preprocess.joblib\")\n",
    "print(\"  feature_names.csv\")\n",
    "print(\"  X_train.npy / X_test.npy\")\n",
    "print(\"  y_train.npy / y_test.npy\")\n",
    "if not ids_df.empty:\n",
    "    print(\"  ids_train.parquet / ids_test.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde8de8-6e7e-425b-a441-25f49dbd4aca",
   "metadata": {},
   "source": [
    "### What Cell 6 Just Did\n",
    "\n",
    "This cell created the model-ready feature matrices by splitting the data and fitting a reproducible preprocessing pipeline. It first assembled `X` from the numeric and categorical feature columns and `y` from the binary `target`, while keeping any ID columns in a separate table for traceability. It then performed a train/test split (80/20), using stratification when possible to preserve class balance between the splits. Next, it defined a `ColumnTransformer` pipeline: numeric features are imputed with the median and scaled, while categorical features are imputed with the most frequent value and one-hot encoded with `handle_unknown=\"ignore\"` to prevent failures on unseen categories. The preprocessor was fit on the training data only, then applied to both train and test sets to produce transformed arrays. Finally, it saved the fitted preprocessor, transformed datasets (`X_train.npy`, `X_test.npy`, `y_train.npy`, `y_test.npy`), feature names, and split-aligned IDs (if present) into the run output directory for reuse in later notebooks without transformation drift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc035ef-b01d-47c8-8148-7a759912a182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance (positive rate):\n",
      "  train: 0.562  (n=96)\n",
      "  test : 0.542  (n=24)\n",
      "\n",
      "Leakage guardrails: PASSED (target/IDs not in feature matrix).\n",
      "\n",
      "First 30 transformed feature names:\n",
      "  is_legacy\n",
      "  is_legacy_asset\n",
      "  line_id_S1-L1\n",
      "  line_id_S1-L2\n",
      "  line_id_S1-L3\n",
      "  line_id_S1-L4\n",
      "  line_id_S1-L5\n",
      "  line_id_S2-L1\n",
      "  line_id_S2-L2\n",
      "  line_id_S2-L3\n",
      "  line_id_S2-L4\n",
      "  line_id_S2-L5\n",
      "  line_id_S3-L1\n",
      "  line_id_S3-L2\n",
      "  line_id_S3-L3\n",
      "  line_id_S3-L4\n",
      "  line_id_S3-L5\n",
      "  line_id_S4-L1\n",
      "  line_id_S4-L2\n",
      "  line_id_S4-L3\n",
      "  line_id_S4-L4\n",
      "  line_id_S4-L5\n",
      "  asset_type_blister_packer\n",
      "  asset_type_bottle_filler\n",
      "  asset_type_capper\n",
      "  asset_type_cartoner\n",
      "  asset_type_case_packer\n",
      "  asset_type_conveyor\n",
      "  asset_type_environmental_monitor\n",
      "  asset_type_labeler\n",
      "\n",
      "Last 10 transformed feature names:\n",
      "  vendor_asset_VendorC\n",
      "  vendor_asset_VendorD\n",
      "  site_name_Dublin EU Packaging\n",
      "  site_name_Indianapolis Packaging Plant\n",
      "  site_name_San Diego Device Assembly\n",
      "  site_name_Singapore Sterile Ops\n",
      "  tz_America/Indiana/Indianapolis\n",
      "  tz_America/Los_Angeles\n",
      "  tz_Asia/Singapore\n",
      "  tz_Europe/Dublin\n",
      "\n",
      "Raw feature cardinality (categoricals):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>line_id</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_id_asset</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset_type</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset_type_asset</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_id_asset</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor_asset</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_name</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tz</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectivity</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectivity_asset</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n_unique\n",
       "line_id                   20\n",
       "line_id_asset             20\n",
       "asset_type                12\n",
       "asset_type_asset          12\n",
       "vendor                     4\n",
       "site_id_asset              4\n",
       "vendor_asset               4\n",
       "site_name                  4\n",
       "tz                         4\n",
       "connectivity               2\n",
       "connectivity_asset         2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw numeric summary (numerics):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_legacy</th>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_legacy_asset</th>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count unique   top freq\n",
       "is_legacy         120      2  True   67\n",
       "is_legacy_asset   120      2  True   67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/qa_summary.json\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 7 — Quality checks: class balance, leakage guardrails, and feature preview\n",
    "#============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Class balance checks\n",
    "# -----------------------------\n",
    "train_pos = float(y_train.mean())\n",
    "test_pos = float(y_test.mean())\n",
    "\n",
    "print(\"Class balance (positive rate):\")\n",
    "print(f\"  train: {train_pos:.3f}  (n={len(y_train)})\")\n",
    "print(f\"  test : {test_pos:.3f}  (n={len(y_test)})\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Basic leakage / sanity checks\n",
    "# -----------------------------\n",
    "# Confirm target not in features\n",
    "assert \"target\" not in X.columns, \"Leakage: 'target' present in X\"\n",
    "\n",
    "# Confirm no ID columns accidentally included\n",
    "for c in id_cols:\n",
    "    assert c not in X.columns, f\"Leakage/ID feature included unexpectedly: {c}\"\n",
    "\n",
    "print(\"\\nLeakage guardrails: PASSED (target/IDs not in feature matrix).\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Feature-name preview (post-transform)\n",
    "# -----------------------------\n",
    "feature_names = pd.read_csv(OUT_DIR / \"feature_names.csv\")[\"feature_name\"].tolist()\n",
    "\n",
    "print(\"\\nFirst 30 transformed feature names:\")\n",
    "for f in feature_names[:30]:\n",
    "    print(\" \", f)\n",
    "\n",
    "print(\"\\nLast 10 transformed feature names:\")\n",
    "for f in feature_names[-10:]:\n",
    "    print(\" \", f)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Quick distribution checks for a few raw features (before transform)\n",
    "# -----------------------------\n",
    "# This helps validate that categorical values look reasonable and not overly messy.\n",
    "print(\"\\nRaw feature cardinality (categoricals):\")\n",
    "if categorical_cols:\n",
    "    cat_card = {c: int(model_df[c].nunique(dropna=True)) for c in categorical_cols}\n",
    "    display(pd.Series(cat_card, name=\"n_unique\").sort_values(ascending=False).to_frame())\n",
    "else:\n",
    "    print(\"  (no categorical columns detected)\")\n",
    "\n",
    "print(\"\\nRaw numeric summary (numerics):\")\n",
    "if numeric_cols:\n",
    "    display(model_df[numeric_cols].describe().T)\n",
    "else:\n",
    "    print(\"  (no numeric columns detected)\")\n",
    "\n",
    "# Persist a small QA summary\n",
    "qa = {\n",
    "    \"train_positive_rate\": train_pos,\n",
    "    \"test_positive_rate\": test_pos,\n",
    "    \"n_train\": int(len(y_train)),\n",
    "    \"n_test\": int(len(y_test)),\n",
    "    \"n_raw_features\": int(X.shape[1]),\n",
    "    \"n_transformed_features\": int(len(feature_names)),\n",
    "    \"numeric_cols\": numeric_cols,\n",
    "    \"categorical_cols\": categorical_cols,\n",
    "}\n",
    "with open(OUT_DIR / \"qa_summary.json\", \"w\") as f:\n",
    "    json.dump(qa, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved:\", OUT_DIR / \"qa_summary.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26744728-0e01-4ddc-8f36-cd9fbc2a4268",
   "metadata": {},
   "source": [
    "### What Cell 7 Just Did\n",
    "\n",
    "This cell performed lightweight quality assurance checks to confirm the feature engineering outputs are sane and safe to use downstream. It compared class balance between train and test splits by printing the positive-rate in each split, helping detect accidental stratification issues or label drift. It then applied simple leakage guardrails to ensure the target label and any ID-like columns were not mistakenly included in the feature matrix. Next, it previewed the transformed feature names produced by the preprocessing pipeline (useful for debugging one-hot expansion and verifying expected categorical encodings). It also summarized categorical cardinalities (number of unique values per categorical feature) and generated descriptive statistics for numeric features to spot obvious anomalies. Finally, it saved a compact QA report to `qa_summary.json` in the run output directory so this run’s health checks are recorded alongside the saved artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4520f6e-587a-4b74-bf74-dec91dcab370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: Logistic Regression\n",
      "  Accuracy : 1.000\n",
      "  Precision: 1.000\n",
      "  Recall   : 1.000\n",
      "  F1       : 1.000\n",
      "  ROC AUC  : 1.000\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[11  0]\n",
      " [ 0 13]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        24\n",
      "   macro avg       1.00      1.00      1.00        24\n",
      "weighted avg       1.00      1.00      1.00        24\n",
      "\n",
      "\n",
      "Saved:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_metrics.json\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg.joblib\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 8 — Baseline model: Logistic Regression (sanity baseline) + simple evaluation\n",
    "#============================================================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Train a simple baseline model\n",
    "# -----------------------------\n",
    "# Use class_weight=\"balanced\" because even moderate imbalance can bias a baseline.\n",
    "clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=None,          # keep default for broad compatibility\n",
    "    solver=\"lbfgs\",\n",
    ")\n",
    "\n",
    "clf.fit(X_train_tx, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Predict and evaluate\n",
    "# -----------------------------\n",
    "y_pred = clf.predict(X_test_tx)\n",
    "\n",
    "# Some metrics require probabilities; handle edge-case where only 1 class exists\n",
    "if len(np.unique(y_train)) == 2:\n",
    "    y_proba = clf.predict_proba(X_test_tx)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "else:\n",
    "    y_proba = None\n",
    "    auc = np.nan\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Baseline: Logistic Regression\")\n",
    "print(f\"  Accuracy : {acc:.3f}\")\n",
    "print(f\"  Precision: {prec:.3f}\")\n",
    "print(f\"  Recall   : {rec:.3f}\")\n",
    "print(f\"  F1       : {f1:.3f}\")\n",
    "print(f\"  ROC AUC  : {auc:.3f}\" if not np.isnan(auc) else \"  ROC AUC  : n/a (single-class train)\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Persist baseline outputs\n",
    "# -----------------------------\n",
    "baseline = {\n",
    "    \"model\": \"LogisticRegression(class_weight=balanced, solver=lbfgs, max_iter=2000)\",\n",
    "    \"accuracy\": float(acc),\n",
    "    \"precision\": float(prec),\n",
    "    \"recall\": float(rec),\n",
    "    \"f1\": float(f1),\n",
    "    \"roc_auc\": float(auc) if not np.isnan(auc) else None,\n",
    "    \"confusion_matrix\": cm.tolist(),\n",
    "}\n",
    "with open(OUT_DIR / \"baseline_logreg_metrics.json\", \"w\") as f:\n",
    "    json.dump(baseline, f, indent=2)\n",
    "\n",
    "joblib.dump(clf, OUT_DIR / \"baseline_logreg.joblib\")\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", OUT_DIR / \"baseline_logreg_metrics.json\")\n",
    "print(\" \", OUT_DIR / \"baseline_logreg.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ed1be3-7e50-4534-a4c4-6cd53dafa7f7",
   "metadata": {},
   "source": [
    "### What Cell 8 Just Did\n",
    "\n",
    "This cell trained and evaluated a simple baseline classifier to sanity-check the engineered features and labels. It fit a `LogisticRegression` model on the preprocessed training data (`X_train_tx`, `y_train`) using `class_weight=\"balanced\"` to reduce bias if the classes are uneven. It then generated predictions on the held-out test set and computed standard classification metrics (accuracy, precision, recall, and F1). When available, it also computed ROC AUC using predicted probabilities. To make model behavior interpretable, it printed a confusion matrix and a full classification report. Finally, it persisted the baseline model (`baseline_logreg.joblib`) and its metrics (`baseline_logreg_metrics.json`) into the run output directory so downstream notebooks can reference this baseline and compare improvements against it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4f83265-8d86-4e0a-b476-44e2848c3ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features by absolute coefficient magnitude:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_legacy</td>\n",
       "      <td>1.380642</td>\n",
       "      <td>1.380642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is_legacy_asset</td>\n",
       "      <td>1.380642</td>\n",
       "      <td>1.380642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>connectivity_asset_mqtt_opcua</td>\n",
       "      <td>-0.685530</td>\n",
       "      <td>0.685530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>connectivity_mqtt_opcua</td>\n",
       "      <td>-0.685530</td>\n",
       "      <td>0.685530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>connectivity_asset_legacy_serial</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.684105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>connectivity_legacy_serial</td>\n",
       "      <td>0.684105</td>\n",
       "      <td>0.684105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>vendor_asset_VendorB</td>\n",
       "      <td>-0.081042</td>\n",
       "      <td>0.081042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>vendor_VendorB</td>\n",
       "      <td>-0.081042</td>\n",
       "      <td>0.081042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>site_name_Singapore Sterile Ops</td>\n",
       "      <td>-0.070988</td>\n",
       "      <td>0.070988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>site_id_asset_S4</td>\n",
       "      <td>-0.070988</td>\n",
       "      <td>0.070988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tz_Asia/Singapore</td>\n",
       "      <td>-0.070988</td>\n",
       "      <td>0.070988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>site_name_San Diego Device Assembly</td>\n",
       "      <td>0.064324</td>\n",
       "      <td>0.064324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tz_America/Los_Angeles</td>\n",
       "      <td>0.064324</td>\n",
       "      <td>0.064324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>site_id_asset_S2</td>\n",
       "      <td>0.064324</td>\n",
       "      <td>0.064324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>vendor_asset_VendorA</td>\n",
       "      <td>0.058303</td>\n",
       "      <td>0.058303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>vendor_VendorA</td>\n",
       "      <td>0.058303</td>\n",
       "      <td>0.058303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>line_id_asset_S2-L5</td>\n",
       "      <td>0.055637</td>\n",
       "      <td>0.055637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>0.055637</td>\n",
       "      <td>0.055637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>line_id_asset_S3-L5</td>\n",
       "      <td>-0.055255</td>\n",
       "      <td>0.055255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>line_id_S3-L5</td>\n",
       "      <td>-0.055255</td>\n",
       "      <td>0.055255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature      coef  abs_coef\n",
       "0                             is_legacy  1.380642  1.380642\n",
       "1                       is_legacy_asset  1.380642  1.380642\n",
       "77        connectivity_asset_mqtt_opcua -0.685530  0.685530\n",
       "35              connectivity_mqtt_opcua -0.685530  0.685530\n",
       "76     connectivity_asset_legacy_serial  0.684105  0.684105\n",
       "34           connectivity_legacy_serial  0.684105  0.684105\n",
       "79                 vendor_asset_VendorB -0.081042  0.081042\n",
       "37                       vendor_VendorB -0.081042  0.081042\n",
       "85      site_name_Singapore Sterile Ops -0.070988  0.070988\n",
       "43                     site_id_asset_S4 -0.070988  0.070988\n",
       "88                    tz_Asia/Singapore -0.070988  0.070988\n",
       "84  site_name_San Diego Device Assembly  0.064324  0.064324\n",
       "87               tz_America/Los_Angeles  0.064324  0.064324\n",
       "41                     site_id_asset_S2  0.064324  0.064324\n",
       "78                 vendor_asset_VendorA  0.058303  0.058303\n",
       "36                       vendor_VendorA  0.058303  0.058303\n",
       "53                  line_id_asset_S2-L5  0.055637  0.055637\n",
       "11                        line_id_S2-L5  0.055637  0.055637\n",
       "58                  line_id_asset_S3-L5 -0.055255  0.055255\n",
       "16                        line_id_S3-L5 -0.055255  0.055255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features pushing toward target=1 (risk proxy):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_legacy</td>\n",
       "      <td>1.380642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is_legacy_asset</td>\n",
       "      <td>1.380642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>connectivity_asset_legacy_serial</td>\n",
       "      <td>0.684105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>connectivity_legacy_serial</td>\n",
       "      <td>0.684105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>tz_America/Los_Angeles</td>\n",
       "      <td>0.064324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>site_id_asset_S2</td>\n",
       "      <td>0.064324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>site_name_San Diego Device Assembly</td>\n",
       "      <td>0.064324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>vendor_asset_VendorA</td>\n",
       "      <td>0.058303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>vendor_VendorA</td>\n",
       "      <td>0.058303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>line_id_asset_S2-L5</td>\n",
       "      <td>0.055637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>0.055637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>asset_type_capper</td>\n",
       "      <td>0.049682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>asset_type_asset_capper</td>\n",
       "      <td>0.049682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>line_id_asset_S3-L2</td>\n",
       "      <td>0.037039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>line_id_S3-L2</td>\n",
       "      <td>0.037039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature      coef\n",
       "0                             is_legacy  1.380642\n",
       "1                       is_legacy_asset  1.380642\n",
       "76     connectivity_asset_legacy_serial  0.684105\n",
       "34           connectivity_legacy_serial  0.684105\n",
       "87               tz_America/Los_Angeles  0.064324\n",
       "41                     site_id_asset_S2  0.064324\n",
       "84  site_name_San Diego Device Assembly  0.064324\n",
       "78                 vendor_asset_VendorA  0.058303\n",
       "36                       vendor_VendorA  0.058303\n",
       "53                  line_id_asset_S2-L5  0.055637\n",
       "11                        line_id_S2-L5  0.055637\n",
       "24                    asset_type_capper  0.049682\n",
       "66              asset_type_asset_capper  0.049682\n",
       "55                  line_id_asset_S3-L2  0.037039\n",
       "13                        line_id_S3-L2  0.037039"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features pushing toward target=0 (non-risk proxy):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>connectivity_asset_mqtt_opcua</td>\n",
       "      <td>-0.685530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>connectivity_mqtt_opcua</td>\n",
       "      <td>-0.685530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>vendor_asset_VendorB</td>\n",
       "      <td>-0.081042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>vendor_VendorB</td>\n",
       "      <td>-0.081042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>site_name_Singapore Sterile Ops</td>\n",
       "      <td>-0.070988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>site_id_asset_S4</td>\n",
       "      <td>-0.070988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>tz_Asia/Singapore</td>\n",
       "      <td>-0.070988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>line_id_S3-L5</td>\n",
       "      <td>-0.055255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>line_id_asset_S3-L5</td>\n",
       "      <td>-0.055255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>line_id_asset_S4-L5</td>\n",
       "      <td>-0.037923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>-0.037923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>line_id_S1-L4</td>\n",
       "      <td>-0.032050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>line_id_asset_S1-L4</td>\n",
       "      <td>-0.032050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>-0.031945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>asset_type_asset_cartoner</td>\n",
       "      <td>-0.031945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature      coef\n",
       "77    connectivity_asset_mqtt_opcua -0.685530\n",
       "35          connectivity_mqtt_opcua -0.685530\n",
       "79             vendor_asset_VendorB -0.081042\n",
       "37                   vendor_VendorB -0.081042\n",
       "85  site_name_Singapore Sterile Ops -0.070988\n",
       "43                 site_id_asset_S4 -0.070988\n",
       "88                tz_Asia/Singapore -0.070988\n",
       "16                    line_id_S3-L5 -0.055255\n",
       "58              line_id_asset_S3-L5 -0.055255\n",
       "63              line_id_asset_S4-L5 -0.037923\n",
       "21                    line_id_S4-L5 -0.037923\n",
       "5                     line_id_S1-L4 -0.032050\n",
       "47              line_id_asset_S1-L4 -0.032050\n",
       "25              asset_type_cartoner -0.031945\n",
       "67        asset_type_asset_cartoner -0.031945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_coefficients.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 9 — Interpretability: top positive/negative coefficients (baseline logistic regression)\n",
    "#============================================================\n",
    "\n",
    "# Load feature names (aligned to transformed matrices)\n",
    "feature_names = pd.read_csv(OUT_DIR / \"feature_names.csv\")[\"feature_name\"].tolist()\n",
    "\n",
    "# LogisticRegression coef_ is shape (1, n_features) for binary classification\n",
    "coefs = clf.coef_.ravel()\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coef\": coefs,\n",
    "    \"abs_coef\": np.abs(coefs),\n",
    "}).sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "print(\"Top 20 features by absolute coefficient magnitude:\")\n",
    "display(coef_df.head(20))\n",
    "\n",
    "print(\"\\nTop 15 features pushing toward target=1 (risk proxy):\")\n",
    "display(coef_df.sort_values(\"coef\", ascending=False).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "print(\"\\nTop 15 features pushing toward target=0 (non-risk proxy):\")\n",
    "display(coef_df.sort_values(\"coef\", ascending=True).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "# Persist for later reporting/slides\n",
    "coef_out = OUT_DIR / \"baseline_logreg_coefficients.csv\"\n",
    "coef_df.to_csv(coef_out, index=False)\n",
    "print(\"\\nSaved:\", coef_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b193a1-0227-4103-899b-d800a9b2a520",
   "metadata": {},
   "source": [
    "### What Cell 9 Just Did\n",
    "\n",
    "This cell added a first layer of interpretability by inspecting which engineered features most strongly influence the baseline logistic regression model. It paired the model’s learned coefficients with the transformed feature names produced by the preprocessing pipeline (including one-hot expanded categorical values). It then ranked features by absolute coefficient magnitude to identify the strongest drivers overall, and separately listed the features with the most positive coefficients (pushing predictions toward `target=1` under our risk proxy) and the most negative coefficients (pushing predictions toward `target=0`). Finally, it saved a complete coefficient table to `baseline_logreg_coefficients.csv` so you can reference these drivers in write-ups, debugging, or slides without rerunning the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97d924b7-fbfb-43fb-b0ce-07f2d8ba8acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/RUN_SUMMARY.md\n",
      "\n",
      "Preview:\n",
      "\n",
      "# Feature Engineering Run Summary\n",
      "\n",
      "- **Run timestamp (UTC):** 20251212T181645Z\n",
      "- **Project root:** `/home/parallels/projects/gmp-packaging-risk-analytics`\n",
      "- **Output directory:** `/home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z`\n",
      "\n",
      "## Data Inputs\n",
      "- **Base dataset:** `/home/parallels/projects/gmp-packaging-risk-analytics/data/raw/assets_master.csv`\n",
      "- **Rows loaded:** 120\n",
      "\n",
      "## Label Definition\n",
      "- **Target column:** `target`\n",
      "- **Rule:** target=1 if is_legacy==1 OR connectivity in {none,offline,disconnected,unknown,blank}; else 0\n",
      "- **Legacy column used:** `is_legacy`\n",
      "- **Connectivity column used:** `connectivity`\n",
      "\n",
      "## Features\n",
      "- **Numeric features (raw):** 2\n",
      "- **Categorical features (raw):** 11\n",
      "- **Total raw features:** 13\n",
      "- **Transformed features (post one-hot):** 90\n",
      "\n",
      "## Train/Test Split\n",
      "- **Train size:** 96 | **Positive rate:** 0.562\n",
      "- **Test size:** 24 | **Positive rate:** 0.542\n",
      "\n",
      "## Baseline Model (Logistic Regression)\n",
      "- **Accuracy:** 1.000\n",
      "- **Precision:** 1.000\n",
      "- **Recall:** 1.000\n",
      "- **F1:** 1.000\n",
      "- **ROC AUC:** 1.000\n",
      "\n",
      "## Saved Artifacts\n",
      "- `run_metadata.json`\n",
      "- `input_base_dataset_path.txt`\n",
      "- `events_standardized_enriched.parquet\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 10 — Package outputs: write a concise “run summary” markdown for the repo/notebook trail\n",
    "#============================================================\n",
    "\n",
    "run_summary_lines = []\n",
    "\n",
    "run_summary_lines.append(f\"# Feature Engineering Run Summary\")\n",
    "run_summary_lines.append(\"\")\n",
    "run_summary_lines.append(f\"- **Run timestamp (UTC):** {RUN_TS}\")\n",
    "run_summary_lines.append(f\"- **Project root:** `{PROJECT_ROOT}`\")\n",
    "run_summary_lines.append(f\"- **Output directory:** `{OUT_DIR}`\")\n",
    "run_summary_lines.append(\"\")\n",
    "\n",
    "# Input + row counts\n",
    "input_path_txt = OUT_DIR / \"input_base_dataset_path.txt\"\n",
    "input_path = input_path_txt.read_text().strip() if input_path_txt.exists() else \"(unknown)\"\n",
    "run_summary_lines.append(\"## Data Inputs\")\n",
    "run_summary_lines.append(f\"- **Base dataset:** `{input_path}`\")\n",
    "run_summary_lines.append(f\"- **Rows loaded:** {int(len(base_df))}\")\n",
    "run_summary_lines.append(\"\")\n",
    "\n",
    "# Label definition\n",
    "label_def_path = OUT_DIR / \"label_definition.json\"\n",
    "if label_def_path.exists():\n",
    "    label_def = json.loads(label_def_path.read_text())\n",
    "    run_summary_lines.append(\"## Label Definition\")\n",
    "    run_summary_lines.append(f\"- **Target column:** `{label_def.get('target_name','target')}`\")\n",
    "    run_summary_lines.append(f\"- **Rule:** {label_def.get('definition','(missing)')}\")\n",
    "    run_summary_lines.append(f\"- **Legacy column used:** `{label_def.get('legacy_col')}`\")\n",
    "    run_summary_lines.append(f\"- **Connectivity column used:** `{label_def.get('connectivity_col')}`\")\n",
    "    run_summary_lines.append(\"\")\n",
    "else:\n",
    "    run_summary_lines.append(\"## Label Definition\")\n",
    "    run_summary_lines.append(\"- (No label definition file found.)\")\n",
    "    run_summary_lines.append(\"\")\n",
    "\n",
    "# Feature counts\n",
    "run_summary_lines.append(\"## Features\")\n",
    "run_summary_lines.append(f\"- **Numeric features (raw):** {len(numeric_cols)}\")\n",
    "run_summary_lines.append(f\"- **Categorical features (raw):** {len(categorical_cols)}\")\n",
    "run_summary_lines.append(f\"- **Total raw features:** {len(numeric_cols) + len(categorical_cols)}\")\n",
    "run_summary_lines.append(f\"- **Transformed features (post one-hot):** {len(feature_names)}\")\n",
    "run_summary_lines.append(\"\")\n",
    "\n",
    "# Split stats\n",
    "run_summary_lines.append(\"## Train/Test Split\")\n",
    "run_summary_lines.append(f\"- **Train size:** {len(y_train)} | **Positive rate:** {float(y_train.mean()):.3f}\")\n",
    "run_summary_lines.append(f\"- **Test size:** {len(y_test)} | **Positive rate:** {float(y_test.mean()):.3f}\")\n",
    "run_summary_lines.append(\"\")\n",
    "\n",
    "# Baseline metrics\n",
    "metrics_path = OUT_DIR / \"baseline_logreg_metrics.json\"\n",
    "if metrics_path.exists():\n",
    "    m = json.loads(metrics_path.read_text())\n",
    "    run_summary_lines.append(\"## Baseline Model (Logistic Regression)\")\n",
    "    run_summary_lines.append(f\"- **Accuracy:** {m.get('accuracy'):.3f}\")\n",
    "    run_summary_lines.append(f\"- **Precision:** {m.get('precision'):.3f}\")\n",
    "    run_summary_lines.append(f\"- **Recall:** {m.get('recall'):.3f}\")\n",
    "    run_summary_lines.append(f\"- **F1:** {m.get('f1'):.3f}\")\n",
    "    if m.get(\"roc_auc\") is not None:\n",
    "        run_summary_lines.append(f\"- **ROC AUC:** {m.get('roc_auc'):.3f}\")\n",
    "    run_summary_lines.append(\"\")\n",
    "else:\n",
    "    run_summary_lines.append(\"## Baseline Model\")\n",
    "    run_summary_lines.append(\"- (No baseline metrics file found.)\")\n",
    "    run_summary_lines.append(\"\")\n",
    "\n",
    "# Artifacts list\n",
    "run_summary_lines.append(\"## Saved Artifacts\")\n",
    "artifacts = [\n",
    "    \"run_metadata.json\",\n",
    "    \"input_base_dataset_path.txt\",\n",
    "    \"events_standardized_enriched.parquet\",\n",
    "    \"label_definition.json\",\n",
    "    \"labeled_master_frame.parquet\",\n",
    "    \"feature_columns.json\",\n",
    "    \"model_table.parquet\",\n",
    "    \"preprocess.joblib\",\n",
    "    \"feature_names.csv\",\n",
    "    \"X_train.npy\",\n",
    "    \"X_test.npy\",\n",
    "    \"y_train.npy\",\n",
    "    \"y_test.npy\",\n",
    "    \"ids_train.parquet\",\n",
    "    \"ids_test.parquet\",\n",
    "    \"qa_summary.json\",\n",
    "    \"baseline_logreg.joblib\",\n",
    "    \"baseline_logreg_metrics.json\",\n",
    "    \"baseline_logreg_coefficients.csv\",\n",
    "]\n",
    "for a in artifacts:\n",
    "    p = OUT_DIR / a\n",
    "    if p.exists():\n",
    "        run_summary_lines.append(f\"- `{a}`\")\n",
    "run_summary_lines.append(\"\")\n",
    "\n",
    "summary_md = \"\\n\".join(run_summary_lines)\n",
    "\n",
    "summary_path = OUT_DIR / \"RUN_SUMMARY.md\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(summary_md)\n",
    "\n",
    "print(\"Saved:\", summary_path)\n",
    "print(\"\\nPreview:\\n\")\n",
    "print(summary_md[:1200] + (\"\\n...\\n\" if len(summary_md) > 1200 else \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57276128-790a-4b6d-8851-dddaf867b126",
   "metadata": {},
   "source": [
    "### What Cell 10 Just Did\n",
    "\n",
    "This cell packaged the work you’ve completed so far into a concise, shareable run summary. It assembled key run metadata (timestamp, project root, and output directory), recorded which base dataset was used, and documented the proxy label rule (including which legacy/connectivity columns were chosen). It also summarized the feature configuration (raw numeric/categorical counts and the final post–one-hot feature count), train/test split sizes and positive rates, and the baseline logistic regression performance metrics when available. Finally, it generated and saved a `RUN_SUMMARY.md` file directly into the run output directory, alongside a curated list of the important artifacts produced by the notebook. This gives you a single “receipt” for the run that is easy to reference later or include in your repo history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f833fee4-7e45-42a3-959d-9ce8a0d5f8f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage-prone columns (used to define proxy label): ['connectivity', 'connectivity_asset', 'is_legacy', 'is_legacy_asset']\n",
      "\n",
      "Feature counts:\n",
      "  numeric (orig): 2 -> (no-leak): 0\n",
      "  categorical (orig): 11 -> (no-leak): 9\n",
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/feature_columns_noleak.json\n",
      "\n",
      "No-leak baseline: Logistic Regression\n",
      "  Accuracy : 0.542\n",
      "  Precision: 0.600\n",
      "  Recall   : 0.462\n",
      "  F1       : 0.522\n",
      "  ROC AUC  : 0.503\n",
      "\n",
      "Saved:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/preprocess_noleak.joblib\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_noleak.joblib\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_noleak_metrics.json\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 11 — Correctness check: detect “proxy label leakage” and generate a no-leak feature set\n",
    "#============================================================\n",
    "\n",
    "# Your proxy label is defined directly from is_legacy / connectivity.\n",
    "# Those same columns are currently in the feature set, which makes the baseline “perfect”\n",
    "# but not meaningful. This cell detects that and creates a leakage-safe feature set.\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Detect leakage columns used by the proxy label\n",
    "# -----------------------------\n",
    "leak_cols = []\n",
    "\n",
    "# From our saved label definition (if present)\n",
    "label_def_path = OUT_DIR / \"label_definition.json\"\n",
    "if label_def_path.exists():\n",
    "    label_def = json.loads(label_def_path.read_text())\n",
    "    if label_def.get(\"legacy_col\"):\n",
    "        leak_cols.append(label_def[\"legacy_col\"])\n",
    "    if label_def.get(\"connectivity_col\"):\n",
    "        leak_cols.append(label_def[\"connectivity_col\"])\n",
    "\n",
    "# Also consider the *_asset duplicates, since they encode the same signal\n",
    "for c in [\"is_legacy\", \"is_legacy_asset\", \"connectivity\", \"connectivity_asset\"]:\n",
    "    if c in model_df.columns and c not in leak_cols:\n",
    "        # Only mark if it exists and is clearly part of the proxy-label family\n",
    "        if \"legacy\" in c or \"connectivity\" in c:\n",
    "            leak_cols.append(c)\n",
    "\n",
    "leak_cols = sorted(set([c for c in leak_cols if c in model_df.columns]))\n",
    "print(\"Leakage-prone columns (used to define proxy label):\", leak_cols)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build a leakage-safe feature list (drop leak_cols from features)\n",
    "# -----------------------------\n",
    "numeric_cols_noleak = [c for c in numeric_cols if c not in leak_cols]\n",
    "categorical_cols_noleak = [c for c in categorical_cols if c not in leak_cols]\n",
    "\n",
    "print(\"\\nFeature counts:\")\n",
    "print(\"  numeric (orig):\", len(numeric_cols), \"-> (no-leak):\", len(numeric_cols_noleak))\n",
    "print(\"  categorical (orig):\", len(categorical_cols), \"-> (no-leak):\", len(categorical_cols_noleak))\n",
    "\n",
    "if len(numeric_cols_noleak) + len(categorical_cols_noleak) == 0:\n",
    "    raise ValueError(\n",
    "        \"After removing leakage columns, no features remain. \"\n",
    "        \"This indicates the proxy label fully depends on the available columns.\"\n",
    "    )\n",
    "\n",
    "# Persist the no-leak feature spec\n",
    "with open(OUT_DIR / \"feature_columns_noleak.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"id_cols\": id_cols,\n",
    "            \"numeric_cols\": numeric_cols_noleak,\n",
    "            \"categorical_cols\": categorical_cols_noleak,\n",
    "            \"dropped_leak_cols\": leak_cols,\n",
    "            \"target_col\": \"target\",\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "print(\"\\nSaved:\", OUT_DIR / \"feature_columns_noleak.json\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Refit preprocessing + baseline on no-leak features (quick re-run)\n",
    "# -----------------------------\n",
    "X_noleak = model_df[numeric_cols_noleak + categorical_cols_noleak].copy()\n",
    "y_noleak = model_df[\"target\"].astype(\"int8\").copy()\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_noleak, y_noleak,\n",
    "    test_size=0.20,\n",
    "    random_state=SEED,\n",
    "    stratify=y_noleak if y_noleak.nunique() > 1 else None\n",
    ")\n",
    "\n",
    "num_tx = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "cat_tx = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "])\n",
    "\n",
    "preprocess_noleak = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_tx, numeric_cols_noleak),\n",
    "        (\"cat\", cat_tx, categorical_cols_noleak),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "preprocess_noleak.fit(Xtr)\n",
    "Xtr_tx = preprocess_noleak.transform(Xtr)\n",
    "Xte_tx = preprocess_noleak.transform(Xte)\n",
    "\n",
    "clf_noleak = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"lbfgs\",\n",
    ")\n",
    "clf_noleak.fit(Xtr_tx, ytr)\n",
    "\n",
    "yp = clf_noleak.predict(Xte_tx)\n",
    "acc = accuracy_score(yte, yp)\n",
    "prec = precision_score(yte, yp, zero_division=0)\n",
    "rec = recall_score(yte, yp, zero_division=0)\n",
    "f1 = f1_score(yte, yp, zero_division=0)\n",
    "\n",
    "if ytr.nunique() == 2:\n",
    "    yproba = clf_noleak.predict_proba(Xte_tx)[:, 1]\n",
    "    auc = roc_auc_score(yte, yproba)\n",
    "else:\n",
    "    auc = np.nan\n",
    "\n",
    "print(\"\\nNo-leak baseline: Logistic Regression\")\n",
    "print(f\"  Accuracy : {acc:.3f}\")\n",
    "print(f\"  Precision: {prec:.3f}\")\n",
    "print(f\"  Recall   : {rec:.3f}\")\n",
    "print(f\"  F1       : {f1:.3f}\")\n",
    "print(f\"  ROC AUC  : {auc:.3f}\" if not np.isnan(auc) else \"  ROC AUC  : n/a (single-class train)\")\n",
    "\n",
    "# Save artifacts\n",
    "joblib.dump(preprocess_noleak, OUT_DIR / \"preprocess_noleak.joblib\")\n",
    "joblib.dump(clf_noleak, OUT_DIR / \"baseline_logreg_noleak.joblib\")\n",
    "\n",
    "with open(OUT_DIR / \"baseline_logreg_noleak_metrics.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"model\": \"LogisticRegression(class_weight=balanced, solver=lbfgs, max_iter=2000)\",\n",
    "            \"accuracy\": float(acc),\n",
    "            \"precision\": float(prec),\n",
    "            \"recall\": float(rec),\n",
    "            \"f1\": float(f1),\n",
    "            \"roc_auc\": float(auc) if not np.isnan(auc) else None,\n",
    "            \"dropped_leak_cols\": leak_cols,\n",
    "            \"n_features_raw\": int(X_noleak.shape[1]),\n",
    "            \"n_features_transformed\": int(Xtr_tx.shape[1]),\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", OUT_DIR / \"preprocess_noleak.joblib\")\n",
    "print(\" \", OUT_DIR / \"baseline_logreg_noleak.joblib\")\n",
    "print(\" \", OUT_DIR / \"baseline_logreg_noleak_metrics.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171fbbe3-fe05-4de7-b34d-006fa0552d1f",
   "metadata": {},
   "source": [
    "### What Cell 11 Just Did\n",
    "\n",
    "This cell addressed an important correctness issue: because our proxy label was defined directly from `is_legacy` and/or `connectivity`, including those same columns as features creates label leakage and can produce artificially perfect metrics (like the 1.000 scores you saw). The cell first identified which columns were used to define the proxy label (including any closely related duplicates such as `is_legacy_asset` or `connectivity_asset`). It then produced a “no-leak” feature specification by removing those columns from the feature set and saved that configuration to `feature_columns_noleak.json`. Finally, it refit a new preprocessing pipeline and a new logistic regression baseline using only the leakage-safe features and saved the resulting pipeline, model, and metrics. This gives you a more honest baseline that reflects how well the remaining attributes predict the proxy label without directly encoding the labeling rule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ce127d0-5a0c-45ba-9696-6c560c476709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 no-leak features by absolute coefficient magnitude:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>asset_type_asset_capper</td>\n",
       "      <td>0.623308</td>\n",
       "      <td>0.623308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>asset_type_capper</td>\n",
       "      <td>0.623308</td>\n",
       "      <td>0.623308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>line_id_asset_S3-L5</td>\n",
       "      <td>-0.583108</td>\n",
       "      <td>0.583108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>line_id_S3-L5</td>\n",
       "      <td>-0.583108</td>\n",
       "      <td>0.583108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>asset_type_asset_print_apply</td>\n",
       "      <td>0.548882</td>\n",
       "      <td>0.548882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>0.548882</td>\n",
       "      <td>0.548882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>line_id_asset_S2-L5</td>\n",
       "      <td>0.497916</td>\n",
       "      <td>0.497916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>0.497916</td>\n",
       "      <td>0.497916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>0.495229</td>\n",
       "      <td>0.495229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>line_id_asset_S1-L2</td>\n",
       "      <td>0.495229</td>\n",
       "      <td>0.495229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>line_id_asset_S3-L2</td>\n",
       "      <td>0.484668</td>\n",
       "      <td>0.484668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>line_id_S3-L2</td>\n",
       "      <td>0.484668</td>\n",
       "      <td>0.484668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>line_id_asset_S3-L1</td>\n",
       "      <td>0.479770</td>\n",
       "      <td>0.479770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>line_id_S3-L1</td>\n",
       "      <td>0.479770</td>\n",
       "      <td>0.479770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>-0.431755</td>\n",
       "      <td>0.431755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>line_id_asset_S4-L5</td>\n",
       "      <td>-0.431755</td>\n",
       "      <td>0.431755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>vendor_VendorB</td>\n",
       "      <td>-0.399185</td>\n",
       "      <td>0.399185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>vendor_asset_VendorB</td>\n",
       "      <td>-0.399185</td>\n",
       "      <td>0.399185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>line_id_asset_S3-L3</td>\n",
       "      <td>-0.398220</td>\n",
       "      <td>0.398220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>line_id_S3-L3</td>\n",
       "      <td>-0.398220</td>\n",
       "      <td>0.398220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature      coef  abs_coef\n",
       "62       asset_type_asset_capper  0.623308  0.623308\n",
       "22             asset_type_capper  0.623308  0.623308\n",
       "54           line_id_asset_S3-L5 -0.583108  0.583108\n",
       "14                 line_id_S3-L5 -0.583108  0.583108\n",
       "68  asset_type_asset_print_apply  0.548882  0.548882\n",
       "28        asset_type_print_apply  0.548882  0.548882\n",
       "49           line_id_asset_S2-L5  0.497916  0.497916\n",
       "9                  line_id_S2-L5  0.497916  0.497916\n",
       "1                  line_id_S1-L2  0.495229  0.495229\n",
       "41           line_id_asset_S1-L2  0.495229  0.495229\n",
       "51           line_id_asset_S3-L2  0.484668  0.484668\n",
       "11                 line_id_S3-L2  0.484668  0.484668\n",
       "50           line_id_asset_S3-L1  0.479770  0.479770\n",
       "10                 line_id_S3-L1  0.479770  0.479770\n",
       "19                 line_id_S4-L5 -0.431755  0.431755\n",
       "59           line_id_asset_S4-L5 -0.431755  0.431755\n",
       "33                vendor_VendorB -0.399185  0.399185\n",
       "73          vendor_asset_VendorB -0.399185  0.399185\n",
       "52           line_id_asset_S3-L3 -0.398220  0.398220\n",
       "12                 line_id_S3-L3 -0.398220  0.398220"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 no-leak features pushing toward target=1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>asset_type_asset_capper</td>\n",
       "      <td>0.623308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>asset_type_capper</td>\n",
       "      <td>0.623308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>asset_type_asset_print_apply</td>\n",
       "      <td>0.548882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>0.548882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>line_id_asset_S2-L5</td>\n",
       "      <td>0.497916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>0.497916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>line_id_asset_S1-L2</td>\n",
       "      <td>0.495229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>0.495229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>line_id_S3-L2</td>\n",
       "      <td>0.484668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>line_id_asset_S3-L2</td>\n",
       "      <td>0.484668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>line_id_asset_S3-L1</td>\n",
       "      <td>0.479770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>line_id_S3-L1</td>\n",
       "      <td>0.479770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>site_id_asset_S2</td>\n",
       "      <td>0.265003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tz_America/Los_Angeles</td>\n",
       "      <td>0.265003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>site_name_San Diego Device Assembly</td>\n",
       "      <td>0.265003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature      coef\n",
       "62              asset_type_asset_capper  0.623308\n",
       "22                    asset_type_capper  0.623308\n",
       "68         asset_type_asset_print_apply  0.548882\n",
       "28               asset_type_print_apply  0.548882\n",
       "49                  line_id_asset_S2-L5  0.497916\n",
       "9                         line_id_S2-L5  0.497916\n",
       "41                  line_id_asset_S1-L2  0.495229\n",
       "1                         line_id_S1-L2  0.495229\n",
       "11                        line_id_S3-L2  0.484668\n",
       "51                  line_id_asset_S3-L2  0.484668\n",
       "50                  line_id_asset_S3-L1  0.479770\n",
       "10                        line_id_S3-L1  0.479770\n",
       "37                     site_id_asset_S2  0.265003\n",
       "81               tz_America/Los_Angeles  0.265003\n",
       "78  site_name_San Diego Device Assembly  0.265003"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 no-leak features pushing toward target=0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>line_id_asset_S3-L5</td>\n",
       "      <td>-0.583108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>line_id_S3-L5</td>\n",
       "      <td>-0.583108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>line_id_asset_S4-L5</td>\n",
       "      <td>-0.431755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>-0.431755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>vendor_asset_VendorB</td>\n",
       "      <td>-0.399185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>vendor_VendorB</td>\n",
       "      <td>-0.399185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>line_id_asset_S3-L3</td>\n",
       "      <td>-0.398220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>line_id_S3-L3</td>\n",
       "      <td>-0.398220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>line_id_asset_S1-L4</td>\n",
       "      <td>-0.363845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>line_id_S1-L4</td>\n",
       "      <td>-0.363845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>asset_type_asset_labeler</td>\n",
       "      <td>-0.334487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>asset_type_labeler</td>\n",
       "      <td>-0.334487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>asset_type_asset_cartoner</td>\n",
       "      <td>-0.300557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>-0.300557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>site_name_Singapore Sterile Ops</td>\n",
       "      <td>-0.296914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature      coef\n",
       "54              line_id_asset_S3-L5 -0.583108\n",
       "14                    line_id_S3-L5 -0.583108\n",
       "59              line_id_asset_S4-L5 -0.431755\n",
       "19                    line_id_S4-L5 -0.431755\n",
       "73             vendor_asset_VendorB -0.399185\n",
       "33                   vendor_VendorB -0.399185\n",
       "52              line_id_asset_S3-L3 -0.398220\n",
       "12                    line_id_S3-L3 -0.398220\n",
       "43              line_id_asset_S1-L4 -0.363845\n",
       "3                     line_id_S1-L4 -0.363845\n",
       "67         asset_type_asset_labeler -0.334487\n",
       "27               asset_type_labeler -0.334487\n",
       "63        asset_type_asset_cartoner -0.300557\n",
       "23              asset_type_cartoner -0.300557\n",
       "79  site_name_Singapore Sterile Ops -0.296914"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_noleak_coefficients.csv\n",
      "\n",
      "Baseline comparison (leaky vs no-leak):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>leaky_baseline</th>\n",
       "      <th>no_leak_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.503497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  leaky_baseline  no_leak_baseline\n",
       "0   accuracy             1.0          0.541667\n",
       "1  precision             1.0          0.600000\n",
       "2     recall             1.0          0.461538\n",
       "3         f1             1.0          0.521739\n",
       "4    roc_auc             1.0          0.503497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_comparison_leak_vs_noleak.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 12 — Interpret no-leak baseline: coefficients + quick comparison to leaky baseline\n",
    "#============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load the no-leak feature names\n",
    "# -----------------------------\n",
    "feature_names_noleak = preprocess_noleak.get_feature_names_out().tolist()\n",
    "\n",
    "coefs_nl = clf_noleak.coef_.ravel()\n",
    "\n",
    "coef_nl_df = pd.DataFrame({\n",
    "    \"feature\": feature_names_noleak,\n",
    "    \"coef\": coefs_nl,\n",
    "    \"abs_coef\": np.abs(coefs_nl),\n",
    "}).sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "print(\"Top 20 no-leak features by absolute coefficient magnitude:\")\n",
    "display(coef_nl_df.head(20))\n",
    "\n",
    "print(\"\\nTop 15 no-leak features pushing toward target=1:\")\n",
    "display(coef_nl_df.sort_values(\"coef\", ascending=False).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "print(\"\\nTop 15 no-leak features pushing toward target=0:\")\n",
    "display(coef_nl_df.sort_values(\"coef\", ascending=True).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "# Save coefficients\n",
    "coef_nl_path = OUT_DIR / \"baseline_logreg_noleak_coefficients.csv\"\n",
    "coef_nl_df.to_csv(coef_nl_path, index=False)\n",
    "print(\"\\nSaved:\", coef_nl_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Compare metrics: leaky vs no-leak\n",
    "# -----------------------------\n",
    "leaky_metrics_path = OUT_DIR / \"baseline_logreg_metrics.json\"\n",
    "noleak_metrics_path = OUT_DIR / \"baseline_logreg_noleak_metrics.json\"\n",
    "\n",
    "def load_metrics(p: Path) -> dict:\n",
    "    return json.loads(p.read_text()) if p.exists() else {}\n",
    "\n",
    "m_leak = load_metrics(leaky_metrics_path)\n",
    "m_nl = load_metrics(noleak_metrics_path)\n",
    "\n",
    "compare_rows = []\n",
    "for k in [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]:\n",
    "    compare_rows.append({\n",
    "        \"metric\": k,\n",
    "        \"leaky_baseline\": m_leak.get(k),\n",
    "        \"no_leak_baseline\": m_nl.get(k),\n",
    "    })\n",
    "\n",
    "compare_df = pd.DataFrame(compare_rows)\n",
    "\n",
    "print(\"\\nBaseline comparison (leaky vs no-leak):\")\n",
    "display(compare_df)\n",
    "\n",
    "compare_path = OUT_DIR / \"baseline_comparison_leak_vs_noleak.csv\"\n",
    "compare_df.to_csv(compare_path, index=False)\n",
    "print(\"Saved:\", compare_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcecc49-47cc-46ad-a6c7-941c122cf871",
   "metadata": {},
   "source": [
    "### What Cell 12 Just Did\n",
    "\n",
    "This cell interpreted the leakage-safe (“no-leak”) baseline model and documented how it differs from the original leaky baseline. First, it extracted the transformed feature names from the no-leak preprocessing pipeline and paired them with the logistic regression coefficients. It then ranked features by absolute coefficient magnitude to highlight which remaining attributes are the strongest drivers of the proxy target when the label-defining columns are removed. Those coefficient tables were saved to `baseline_logreg_noleak_coefficients.csv` for easy reuse in reporting. Next, the cell loaded both metric files—`baseline_logreg_metrics.json` (leaky) and `baseline_logreg_noleak_metrics.json` (no-leak)—and assembled a side-by-side comparison table across accuracy, precision, recall, F1, and ROC AUC. Finally, it saved that comparison to `baseline_comparison_leak_vs_noleak.csv`, giving you a clear audit trail that explains why the original 1.000 scores were not trustworthy and what performance looks like after removing leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36b0299b-2cce-45e1-be0d-7f387beec751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iot_events shape: (588681, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>ts_utc</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>event_kind</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_unit</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>severity</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>message</th>\n",
       "      <th>ts_local</th>\n",
       "      <th>local_date</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>ts_local_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0000000001</td>\n",
       "      <td>2025-11-27 00:05:18.868743+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>telemetry</td>\n",
       "      <td>temp_c</td>\n",
       "      <td>C</td>\n",
       "      <td>29.490142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-26 19:05:18.868743-05:00</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-11-26 19:05:18 EST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0000000002</td>\n",
       "      <td>2025-11-27 00:05:18.868743+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>telemetry</td>\n",
       "      <td>humidity_rh</td>\n",
       "      <td>%</td>\n",
       "      <td>43.893886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-26 19:05:18.868743-05:00</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-11-26 19:05:18 EST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0000000003</td>\n",
       "      <td>2025-11-27 00:10:18.868743+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>telemetry</td>\n",
       "      <td>humidity_rh</td>\n",
       "      <td>%</td>\n",
       "      <td>50.181508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-26 19:10:18.868743-05:00</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-11-26 19:10:18 EST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0000000004</td>\n",
       "      <td>2025-11-27 00:15:18.868743+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>telemetry</td>\n",
       "      <td>reject_rate_pct</td>\n",
       "      <td>%</td>\n",
       "      <td>1.561515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-26 19:15:18.868743-05:00</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-11-26 19:15:18 EST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0000000005</td>\n",
       "      <td>2025-11-27 00:15:18.868743+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>telemetry</td>\n",
       "      <td>vibration_mm_s</td>\n",
       "      <td>mm/s</td>\n",
       "      <td>1.789262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-26 19:15:18.868743-05:00</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-11-26 19:15:18 EST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_id                           ts_utc site_id line_id asset_id  \\\n",
       "0  E0000000001 2025-11-27 00:05:18.868743+00:00      S1   S1-L2    A0001   \n",
       "1  E0000000002 2025-11-27 00:05:18.868743+00:00      S1   S1-L2    A0001   \n",
       "2  E0000000003 2025-11-27 00:10:18.868743+00:00      S1   S1-L2    A0001   \n",
       "3  E0000000004 2025-11-27 00:15:18.868743+00:00      S1   S1-L2    A0001   \n",
       "4  E0000000005 2025-11-27 00:15:18.868743+00:00      S1   S1-L2    A0001   \n",
       "\n",
       "       asset_type  is_legacy event_kind      metric_name metric_unit  \\\n",
       "0  blister_packer      False  telemetry           temp_c           C   \n",
       "1  blister_packer      False  telemetry      humidity_rh           %   \n",
       "2  blister_packer      False  telemetry      humidity_rh           %   \n",
       "3  blister_packer      False  telemetry  reject_rate_pct           %   \n",
       "4  blister_packer      False  telemetry   vibration_mm_s        mm/s   \n",
       "\n",
       "   metric_value  severity incident_type message  \\\n",
       "0     29.490142       NaN          None    None   \n",
       "1     43.893886       NaN          None    None   \n",
       "2     50.181508       NaN          None    None   \n",
       "3      1.561515       NaN          None    None   \n",
       "4      1.789262       NaN          None    None   \n",
       "\n",
       "                          ts_local  local_date  local_hour  \\\n",
       "0 2025-11-26 19:05:18.868743-05:00  2025-11-26          19   \n",
       "1 2025-11-26 19:05:18.868743-05:00  2025-11-26          19   \n",
       "2 2025-11-26 19:10:18.868743-05:00  2025-11-26          19   \n",
       "3 2025-11-26 19:15:18.868743-05:00  2025-11-26          19   \n",
       "4 2025-11-26 19:15:18.868743-05:00  2025-11-26          19   \n",
       "\n",
       "              ts_local_str  \n",
       "0  2025-11-26 19:05:18 EST  \n",
       "1  2025-11-26 19:05:18 EST  \n",
       "2  2025-11-26 19:10:18 EST  \n",
       "3  2025-11-26 19:15:18 EST  \n",
       "4  2025-11-26 19:15:18 EST  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected columns:\n",
      "  asset: asset_id\n",
      "  ts   : None\n",
      "  type : None\n",
      "  value: metric_value\n",
      "  sev  : severity\n",
      "\n",
      "Aggregates per asset_id:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>event_count</th>\n",
       "      <th>severity_mean</th>\n",
       "      <th>severity_max</th>\n",
       "      <th>value_mean</th>\n",
       "      <th>value_std</th>\n",
       "      <th>value_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>8006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.877219</td>\n",
       "      <td>76.434873</td>\n",
       "      <td>287.054630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>2419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.946323</td>\n",
       "      <td>76.050874</td>\n",
       "      <td>273.747021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>2505</td>\n",
       "      <td>2.712840</td>\n",
       "      <td>3.698664</td>\n",
       "      <td>64.837749</td>\n",
       "      <td>77.246431</td>\n",
       "      <td>305.024304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>2520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.875996</td>\n",
       "      <td>98.571559</td>\n",
       "      <td>375.143159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>2503</td>\n",
       "      <td>3.309361</td>\n",
       "      <td>4.803082</td>\n",
       "      <td>68.436679</td>\n",
       "      <td>77.827009</td>\n",
       "      <td>297.961037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0006</td>\n",
       "      <td>2537</td>\n",
       "      <td>3.006059</td>\n",
       "      <td>3.403290</td>\n",
       "      <td>66.424449</td>\n",
       "      <td>77.451523</td>\n",
       "      <td>325.290628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0007</td>\n",
       "      <td>2413</td>\n",
       "      <td>2.425788</td>\n",
       "      <td>2.811133</td>\n",
       "      <td>67.970847</td>\n",
       "      <td>78.023360</td>\n",
       "      <td>295.162197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0008</td>\n",
       "      <td>8007</td>\n",
       "      <td>2.930029</td>\n",
       "      <td>2.930029</td>\n",
       "      <td>68.466277</td>\n",
       "      <td>76.112597</td>\n",
       "      <td>276.964144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0009</td>\n",
       "      <td>2408</td>\n",
       "      <td>2.661444</td>\n",
       "      <td>2.914285</td>\n",
       "      <td>79.691943</td>\n",
       "      <td>97.993319</td>\n",
       "      <td>374.457264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0010</td>\n",
       "      <td>2467</td>\n",
       "      <td>2.488037</td>\n",
       "      <td>3.416626</td>\n",
       "      <td>64.451269</td>\n",
       "      <td>75.722211</td>\n",
       "      <td>290.799053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id  event_count  severity_mean  severity_max  value_mean  value_std  \\\n",
       "0    A0001         8006            NaN           NaN   66.877219  76.434873   \n",
       "1    A0002         2419            NaN           NaN   65.946323  76.050874   \n",
       "2    A0003         2505       2.712840      3.698664   64.837749  77.246431   \n",
       "3    A0004         2520            NaN           NaN   79.875996  98.571559   \n",
       "4    A0005         2503       3.309361      4.803082   68.436679  77.827009   \n",
       "5    A0006         2537       3.006059      3.403290   66.424449  77.451523   \n",
       "6    A0007         2413       2.425788      2.811133   67.970847  78.023360   \n",
       "7    A0008         8007       2.930029      2.930029   68.466277  76.112597   \n",
       "8    A0009         2408       2.661444      2.914285   79.691943  97.993319   \n",
       "9    A0010         2467       2.488037      3.416626   64.451269  75.722211   \n",
       "\n",
       "    value_max  \n",
       "0  287.054630  \n",
       "1  273.747021  \n",
       "2  305.024304  \n",
       "3  375.143159  \n",
       "4  297.961037  \n",
       "5  325.290628  \n",
       "6  295.162197  \n",
       "7  276.964144  \n",
       "8  374.457264  \n",
       "9  290.799053  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/iot_event_aggregates_by_asset.csv\n",
      "\n",
      "Event-derived target distribution:\n",
      "target_event\n",
      "1    65\n",
      "0    55\n",
      "Name: count, dtype: int64\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/iot_event_labels_by_asset.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 13 — (Optional but recommended) Prepare a “real-label” path using iot_events.parquet\n",
    "#   Goal: aggregate event signals per asset_id over a time window, then label assets as risky\n",
    "#============================================================\n",
    "\n",
    "# If you have iot events (you do: data/raw/iot_events.parquet), this cell builds a candidate\n",
    "# event-derived labeling table that we can later refine (thresholds, specific event types, etc.).\n",
    "#\n",
    "# We DO NOT assume exact schema; we auto-detect likely columns and proceed conservatively.\n",
    "\n",
    "iot_path = RAW_DIR / \"iot_events.parquet\"\n",
    "if not iot_path.exists():\n",
    "    raise FileNotFoundError(f\"Expected iot events at: {iot_path}\")\n",
    "\n",
    "iot = pd.read_parquet(iot_path)\n",
    "print(\"iot_events shape:\", iot.shape)\n",
    "display(iot.head(5))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Detect key columns (asset_id + timestamp + event/value/type)\n",
    "# -----------------------------\n",
    "iot_asset_col = find_col(iot.columns.tolist(), [\"asset_id\", \"assetid\", \"device_id\", \"equipment_id\", \"asset\"])\n",
    "iot_ts_col = find_col(iot.columns.tolist(), [\"event_ts\", \"timestamp\", \"ts\", \"time\", \"datetime\", \"created_at\", \"received_at\"])\n",
    "iot_type_col = find_col(iot.columns.tolist(), [\"event_type\", \"type\", \"signal\", \"tag\", \"metric\", \"name\", \"code\"])\n",
    "iot_value_col = find_col(iot.columns.tolist(), [\"value\", \"reading\", \"val\", \"measurement\", \"metric_value\"])\n",
    "iot_sev_col = find_col(iot.columns.tolist(), [\"severity\", \"sev\", \"level\", \"priority\"])\n",
    "\n",
    "print(\"\\nDetected columns:\")\n",
    "print(\"  asset:\", iot_asset_col)\n",
    "print(\"  ts   :\", iot_ts_col)\n",
    "print(\"  type :\", iot_type_col)\n",
    "print(\"  value:\", iot_value_col)\n",
    "print(\"  sev  :\", iot_sev_col)\n",
    "\n",
    "if iot_asset_col is None:\n",
    "    raise KeyError(\"Could not detect an asset/device id column in iot_events.parquet\")\n",
    "\n",
    "iot = iot.rename(columns={iot_asset_col: \"asset_id\"})\n",
    "iot[\"asset_id\"] = iot[\"asset_id\"].astype(str).str.strip()\n",
    "\n",
    "# Timestamp is optional (but strongly preferred for time-windowed features)\n",
    "if iot_ts_col is not None:\n",
    "    iot = iot.rename(columns={iot_ts_col: \"event_ts\"})\n",
    "    iot[\"event_ts\"] = pd.to_datetime(iot[\"event_ts\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "# Normalize optional columns\n",
    "if iot_type_col is not None and iot_type_col != \"event_type\":\n",
    "    iot = iot.rename(columns={iot_type_col: \"event_type\"})\n",
    "if iot_value_col is not None and iot_value_col != \"value\":\n",
    "    iot = iot.rename(columns={iot_value_col: \"value\"})\n",
    "if iot_sev_col is not None and iot_sev_col != \"severity\":\n",
    "    iot = iot.rename(columns={iot_sev_col: \"severity\"})\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build event-derived aggregates per asset_id\n",
    "# -----------------------------\n",
    "agg = pd.DataFrame({\"asset_id\": sorted(iot[\"asset_id\"].unique())}).set_index(\"asset_id\")\n",
    "\n",
    "# Count events\n",
    "agg[\"event_count\"] = iot.groupby(\"asset_id\").size()\n",
    "\n",
    "# Event type cardinality (if present)\n",
    "if \"event_type\" in iot.columns:\n",
    "    agg[\"event_type_nunique\"] = iot.groupby(\"asset_id\")[\"event_type\"].nunique(dropna=True)\n",
    "\n",
    "# Severity stats (if present + numeric-ish)\n",
    "if \"severity\" in iot.columns:\n",
    "    sev_num = pd.to_numeric(iot[\"severity\"], errors=\"coerce\")\n",
    "    agg[\"severity_mean\"] = sev_num.groupby(iot[\"asset_id\"]).mean()\n",
    "    agg[\"severity_max\"] = sev_num.groupby(iot[\"asset_id\"]).max()\n",
    "\n",
    "# Value stats (if present + numeric-ish)\n",
    "if \"value\" in iot.columns:\n",
    "    val_num = pd.to_numeric(iot[\"value\"], errors=\"coerce\")\n",
    "    agg[\"value_mean\"] = val_num.groupby(iot[\"asset_id\"]).mean()\n",
    "    agg[\"value_std\"] = val_num.groupby(iot[\"asset_id\"]).std()\n",
    "    agg[\"value_max\"] = val_num.groupby(iot[\"asset_id\"]).max()\n",
    "\n",
    "# Time coverage (if timestamps present)\n",
    "if \"event_ts\" in iot.columns:\n",
    "    agg[\"first_event_ts\"] = iot.groupby(\"asset_id\")[\"event_ts\"].min()\n",
    "    agg[\"last_event_ts\"] = iot.groupby(\"asset_id\")[\"event_ts\"].max()\n",
    "    agg[\"active_days\"] = (agg[\"last_event_ts\"] - agg[\"first_event_ts\"]).dt.days\n",
    "\n",
    "agg = agg.reset_index()\n",
    "\n",
    "print(\"\\nAggregates per asset_id:\")\n",
    "display(agg.head(10))\n",
    "\n",
    "agg_path = OUT_DIR / \"iot_event_aggregates_by_asset.csv\"\n",
    "agg.to_csv(agg_path, index=False)\n",
    "print(\"Saved:\", agg_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Create a first-pass *event-derived* label (placeholder thresholds)\n",
    "# -----------------------------\n",
    "# This is intentionally conservative: we can refine thresholds once we inspect distributions.\n",
    "# Example rule:\n",
    "#   target_event = 1 if event_count is in the top quartile OR severity_max above median (if present)\n",
    "#\n",
    "# If you want a different rule (e.g., \"any alarms\" or \"any deviations\"), we can tailor it after inspecting schema.\n",
    "\n",
    "target_event = pd.Series(0, index=agg.index, dtype=\"int8\")\n",
    "\n",
    "# event_count quantile rule\n",
    "q75 = agg[\"event_count\"].quantile(0.75)\n",
    "target_event = (agg[\"event_count\"] >= q75).astype(\"int8\")\n",
    "\n",
    "# severity rule (if available)\n",
    "if \"severity_max\" in agg.columns and agg[\"severity_max\"].notna().any():\n",
    "    sev_med = agg[\"severity_max\"].median()\n",
    "    target_event = ((target_event == 1) | (agg[\"severity_max\"] >= sev_med)).astype(\"int8\")\n",
    "\n",
    "agg[\"target_event\"] = target_event\n",
    "\n",
    "print(\"\\nEvent-derived target distribution:\")\n",
    "print(agg[\"target_event\"].value_counts(dropna=False))\n",
    "\n",
    "label_event_path = OUT_DIR / \"iot_event_labels_by_asset.csv\"\n",
    "agg[[\"asset_id\", \"target_event\"]].to_csv(label_event_path, index=False)\n",
    "print(\"Saved:\", label_event_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae27ea5-197c-41e6-9a2d-dfc1caaa0337",
   "metadata": {},
   "source": [
    "### What Cell 13 Just Did\n",
    "\n",
    "This cell opened the door to a more “real” labeling strategy by leveraging `data/raw/iot_events.parquet` instead of relying solely on the proxy label derived from master attributes. It loaded the IoT event table and automatically detected key columns such as an asset/device identifier, an event timestamp (if available), an event type/name field, an event value/reading field, and an optional severity/priority field. Using those fields, it created a compact set of event-derived aggregates per `asset_id` (event counts, event-type diversity, basic severity/value statistics, and time coverage when timestamps exist). It saved these aggregates to `iot_event_aggregates_by_asset.csv` for inspection and reuse. Finally, it generated a first-pass event-derived binary label (`target_event`) using conservative placeholder thresholds (e.g., high event volume and/or high severity) and saved that mapping to `iot_event_labels_by_asset.csv`. This gives us a concrete starting point for refining a production-quality label definition based on the actual IoT schema and distributional behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "409a9f12-d66b-497d-8df4-14c50835eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined IoT aggregates. Added: ['event_count', 'severity_max', 'severity_mean', 'value_max', 'value_mean', 'value_std']\n",
      "Shape after joins: (120, 22)\n",
      "Dropped 0 row(s) with missing target_event. Remaining: 120\n",
      "\n",
      "Event-derived label distribution (target_event):\n",
      "target_event\n",
      "1    65\n",
      "0    55\n",
      "Name: count, dtype: int64\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/event_derived_model_table.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>vendor</th>\n",
       "      <th>site_id_asset</th>\n",
       "      <th>line_id_asset</th>\n",
       "      <th>asset_type_asset</th>\n",
       "      <th>...</th>\n",
       "      <th>vendor_asset</th>\n",
       "      <th>site_name</th>\n",
       "      <th>tz</th>\n",
       "      <th>event_count</th>\n",
       "      <th>severity_mean</th>\n",
       "      <th>severity_max</th>\n",
       "      <th>value_mean</th>\n",
       "      <th>value_std</th>\n",
       "      <th>value_max</th>\n",
       "      <th>target_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>...</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>8006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.877219</td>\n",
       "      <td>76.434873</td>\n",
       "      <td>287.054630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>...</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>2419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.946323</td>\n",
       "      <td>76.050874</td>\n",
       "      <td>273.747021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>...</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>2505</td>\n",
       "      <td>2.712840</td>\n",
       "      <td>3.698664</td>\n",
       "      <td>64.837749</td>\n",
       "      <td>77.246431</td>\n",
       "      <td>305.024304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>...</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>2520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.875996</td>\n",
       "      <td>98.571559</td>\n",
       "      <td>375.143159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>...</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>2503</td>\n",
       "      <td>3.309361</td>\n",
       "      <td>4.803082</td>\n",
       "      <td>68.436679</td>\n",
       "      <td>77.827009</td>\n",
       "      <td>297.961037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id site_id line_id             asset_type  is_legacy   connectivity  \\\n",
       "0    A0001      S1   S1-L2         blister_packer      False     mqtt_opcua   \n",
       "1    A0002      S2   S2-L5            print_apply       True  legacy_serial   \n",
       "2    A0003      S4   S4-L2         blister_packer       True  legacy_serial   \n",
       "3    A0004      S1   S1-L2             sterilizer       True  legacy_serial   \n",
       "4    A0005      S4   S4-L2  environmental_monitor       True  legacy_serial   \n",
       "\n",
       "    vendor site_id_asset line_id_asset       asset_type_asset  ...  \\\n",
       "0  VendorB            S1         S1-L2         blister_packer  ...   \n",
       "1  VendorA            S2         S2-L5            print_apply  ...   \n",
       "2  VendorB            S4         S4-L2         blister_packer  ...   \n",
       "3  VendorD            S1         S1-L2             sterilizer  ...   \n",
       "4  VendorA            S4         S4-L2  environmental_monitor  ...   \n",
       "\n",
       "   vendor_asset                     site_name                            tz  \\\n",
       "0       VendorB  Indianapolis Packaging Plant  America/Indiana/Indianapolis   \n",
       "1       VendorA     San Diego Device Assembly           America/Los_Angeles   \n",
       "2       VendorB         Singapore Sterile Ops                Asia/Singapore   \n",
       "3       VendorD  Indianapolis Packaging Plant  America/Indiana/Indianapolis   \n",
       "4       VendorA         Singapore Sterile Ops                Asia/Singapore   \n",
       "\n",
       "  event_count severity_mean  severity_max  value_mean  value_std   value_max  \\\n",
       "0        8006           NaN           NaN   66.877219  76.434873  287.054630   \n",
       "1        2419           NaN           NaN   65.946323  76.050874  273.747021   \n",
       "2        2505      2.712840      3.698664   64.837749  77.246431  305.024304   \n",
       "3        2520           NaN           NaN   79.875996  98.571559  375.143159   \n",
       "4        2503      3.309361      4.803082   68.436679  77.827009  297.961037   \n",
       "\n",
       "   target_event  \n",
       "0             1  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 14 — Build an event-derived modeling table (asset master + IoT aggregates + event-derived label)\n",
    "#============================================================\n",
    "\n",
    "# We will:\n",
    "# 1) Load the asset-level aggregates computed in Cell 13\n",
    "# 2) Join them to the master/enrichment table from Cell 3 (df)\n",
    "# 3) Use target_event as the “real” label for a second modeling pass\n",
    "\n",
    "agg_path = OUT_DIR / \"iot_event_aggregates_by_asset.csv\"\n",
    "labels_path = OUT_DIR / \"iot_event_labels_by_asset.csv\"\n",
    "\n",
    "agg = pd.read_csv(agg_path)\n",
    "labels = pd.read_csv(labels_path)\n",
    "\n",
    "# Ensure clean keys\n",
    "agg[\"asset_id\"] = agg[\"asset_id\"].astype(str).str.strip()\n",
    "labels[\"asset_id\"] = labels[\"asset_id\"].astype(str).str.strip()\n",
    "\n",
    "# Start from your enriched master table (df) and join aggregates\n",
    "event_model_df = df.copy()\n",
    "event_model_df[\"asset_id\"] = event_model_df[\"asset_id\"].astype(str).str.strip()\n",
    "\n",
    "# Join event aggregates (left join keeps all master assets)\n",
    "before_cols = set(event_model_df.columns)\n",
    "event_model_df = event_model_df.merge(agg, how=\"left\", on=\"asset_id\", suffixes=(\"\", \"_iot\"))\n",
    "added_agg = sorted(list(set(event_model_df.columns) - before_cols))\n",
    "\n",
    "# Join event-derived labels (target_event)\n",
    "event_model_df = event_model_df.merge(labels, how=\"left\", on=\"asset_id\")\n",
    "\n",
    "print(\"Joined IoT aggregates. Added:\", added_agg)\n",
    "print(\"Shape after joins:\", event_model_df.shape)\n",
    "\n",
    "# Drop assets with missing event label (if any)\n",
    "before = len(event_model_df)\n",
    "event_model_df = event_model_df.dropna(subset=[\"target_event\"]).copy()\n",
    "after = len(event_model_df)\n",
    "print(f\"Dropped {before - after} row(s) with missing target_event. Remaining: {after}\")\n",
    "\n",
    "# Coerce label\n",
    "event_model_df[\"target_event\"] = pd.to_numeric(event_model_df[\"target_event\"], errors=\"coerce\").astype(\"int8\")\n",
    "\n",
    "print(\"\\nEvent-derived label distribution (target_event):\")\n",
    "print(event_model_df[\"target_event\"].value_counts(dropna=False))\n",
    "\n",
    "# Persist the event-derived modeling table\n",
    "event_model_path = OUT_DIR / \"event_derived_model_table.parquet\"\n",
    "event_model_df.to_parquet(event_model_path, index=False)\n",
    "print(\"Saved:\", event_model_path)\n",
    "\n",
    "display(event_model_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9e539-9224-4d09-b5c9-2b21f8d7bd55",
   "metadata": {},
   "source": [
    "### What Cell 14 Just Did\n",
    "\n",
    "This cell created a second, more defensible modeling dataset by combining asset master attributes with event-derived signals from the IoT data. It loaded the per-asset IoT aggregates (`iot_event_aggregates_by_asset.csv`) and the event-derived binary labels (`iot_event_labels_by_asset.csv`) produced in the previous cell. It then joined those aggregates to the enriched master table from Cell 3 using `asset_id` as the key, adding features such as event volume and value/severity statistics. Next, it joined the event-derived label (`target_event`) and removed any rows where the label was missing, ensuring the table is ready for supervised learning. Finally, it saved the resulting merged dataset to `event_derived_model_table.parquet` in the run output directory, giving you a clean, asset-level modeling table that reflects operational behavior captured in the IoT event stream.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86002204-c7ee-4d7b-9e31-5cf753ff2802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID columns excluded: ['asset_id', 'site_id']\n",
      "Numeric feature columns: ['is_legacy', 'is_legacy_asset', 'event_count', 'severity_mean', 'severity_max', 'value_mean', 'value_std', 'value_max']\n",
      "Categorical feature columns: ['line_id', 'asset_type', 'connectivity', 'vendor', 'site_id_asset', 'line_id_asset', 'asset_type_asset', 'connectivity_asset', 'vendor_asset', 'site_name', 'tz']\n",
      "\n",
      "Split shapes:\n",
      "  X_train: (96, 19) | y_train: (96,) | pos_rate: 0.5416666666666666\n",
      "  X_test : (24, 19) | y_test : (24,) | pos_rate: 0.5416666666666666\n",
      "\n",
      "Transformed shapes:\n",
      "  X_train_tx: (96, 96)\n",
      "  X_test_tx : (24, 96)\n",
      "  # features: 96\n",
      "\n",
      "Event-derived baseline: Logistic Regression\n",
      "  Accuracy : 0.792\n",
      "  Precision: 0.833\n",
      "  Recall   : 0.769\n",
      "  F1       : 0.800\n",
      "  ROC AUC  : 0.944\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[ 9  2]\n",
      " [ 3 10]]\n",
      "\n",
      "Saved:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/preprocess_event.joblib\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_event.joblib\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_event_metrics.json\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/feature_names_event.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 15 — Event-derived modeling pass: features, split, preprocess, baseline + metrics\n",
    "#============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Define target + exclude IDs\n",
    "# -----------------------------\n",
    "event_df = event_model_df.copy()\n",
    "\n",
    "target_col = \"target_event\"\n",
    "if target_col not in event_df.columns:\n",
    "    raise KeyError(f\"Expected '{target_col}' in event_model_df\")\n",
    "\n",
    "# ID columns to exclude from features\n",
    "id_like = [\"asset_id\", \"site_id\", \"event_id\", \"id\", \"uuid\"]\n",
    "id_cols_evt = [c for c in id_like if c in event_df.columns]\n",
    "\n",
    "exclude_evt = set(id_cols_evt + [target_col])\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Detect numeric vs categorical features\n",
    "# -----------------------------\n",
    "numeric_cols_evt = [\n",
    "    c for c in event_df.columns\n",
    "    if c not in exclude_evt and pd.api.types.is_numeric_dtype(event_df[c])\n",
    "]\n",
    "\n",
    "categorical_cols_evt = [\n",
    "    c for c in event_df.columns\n",
    "    if c not in exclude_evt and not pd.api.types.is_numeric_dtype(event_df[c])\n",
    "]\n",
    "\n",
    "print(\"ID columns excluded:\", id_cols_evt)\n",
    "print(\"Numeric feature columns:\", numeric_cols_evt)\n",
    "print(\"Categorical feature columns:\", categorical_cols_evt)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Build X/y and split (stratified)\n",
    "# -----------------------------\n",
    "X_evt = event_df[numeric_cols_evt + categorical_cols_evt].copy()\n",
    "y_evt = event_df[target_col].astype(\"int8\").copy()\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_evt, y_evt,\n",
    "    test_size=0.20,\n",
    "    random_state=SEED,\n",
    "    stratify=y_evt if y_evt.nunique() > 1 else None\n",
    ")\n",
    "\n",
    "print(\"\\nSplit shapes:\")\n",
    "print(\"  X_train:\", Xtr.shape, \"| y_train:\", ytr.shape, \"| pos_rate:\", float(ytr.mean()))\n",
    "print(\"  X_test :\", Xte.shape, \"| y_test :\", yte.shape, \"| pos_rate:\", float(yte.mean()))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Preprocess (impute/scale + one-hot)\n",
    "# -----------------------------\n",
    "num_tx = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "cat_tx = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "])\n",
    "\n",
    "preprocess_evt = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_tx, numeric_cols_evt),\n",
    "        (\"cat\", cat_tx, categorical_cols_evt),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "preprocess_evt.fit(Xtr)\n",
    "Xtr_tx = preprocess_evt.transform(Xtr)\n",
    "Xte_tx = preprocess_evt.transform(Xte)\n",
    "\n",
    "feat_evt = preprocess_evt.get_feature_names_out().tolist()\n",
    "\n",
    "print(\"\\nTransformed shapes:\")\n",
    "print(\"  X_train_tx:\", Xtr_tx.shape)\n",
    "print(\"  X_test_tx :\", Xte_tx.shape)\n",
    "print(\"  # features:\", len(feat_evt))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Baseline model\n",
    "# -----------------------------\n",
    "clf_evt = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"lbfgs\",\n",
    ")\n",
    "\n",
    "clf_evt.fit(Xtr_tx, ytr)\n",
    "yp = clf_evt.predict(Xte_tx)\n",
    "\n",
    "acc = accuracy_score(yte, yp)\n",
    "prec = precision_score(yte, yp, zero_division=0)\n",
    "rec = recall_score(yte, yp, zero_division=0)\n",
    "f1 = f1_score(yte, yp, zero_division=0)\n",
    "\n",
    "if ytr.nunique() == 2:\n",
    "    yproba = clf_evt.predict_proba(Xte_tx)[:, 1]\n",
    "    auc = roc_auc_score(yte, yproba)\n",
    "else:\n",
    "    auc = np.nan\n",
    "\n",
    "print(\"\\nEvent-derived baseline: Logistic Regression\")\n",
    "print(f\"  Accuracy : {acc:.3f}\")\n",
    "print(f\"  Precision: {prec:.3f}\")\n",
    "print(f\"  Recall   : {rec:.3f}\")\n",
    "print(f\"  F1       : {f1:.3f}\")\n",
    "print(f\"  ROC AUC  : {auc:.3f}\" if not np.isnan(auc) else \"  ROC AUC  : n/a (single-class train)\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "print(confusion_matrix(yte, yp))\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Persist artifacts\n",
    "# -----------------------------\n",
    "# Store under the same run directory, with an \"event_\" prefix to distinguish\n",
    "joblib.dump(preprocess_evt, OUT_DIR / \"preprocess_event.joblib\")\n",
    "joblib.dump(clf_evt, OUT_DIR / \"baseline_logreg_event.joblib\")\n",
    "\n",
    "pd.Series(feat_evt, name=\"feature_name\").to_csv(OUT_DIR / \"feature_names_event.csv\", index=False)\n",
    "\n",
    "with open(OUT_DIR / \"baseline_logreg_event_metrics.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"model\": \"LogisticRegression(class_weight=balanced, solver=lbfgs, max_iter=2000)\",\n",
    "            \"accuracy\": float(acc),\n",
    "            \"precision\": float(prec),\n",
    "            \"recall\": float(rec),\n",
    "            \"f1\": float(f1),\n",
    "            \"roc_auc\": float(auc) if not np.isnan(auc) else None,\n",
    "            \"n_features_raw\": int(X_evt.shape[1]),\n",
    "            \"n_features_transformed\": int(len(feat_evt)),\n",
    "            \"target_col\": target_col,\n",
    "            \"id_cols_excluded\": id_cols_evt,\n",
    "            \"numeric_cols\": numeric_cols_evt,\n",
    "            \"categorical_cols\": categorical_cols_evt,\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", OUT_DIR / \"preprocess_event.joblib\")\n",
    "print(\" \", OUT_DIR / \"baseline_logreg_event.joblib\")\n",
    "print(\" \", OUT_DIR / \"baseline_logreg_event_metrics.json\")\n",
    "print(\" \", OUT_DIR / \"feature_names_event.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e01781-554b-4374-a03e-f225cf362d7b",
   "metadata": {},
   "source": [
    "### What Cell 15 Just Did\n",
    "\n",
    "This cell ran a second end-to-end modeling pass using the event-derived label (`target_event`) and the combined feature set (asset master attributes plus IoT aggregate signals). It identified and excluded ID-like columns from the feature matrix, split the remaining columns into numeric and categorical features, and built `X`/`y` for supervised learning. It then performed a stratified train/test split to preserve class balance. Next, it fit a preprocessing pipeline that imputes and scales numeric features while imputing and one-hot encoding categorical features, producing transformed arrays for modeling. Using those transformed arrays, it trained a balanced logistic regression baseline and evaluated it on the held-out test set with accuracy, precision, recall, F1, and ROC AUC (when applicable), along with a confusion matrix for interpretability. Finally, it saved the fitted event-specific preprocessor, model, metrics, and feature-name list into the run output directory with an `event_` prefix so the artifacts are clearly separated from the earlier proxy-label baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83cb67c4-14f3-41de-9055-2e261e168baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 event-derived features by absolute coefficient magnitude:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>severity_max</td>\n",
       "      <td>1.543977</td>\n",
       "      <td>1.543977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>line_id_asset_S2-L5</td>\n",
       "      <td>-0.745801</td>\n",
       "      <td>0.745801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-0.745801</td>\n",
       "      <td>0.745801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>severity_mean</td>\n",
       "      <td>0.476273</td>\n",
       "      <td>0.476273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>line_id_asset_S4-L2</td>\n",
       "      <td>-0.459409</td>\n",
       "      <td>0.459409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>line_id_S4-L2</td>\n",
       "      <td>-0.459409</td>\n",
       "      <td>0.459409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-0.458345</td>\n",
       "      <td>0.458345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>line_id_asset_S1-L2</td>\n",
       "      <td>-0.458345</td>\n",
       "      <td>0.458345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>0.451786</td>\n",
       "      <td>0.451786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>asset_type_asset_cartoner</td>\n",
       "      <td>0.451786</td>\n",
       "      <td>0.451786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-0.431781</td>\n",
       "      <td>0.431781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>asset_type_asset_print_apply</td>\n",
       "      <td>-0.431781</td>\n",
       "      <td>0.431781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>line_id_asset_S1-L1</td>\n",
       "      <td>0.388065</td>\n",
       "      <td>0.388065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>line_id_S1-L1</td>\n",
       "      <td>0.388065</td>\n",
       "      <td>0.388065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>line_id_asset_S2-L1</td>\n",
       "      <td>0.363094</td>\n",
       "      <td>0.363094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>line_id_S2-L1</td>\n",
       "      <td>0.363094</td>\n",
       "      <td>0.363094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>line_id_asset_S2-L2</td>\n",
       "      <td>0.358479</td>\n",
       "      <td>0.358479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>line_id_S2-L2</td>\n",
       "      <td>0.358479</td>\n",
       "      <td>0.358479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>event_count</td>\n",
       "      <td>0.317097</td>\n",
       "      <td>0.317097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>asset_type_asset_weigh_check</td>\n",
       "      <td>-0.295209</td>\n",
       "      <td>0.295209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>asset_type_weigh_check</td>\n",
       "      <td>-0.295209</td>\n",
       "      <td>0.295209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>asset_type_bottle_filler</td>\n",
       "      <td>-0.281783</td>\n",
       "      <td>0.281783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>asset_type_asset_bottle_filler</td>\n",
       "      <td>-0.281783</td>\n",
       "      <td>0.281783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>line_id_S4-L3</td>\n",
       "      <td>0.279103</td>\n",
       "      <td>0.279103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>line_id_asset_S4-L3</td>\n",
       "      <td>0.279103</td>\n",
       "      <td>0.279103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature      coef  abs_coef\n",
       "4                     severity_max  1.543977  1.543977\n",
       "59             line_id_asset_S2-L5 -0.745801  0.745801\n",
       "17                   line_id_S2-L5 -0.745801  0.745801\n",
       "3                    severity_mean  0.476273  0.476273\n",
       "66             line_id_asset_S4-L2 -0.459409  0.459409\n",
       "24                   line_id_S4-L2 -0.459409  0.459409\n",
       "9                    line_id_S1-L2 -0.458345  0.458345\n",
       "51             line_id_asset_S1-L2 -0.458345  0.458345\n",
       "31             asset_type_cartoner  0.451786  0.451786\n",
       "73       asset_type_asset_cartoner  0.451786  0.451786\n",
       "36          asset_type_print_apply -0.431781  0.431781\n",
       "78    asset_type_asset_print_apply -0.431781  0.431781\n",
       "50             line_id_asset_S1-L1  0.388065  0.388065\n",
       "8                    line_id_S1-L1  0.388065  0.388065\n",
       "55             line_id_asset_S2-L1  0.363094  0.363094\n",
       "13                   line_id_S2-L1  0.363094  0.363094\n",
       "56             line_id_asset_S2-L2  0.358479  0.358479\n",
       "14                   line_id_S2-L2  0.358479  0.358479\n",
       "2                      event_count  0.317097  0.317097\n",
       "81    asset_type_asset_weigh_check -0.295209  0.295209\n",
       "39          asset_type_weigh_check -0.295209  0.295209\n",
       "29        asset_type_bottle_filler -0.281783  0.281783\n",
       "71  asset_type_asset_bottle_filler -0.281783  0.281783\n",
       "25                   line_id_S4-L3  0.279103  0.279103\n",
       "67             line_id_asset_S4-L3  0.279103  0.279103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features pushing toward target_event=1 (higher event-derived risk):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>severity_max</td>\n",
       "      <td>1.543977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>severity_mean</td>\n",
       "      <td>0.476273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>0.451786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>asset_type_asset_cartoner</td>\n",
       "      <td>0.451786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>line_id_S1-L1</td>\n",
       "      <td>0.388065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>line_id_asset_S1-L1</td>\n",
       "      <td>0.388065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>line_id_S2-L1</td>\n",
       "      <td>0.363094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>line_id_asset_S2-L1</td>\n",
       "      <td>0.363094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>line_id_asset_S2-L2</td>\n",
       "      <td>0.358479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>line_id_S2-L2</td>\n",
       "      <td>0.358479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>event_count</td>\n",
       "      <td>0.317097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>line_id_asset_S4-L3</td>\n",
       "      <td>0.279103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>line_id_S4-L3</td>\n",
       "      <td>0.279103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>asset_type_blister_packer</td>\n",
       "      <td>0.266611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>asset_type_asset_blister_packer</td>\n",
       "      <td>0.266611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature      coef\n",
       "4                      severity_max  1.543977\n",
       "3                     severity_mean  0.476273\n",
       "31              asset_type_cartoner  0.451786\n",
       "73        asset_type_asset_cartoner  0.451786\n",
       "8                     line_id_S1-L1  0.388065\n",
       "50              line_id_asset_S1-L1  0.388065\n",
       "13                    line_id_S2-L1  0.363094\n",
       "55              line_id_asset_S2-L1  0.363094\n",
       "56              line_id_asset_S2-L2  0.358479\n",
       "14                    line_id_S2-L2  0.358479\n",
       "2                       event_count  0.317097\n",
       "67              line_id_asset_S4-L3  0.279103\n",
       "25                    line_id_S4-L3  0.279103\n",
       "28        asset_type_blister_packer  0.266611\n",
       "70  asset_type_asset_blister_packer  0.266611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features pushing toward target_event=0 (lower event-derived risk):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>line_id_asset_S2-L5</td>\n",
       "      <td>-0.745801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-0.745801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>line_id_asset_S4-L2</td>\n",
       "      <td>-0.459409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>line_id_S4-L2</td>\n",
       "      <td>-0.459409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-0.458345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>line_id_asset_S1-L2</td>\n",
       "      <td>-0.458345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-0.431781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>asset_type_asset_print_apply</td>\n",
       "      <td>-0.431781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>asset_type_asset_weigh_check</td>\n",
       "      <td>-0.295209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>asset_type_weigh_check</td>\n",
       "      <td>-0.295209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>asset_type_asset_bottle_filler</td>\n",
       "      <td>-0.281783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>asset_type_bottle_filler</td>\n",
       "      <td>-0.281783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>line_id_asset_S4-L5</td>\n",
       "      <td>-0.247126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>-0.247126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>line_id_S3-L3</td>\n",
       "      <td>-0.226873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature      coef\n",
       "59             line_id_asset_S2-L5 -0.745801\n",
       "17                   line_id_S2-L5 -0.745801\n",
       "66             line_id_asset_S4-L2 -0.459409\n",
       "24                   line_id_S4-L2 -0.459409\n",
       "9                    line_id_S1-L2 -0.458345\n",
       "51             line_id_asset_S1-L2 -0.458345\n",
       "36          asset_type_print_apply -0.431781\n",
       "78    asset_type_asset_print_apply -0.431781\n",
       "81    asset_type_asset_weigh_check -0.295209\n",
       "39          asset_type_weigh_check -0.295209\n",
       "71  asset_type_asset_bottle_filler -0.281783\n",
       "29        asset_type_bottle_filler -0.281783\n",
       "69             line_id_asset_S4-L5 -0.247126\n",
       "27                   line_id_S4-L5 -0.247126\n",
       "20                   line_id_S3-L3 -0.226873"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IoT aggregate drivers (sorted by |coef|):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>severity_max</td>\n",
       "      <td>1.543977</td>\n",
       "      <td>1.543977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>severity_mean</td>\n",
       "      <td>0.476273</td>\n",
       "      <td>0.476273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>event_count</td>\n",
       "      <td>0.317097</td>\n",
       "      <td>0.317097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>value_std</td>\n",
       "      <td>-0.102639</td>\n",
       "      <td>0.102639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>value_max</td>\n",
       "      <td>0.095404</td>\n",
       "      <td>0.095404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>value_mean</td>\n",
       "      <td>-0.065503</td>\n",
       "      <td>0.065503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature      coef  abs_coef\n",
       "4   severity_max  1.543977  1.543977\n",
       "3  severity_mean  0.476273  0.476273\n",
       "2    event_count  0.317097  0.317097\n",
       "6      value_std -0.102639  0.102639\n",
       "7      value_max  0.095404  0.095404\n",
       "5     value_mean -0.065503  0.065503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_event_coefficients.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 16 — Interpretability (event-derived): coefficients + top IoT drivers\n",
    "#============================================================\n",
    "\n",
    "# Load event-derived feature names aligned to preprocess_event\n",
    "feature_names_evt = pd.read_csv(OUT_DIR / \"feature_names_event.csv\")[\"feature_name\"].tolist()\n",
    "\n",
    "coefs_evt = clf_evt.coef_.ravel()\n",
    "\n",
    "coef_evt_df = pd.DataFrame({\n",
    "    \"feature\": feature_names_evt,\n",
    "    \"coef\": coefs_evt,\n",
    "    \"abs_coef\": np.abs(coefs_evt),\n",
    "}).sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "print(\"Top 25 event-derived features by absolute coefficient magnitude:\")\n",
    "display(coef_evt_df.head(25))\n",
    "\n",
    "print(\"\\nTop 15 features pushing toward target_event=1 (higher event-derived risk):\")\n",
    "display(coef_evt_df.sort_values(\"coef\", ascending=False).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "print(\"\\nTop 15 features pushing toward target_event=0 (lower event-derived risk):\")\n",
    "display(coef_evt_df.sort_values(\"coef\", ascending=True).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "# Highlight the pure IoT aggregate drivers explicitly\n",
    "iot_driver_prefixes = [\"event_count\", \"severity_\", \"value_\"]\n",
    "iot_drivers = coef_evt_df[coef_evt_df[\"feature\"].str.startswith(tuple(iot_driver_prefixes))].copy()\n",
    "\n",
    "print(\"\\nIoT aggregate drivers (sorted by |coef|):\")\n",
    "display(iot_drivers.sort_values(\"abs_coef\", ascending=False).head(20))\n",
    "\n",
    "# Save coefficients\n",
    "coef_evt_path = OUT_DIR / \"baseline_logreg_event_coefficients.csv\"\n",
    "coef_evt_df.to_csv(coef_evt_path, index=False)\n",
    "print(\"\\nSaved:\", coef_evt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea6e6e-8662-4afe-954d-ceadcf31a8b5",
   "metadata": {},
   "source": [
    "### What Cell 16 Just Did\n",
    "\n",
    "This cell added interpretability for the event-derived baseline model by analyzing which features most strongly influence predictions of `target_event`. It paired the logistic regression coefficients from the event-derived model with the transformed feature names generated by the event preprocessing pipeline (including one-hot expanded categorical values and the numeric IoT aggregate fields). It then ranked features by absolute coefficient magnitude to identify the strongest drivers overall, and separately listed the most positive and most negative coefficients to show what pushes the model toward higher vs. lower event-derived risk. To focus specifically on operational behavior, it also filtered and displayed the IoT aggregate features (such as `event_count`, `severity_*`, and `value_*`) so you can quickly see whether the model is being driven more by event volume, severity, or value statistics. Finally, it saved the full coefficient table to `baseline_logreg_event_coefficients.csv` for reporting and downstream analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f03e1895-9e82-4881-80f5-4052e8fca14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/RUN_SUMMARY.md\n",
      "\n",
      "Preview (tail):\n",
      "\n",
      "- **Transformed features (post one-hot):** 90\n",
      "\n",
      "## Train/Test Split\n",
      "- **Train size:** 96 | **Positive rate:** 0.562\n",
      "- **Test size:** 24 | **Positive rate:** 0.542\n",
      "\n",
      "## Baseline Model (Logistic Regression)\n",
      "- **Accuracy:** 1.000\n",
      "- **Precision:** 1.000\n",
      "- **Recall:** 1.000\n",
      "- **F1:** 1.000\n",
      "- **ROC AUC:** 1.000\n",
      "\n",
      "## Saved Artifacts\n",
      "- `run_metadata.json`\n",
      "- `input_base_dataset_path.txt`\n",
      "- `events_standardized_enriched.parquet`\n",
      "- `label_definition.json`\n",
      "- `labeled_master_frame.parquet`\n",
      "- `feature_columns.json`\n",
      "- `model_table.parquet`\n",
      "- `preprocess.joblib`\n",
      "- `feature_names.csv`\n",
      "- `X_train.npy`\n",
      "- `X_test.npy`\n",
      "- `y_train.npy`\n",
      "- `y_test.npy`\n",
      "- `ids_train.parquet`\n",
      "- `ids_test.parquet`\n",
      "- `qa_summary.json`\n",
      "- `baseline_logreg.joblib`\n",
      "- `baseline_logreg_metrics.json`\n",
      "- `baseline_logreg_coefficients.csv`\n",
      "\n",
      "## Event-Derived Label + Baseline\n",
      "\n",
      "- **Event-derived label:** `target_event` (from `iot_event_labels_by_asset.csv`)\n",
      "- **IoT aggregates added:** `event_count`, `severity_*`, `value_*`\n",
      "- **Accuracy:** 0.792\n",
      "- **Precision:** 0.833\n",
      "- **Recall:** 0.769\n",
      "- **F1:** 0.800\n",
      "- **ROC AUC:** 0.944\n",
      "\n",
      "### Top Event-Derived Drivers (by |coef|)\n",
      "- `severity_max` (coef=1.544)\n",
      "- `line_id_S2-L5` (coef=-0.746)\n",
      "- `line_id_asset_S2-L5` (coef=-0.746)\n",
      "- `severity_mean` (coef=0.476)\n",
      "- `line_id_asset_S4-L2` (coef=-0.459)\n",
      "\n",
      "### Event-Derived Artifacts\n",
      "- `iot_event_aggregates_by_asset.csv`\n",
      "- `iot_event_labels_by_asset.csv`\n",
      "- `event_derived_model_table.parquet`\n",
      "- `preprocess_event.joblib`\n",
      "- `feature_names_event.csv`\n",
      "- `baseline_logreg_event.joblib`\n",
      "- `baseline_logreg_event_metrics.json`\n",
      "- `baseline_logreg_event_coefficients.csv`\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 17 — Update run summary: add event-derived label/model results + key drivers\n",
    "#============================================================\n",
    "\n",
    "summary_path = OUT_DIR / \"RUN_SUMMARY.md\"\n",
    "summary_text = summary_path.read_text() if summary_path.exists() else \"\"\n",
    "\n",
    "# Load event-derived metrics\n",
    "evt_metrics_path = OUT_DIR / \"baseline_logreg_event_metrics.json\"\n",
    "evt_metrics = json.loads(evt_metrics_path.read_text()) if evt_metrics_path.exists() else {}\n",
    "\n",
    "# Pull a few key coefficient “headlines”\n",
    "coef_evt_path = OUT_DIR / \"baseline_logreg_event_coefficients.csv\"\n",
    "coef_evt = pd.read_csv(coef_evt_path) if coef_evt_path.exists() else pd.DataFrame(columns=[\"feature\", \"coef\", \"abs_coef\"])\n",
    "\n",
    "top_evt = coef_evt.sort_values(\"abs_coef\", ascending=False).head(5)\n",
    "top_evt_lines = [\n",
    "    f\"- `{r.feature}` (coef={r.coef:.3f})\" for r in top_evt.itertuples(index=False)\n",
    "] if not top_evt.empty else [\"- (coefficients not found)\"]\n",
    "\n",
    "event_block = []\n",
    "event_block.append(\"## Event-Derived Label + Baseline\")\n",
    "event_block.append(\"\")\n",
    "event_block.append(\"- **Event-derived label:** `target_event` (from `iot_event_labels_by_asset.csv`)\")\n",
    "event_block.append(\"- **IoT aggregates added:** `event_count`, `severity_*`, `value_*`\")\n",
    "if evt_metrics:\n",
    "    event_block.append(f\"- **Accuracy:** {evt_metrics.get('accuracy'):.3f}\")\n",
    "    event_block.append(f\"- **Precision:** {evt_metrics.get('precision'):.3f}\")\n",
    "    event_block.append(f\"- **Recall:** {evt_metrics.get('recall'):.3f}\")\n",
    "    event_block.append(f\"- **F1:** {evt_metrics.get('f1'):.3f}\")\n",
    "    if evt_metrics.get(\"roc_auc\") is not None:\n",
    "        event_block.append(f\"- **ROC AUC:** {evt_metrics.get('roc_auc'):.3f}\")\n",
    "event_block.append(\"\")\n",
    "event_block.append(\"### Top Event-Derived Drivers (by |coef|)\")\n",
    "event_block.extend(top_evt_lines)\n",
    "event_block.append(\"\")\n",
    "event_block.append(\"### Event-Derived Artifacts\")\n",
    "for a in [\n",
    "    \"iot_event_aggregates_by_asset.csv\",\n",
    "    \"iot_event_labels_by_asset.csv\",\n",
    "    \"event_derived_model_table.parquet\",\n",
    "    \"preprocess_event.joblib\",\n",
    "    \"feature_names_event.csv\",\n",
    "    \"baseline_logreg_event.joblib\",\n",
    "    \"baseline_logreg_event_metrics.json\",\n",
    "    \"baseline_logreg_event_coefficients.csv\",\n",
    "]:\n",
    "    p = OUT_DIR / a\n",
    "    if p.exists():\n",
    "        event_block.append(f\"- `{a}`\")\n",
    "event_block.append(\"\")\n",
    "\n",
    "event_block_text = \"\\n\".join(event_block)\n",
    "\n",
    "# Append if not already present\n",
    "if \"## Event-Derived Label + Baseline\" not in summary_text:\n",
    "    summary_text = summary_text.rstrip() + \"\\n\\n\" + event_block_text\n",
    "else:\n",
    "    # If it exists, do a simple replace from that header onward (best-effort)\n",
    "    parts = summary_text.split(\"## Event-Derived Label + Baseline\")\n",
    "    summary_text = parts[0].rstrip() + \"\\n\\n\" + event_block_text\n",
    "\n",
    "summary_path.write_text(summary_text)\n",
    "print(\"Updated:\", summary_path)\n",
    "\n",
    "print(\"\\nPreview (tail):\\n\")\n",
    "tail = \"\\n\".join(summary_text.splitlines()[-60:])\n",
    "print(tail)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a319d2c-e66b-4159-af4e-526b5b225f56",
   "metadata": {},
   "source": [
    "### What Cell 17 Just Did\n",
    "\n",
    "This cell updated `RUN_SUMMARY.md` to reflect the stronger, event-derived modeling results. It loaded the saved event-derived baseline metrics (`baseline_logreg_event_metrics.json`) and the coefficient table (`baseline_logreg_event_coefficients.csv`) to extract a handful of “headline” drivers (top features by absolute coefficient). It then appended (or replaced) a dedicated section in the run summary describing the event-derived label (`target_event`), the IoT aggregate features that were added, the key baseline performance metrics (accuracy/precision/recall/F1/ROC AUC), and a short list of the strongest drivers. Finally, it listed the main event-derived artifacts produced by the notebook so the run summary acts as a single, up-to-date receipt of both the proxy-label path and the event-derived path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17b93d4e-9912-4f2d-ba64-163396ce961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/RUN_SUMMARY.md\n",
      "\n",
      "Preview (tail):\n",
      "\n",
      "- **Train size:** 96 | **Positive rate:** 0.562\n",
      "- **Test size:** 24 | **Positive rate:** 0.542\n",
      "\n",
      "## Baseline Model (Logistic Regression)\n",
      "- **Accuracy:** 1.000\n",
      "- **Precision:** 1.000\n",
      "- **Recall:** 1.000\n",
      "- **F1:** 1.000\n",
      "- **ROC AUC:** 1.000\n",
      "\n",
      "## Saved Artifacts\n",
      "- `run_metadata.json`\n",
      "- `input_base_dataset_path.txt`\n",
      "- `events_standardized_enriched.parquet`\n",
      "- `label_definition.json`\n",
      "- `labeled_master_frame.parquet`\n",
      "- `feature_columns.json`\n",
      "- `model_table.parquet`\n",
      "- `preprocess.joblib`\n",
      "- `feature_names.csv`\n",
      "- `X_train.npy`\n",
      "- `X_test.npy`\n",
      "- `y_train.npy`\n",
      "- `y_test.npy`\n",
      "- `ids_train.parquet`\n",
      "- `ids_test.parquet`\n",
      "- `qa_summary.json`\n",
      "- `baseline_logreg.joblib`\n",
      "- `baseline_logreg_metrics.json`\n",
      "- `baseline_logreg_coefficients.csv`\n",
      "\n",
      "## Proxy Label Baseline (Important Note)\n",
      "\n",
      "- The original proxy-label baseline used features that directly defined the proxy label (label leakage).\n",
      "- The 1.000 metrics under **Baseline Model (Logistic Regression)** above are therefore not meaningful.\n",
      "- Use the **No-Leak Proxy Baseline** below for an honest proxy-label reference point.\n",
      "\n",
      "### No-Leak Proxy Baseline (Logistic Regression)\n",
      "- **Accuracy:** 0.542\n",
      "- **Precision:** 0.600\n",
      "- **Recall:** 0.462\n",
      "- **F1:** 0.522\n",
      "- **ROC AUC:** 0.503\n",
      "- **Dropped leakage columns:** `connectivity`, `connectivity_asset`, `is_legacy`, `is_legacy_asset`\n",
      "\n",
      "### No-Leak Proxy Artifacts\n",
      "- `feature_columns_noleak.json`\n",
      "- `preprocess_noleak.joblib`\n",
      "- `baseline_logreg_noleak.joblib`\n",
      "- `baseline_logreg_noleak_metrics.json`\n",
      "- `baseline_logreg_noleak_coefficients.csv`\n",
      "- `baseline_comparison_leak_vs_noleak.csv`\n",
      "\n",
      "\n",
      "## Event-Derived Label + Baseline\n",
      "\n",
      "- **Event-derived label:** `target_event` (from `iot_event_labels_by_asset.csv`)\n",
      "- **IoT aggregates added:** `event_count`, `severity_*`, `value_*`\n",
      "- **Accuracy:** 0.792\n",
      "- **Precision:** 0.833\n",
      "- **Recall:** 0.769\n",
      "- **F1:** 0.800\n",
      "- **ROC AUC:** 0.944\n",
      "\n",
      "### Top Event-Derived Drivers (by |coef|)\n",
      "- `severity_max` (coef=1.544)\n",
      "- `line_id_S2-L5` (coef=-0.746)\n",
      "- `line_id_asset_S2-L5` (coef=-0.746)\n",
      "- `severity_mean` (coef=0.476)\n",
      "- `line_id_asset_S4-L2` (coef=-0.459)\n",
      "\n",
      "### Event-Derived Artifacts\n",
      "- `iot_event_aggregates_by_asset.csv`\n",
      "- `iot_event_labels_by_asset.csv`\n",
      "- `event_derived_model_table.parquet`\n",
      "- `preprocess_event.joblib`\n",
      "- `feature_names_event.csv`\n",
      "- `baseline_logreg_event.joblib`\n",
      "- `baseline_logreg_event_metrics.json`\n",
      "- `baseline_logreg_event_coefficients.csv`\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 18 — Clean up summary: explicitly flag leaky proxy baseline and add no-leak proxy metrics\n",
    "#============================================================\n",
    "\n",
    "summary_path = OUT_DIR / \"RUN_SUMMARY.md\"\n",
    "text = summary_path.read_text() if summary_path.exists() else \"\"\n",
    "\n",
    "# Load no-leak proxy metrics (if present)\n",
    "nl_path = OUT_DIR / \"baseline_logreg_noleak_metrics.json\"\n",
    "nl = json.loads(nl_path.read_text()) if nl_path.exists() else {}\n",
    "\n",
    "# Build a clarification block for the proxy baseline section\n",
    "clarify = []\n",
    "clarify.append(\"## Proxy Label Baseline (Important Note)\")\n",
    "clarify.append(\"\")\n",
    "clarify.append(\"- The original proxy-label baseline used features that directly defined the proxy label (label leakage).\")\n",
    "clarify.append(\"- The 1.000 metrics under **Baseline Model (Logistic Regression)** above are therefore not meaningful.\")\n",
    "clarify.append(\"- Use the **No-Leak Proxy Baseline** below for an honest proxy-label reference point.\")\n",
    "clarify.append(\"\")\n",
    "if nl:\n",
    "    clarify.append(\"### No-Leak Proxy Baseline (Logistic Regression)\")\n",
    "    clarify.append(f\"- **Accuracy:** {nl.get('accuracy'):.3f}\")\n",
    "    clarify.append(f\"- **Precision:** {nl.get('precision'):.3f}\")\n",
    "    clarify.append(f\"- **Recall:** {nl.get('recall'):.3f}\")\n",
    "    clarify.append(f\"- **F1:** {nl.get('f1'):.3f}\")\n",
    "    if nl.get(\"roc_auc\") is not None:\n",
    "        clarify.append(f\"- **ROC AUC:** {nl.get('roc_auc'):.3f}\")\n",
    "    dropped = nl.get(\"dropped_leak_cols\", [])\n",
    "    if dropped:\n",
    "        clarify.append(f\"- **Dropped leakage columns:** {', '.join([f'`{c}`' for c in dropped])}\")\n",
    "    clarify.append(\"\")\n",
    "    clarify.append(\"### No-Leak Proxy Artifacts\")\n",
    "    for a in [\n",
    "        \"feature_columns_noleak.json\",\n",
    "        \"preprocess_noleak.joblib\",\n",
    "        \"baseline_logreg_noleak.joblib\",\n",
    "        \"baseline_logreg_noleak_metrics.json\",\n",
    "        \"baseline_logreg_noleak_coefficients.csv\",\n",
    "        \"baseline_comparison_leak_vs_noleak.csv\",\n",
    "    ]:\n",
    "        p = OUT_DIR / a\n",
    "        if p.exists():\n",
    "            clarify.append(f\"- `{a}`\")\n",
    "    clarify.append(\"\")\n",
    "else:\n",
    "    clarify.append(\"### No-Leak Proxy Baseline\")\n",
    "    clarify.append(\"- (No no-leak proxy metrics found; run Cell 11–12 to generate them.)\")\n",
    "    clarify.append(\"\")\n",
    "\n",
    "clarify_block = \"\\n\".join(clarify)\n",
    "\n",
    "# Insert the clarification block right after the Saved Artifacts list (best-effort),\n",
    "# but before the Event-Derived section.\n",
    "if \"## Event-Derived Label + Baseline\" in text:\n",
    "    parts = text.split(\"## Event-Derived Label + Baseline\")\n",
    "    head = parts[0].rstrip()\n",
    "    tail = \"## Event-Derived Label + Baseline\" + parts[1]\n",
    "    if \"## Proxy Label Baseline (Important Note)\" not in head:\n",
    "        text = head + \"\\n\\n\" + clarify_block + \"\\n\\n\" + tail\n",
    "else:\n",
    "    # If event block not found, just append\n",
    "    if \"## Proxy Label Baseline (Important Note)\" not in text:\n",
    "        text = text.rstrip() + \"\\n\\n\" + clarify_block\n",
    "\n",
    "summary_path.write_text(text)\n",
    "print(\"Updated:\", summary_path)\n",
    "\n",
    "print(\"\\nPreview (tail):\\n\")\n",
    "tail = \"\\n\".join(text.splitlines()[-80:])\n",
    "print(tail)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46265c0d-3691-41f6-8005-e45087931050",
   "metadata": {},
   "source": [
    "### What Cell 18 Just Did\n",
    "\n",
    "This cell improved the auditability of `RUN_SUMMARY.md` by explicitly documenting the proxy-label leakage issue and adding the correct no-leak proxy baseline results. It loaded the no-leak proxy baseline metrics (produced earlier) and generated a clear note explaining that the original proxy baseline achieved perfect performance only because the label-defining columns were included as features. It then inserted a new “Proxy Label Baseline (Important Note)” section into the run summary, listing the no-leak proxy metrics (accuracy/precision/recall/F1/ROC AUC) and the specific columns that were removed to prevent leakage. Finally, it recorded the key no-leak proxy artifacts so the summary provides a transparent and trustworthy record of both the proxy path and the event-derived path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb51ab39-929a-47b0-a27d-27833388d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/EXPORTS.json\n",
      "\n",
      "Key outputs (copy/paste friendly):\n",
      "- RUN_DIR: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z\n",
      "- RUN_SUMMARY_MD: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/RUN_SUMMARY.md\n",
      "- EVENT_MODEL_TABLE: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/event_derived_model_table.parquet\n",
      "- EVENT_PREPROCESS: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/preprocess_event.joblib\n",
      "- EVENT_BASELINE_METRICS: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_event_metrics.json\n",
      "- EVENT_COEFFICIENTS: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_event_coefficients.csv\n",
      "\n",
      "Next-step checklist:\n",
      " - 1) Decide whether target_event definition should change (use incident_type, event_kind, or metric thresholds).\n",
      " - 2) Add time-windowed aggregates (last 7d / 30d counts) using ts_utc for stronger temporal features.\n",
      " - 3) Replace Logistic Regression with a tree model (RandomForest / XGBoost if allowed) and compare ROC AUC.\n",
      " - 4) Calibrate threshold for business action (optimize precision vs recall) and produce a ranked asset risk list.\n",
      " - 5) Save a scored table: asset_id, site, line, predicted_risk, top drivers (for reporting).\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 19 — Final notebook “exports”: copy key paths + print a checklist for next notebook steps\n",
    "#============================================================\n",
    "\n",
    "# A tiny helper to print paths cleanly\n",
    "def p(path: Path) -> str:\n",
    "    return str(path.resolve())\n",
    "\n",
    "exports = {\n",
    "    # Core run metadata\n",
    "    \"RUN_DIR\": p(OUT_DIR),\n",
    "    \"RUN_SUMMARY_MD\": p(OUT_DIR / \"RUN_SUMMARY.md\"),\n",
    "\n",
    "    # Proxy-label path (leaky + no-leak)\n",
    "    \"PROXY_MODEL_TABLE\": p(OUT_DIR / \"model_table.parquet\"),\n",
    "    \"PROXY_PREPROCESS\": p(OUT_DIR / \"preprocess.joblib\"),\n",
    "    \"PROXY_FEATURE_NAMES\": p(OUT_DIR / \"feature_names.csv\"),\n",
    "    \"PROXY_BASELINE_MODEL\": p(OUT_DIR / \"baseline_logreg.joblib\"),\n",
    "    \"PROXY_BASELINE_METRICS\": p(OUT_DIR / \"baseline_logreg_metrics.json\"),\n",
    "    \"NOLEAK_PREPROCESS\": p(OUT_DIR / \"preprocess_noleak.joblib\"),\n",
    "    \"NOLEAK_BASELINE_MODEL\": p(OUT_DIR / \"baseline_logreg_noleak.joblib\"),\n",
    "    \"NOLEAK_BASELINE_METRICS\": p(OUT_DIR / \"baseline_logreg_noleak_metrics.json\"),\n",
    "\n",
    "    # Event-derived path (recommended)\n",
    "    \"IOT_AGG_BY_ASSET\": p(OUT_DIR / \"iot_event_aggregates_by_asset.csv\"),\n",
    "    \"IOT_LABELS_BY_ASSET\": p(OUT_DIR / \"iot_event_labels_by_asset.csv\"),\n",
    "    \"EVENT_MODEL_TABLE\": p(OUT_DIR / \"event_derived_model_table.parquet\"),\n",
    "    \"EVENT_PREPROCESS\": p(OUT_DIR / \"preprocess_event.joblib\"),\n",
    "    \"EVENT_FEATURE_NAMES\": p(OUT_DIR / \"feature_names_event.csv\"),\n",
    "    \"EVENT_BASELINE_MODEL\": p(OUT_DIR / \"baseline_logreg_event.joblib\"),\n",
    "    \"EVENT_BASELINE_METRICS\": p(OUT_DIR / \"baseline_logreg_event_metrics.json\"),\n",
    "    \"EVENT_COEFFICIENTS\": p(OUT_DIR / \"baseline_logreg_event_coefficients.csv\"),\n",
    "}\n",
    "\n",
    "# Save a single JSON export map for downstream notebooks/scripts\n",
    "exports_path = OUT_DIR / \"EXPORTS.json\"\n",
    "with open(exports_path, \"w\") as f:\n",
    "    json.dump(exports, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", exports_path)\n",
    "print(\"\\nKey outputs (copy/paste friendly):\")\n",
    "for k in [\n",
    "    \"RUN_DIR\",\n",
    "    \"RUN_SUMMARY_MD\",\n",
    "    \"EVENT_MODEL_TABLE\",\n",
    "    \"EVENT_PREPROCESS\",\n",
    "    \"EVENT_BASELINE_METRICS\",\n",
    "    \"EVENT_COEFFICIENTS\",\n",
    "]:\n",
    "    print(f\"- {k}: {exports[k]}\")\n",
    "\n",
    "print(\"\\nNext-step checklist:\")\n",
    "checklist = [\n",
    "    \"1) Decide whether target_event definition should change (use incident_type, event_kind, or metric thresholds).\",\n",
    "    \"2) Add time-windowed aggregates (last 7d / 30d counts) using ts_utc for stronger temporal features.\",\n",
    "    \"3) Replace Logistic Regression with a tree model (RandomForest / XGBoost if allowed) and compare ROC AUC.\",\n",
    "    \"4) Calibrate threshold for business action (optimize precision vs recall) and produce a ranked asset risk list.\",\n",
    "    \"5) Save a scored table: asset_id, site, line, predicted_risk, top drivers (for reporting).\",\n",
    "]\n",
    "for line in checklist:\n",
    "    print(\" -\", line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d6ef74-d4ab-418b-838a-f5e552c606c4",
   "metadata": {},
   "source": [
    "### What Cell 19 Just Did\n",
    "\n",
    "This final cell packaged the notebook’s most important outputs into a single, easy-to-consume “exports map” for downstream work. It collected absolute paths to the run directory, the updated `RUN_SUMMARY.md`, and the main artifacts produced by both modeling paths (proxy/no-leak and the recommended event-derived path). It then wrote those paths to `EXPORTS.json` inside the run output directory so future notebooks and scripts can programmatically load the correct tables, preprocessors, models, and metrics without hard-coding filenames. Finally, it printed a short, copy/paste-friendly list of the most important event-derived artifacts and a concise checklist of practical next steps (refining the event label, adding time-windowed aggregates using `ts_utc`, trying stronger models, choosing decision thresholds, and producing a ranked risk output for reporting).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2cf5835-44a9-466e-9467-29de277286cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time windows end at: 2025-12-11 00:00:18.868743+00:00\n",
      "  7d start: 2025-12-04 00:00:18.868743+00:00\n",
      " 30d start: 2025-11-11 00:00:18.868743+00:00\n",
      "\n",
      "7d window aggregate sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>event_count_7d</th>\n",
       "      <th>severity_mean_7d</th>\n",
       "      <th>severity_max_7d</th>\n",
       "      <th>value_mean_7d</th>\n",
       "      <th>value_std_7d</th>\n",
       "      <th>value_max_7d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>4006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.688916</td>\n",
       "      <td>76.445526</td>\n",
       "      <td>266.486612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>1220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.418213</td>\n",
       "      <td>76.509260</td>\n",
       "      <td>273.439054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>1258</td>\n",
       "      <td>3.698664</td>\n",
       "      <td>3.698664</td>\n",
       "      <td>66.742084</td>\n",
       "      <td>78.089471</td>\n",
       "      <td>305.024304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>1256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.598842</td>\n",
       "      <td>96.478835</td>\n",
       "      <td>370.493533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>1232</td>\n",
       "      <td>3.218420</td>\n",
       "      <td>4.803082</td>\n",
       "      <td>68.796690</td>\n",
       "      <td>79.309037</td>\n",
       "      <td>277.108071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id  event_count_7d  severity_mean_7d  severity_max_7d  value_mean_7d  \\\n",
       "0    A0001            4006               NaN              NaN      65.688916   \n",
       "1    A0002            1220               NaN              NaN      65.418213   \n",
       "2    A0003            1258          3.698664         3.698664      66.742084   \n",
       "3    A0004            1256               NaN              NaN      76.598842   \n",
       "4    A0005            1232          3.218420         4.803082      68.796690   \n",
       "\n",
       "   value_std_7d  value_max_7d  \n",
       "0     76.445526    266.486612  \n",
       "1     76.509260    273.439054  \n",
       "2     78.089471    305.024304  \n",
       "3     96.478835    370.493533  \n",
       "4     79.309037    277.108071  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30d window aggregate sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>event_count_30d</th>\n",
       "      <th>severity_mean_30d</th>\n",
       "      <th>severity_max_30d</th>\n",
       "      <th>value_mean_30d</th>\n",
       "      <th>value_std_30d</th>\n",
       "      <th>value_max_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>8006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.877219</td>\n",
       "      <td>76.434873</td>\n",
       "      <td>287.054630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>2419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.946323</td>\n",
       "      <td>76.050874</td>\n",
       "      <td>273.747021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>2505</td>\n",
       "      <td>2.712840</td>\n",
       "      <td>3.698664</td>\n",
       "      <td>64.837749</td>\n",
       "      <td>77.246431</td>\n",
       "      <td>305.024304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>2520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.875996</td>\n",
       "      <td>98.571559</td>\n",
       "      <td>375.143159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>2503</td>\n",
       "      <td>3.309361</td>\n",
       "      <td>4.803082</td>\n",
       "      <td>68.436679</td>\n",
       "      <td>77.827009</td>\n",
       "      <td>297.961037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id  event_count_30d  severity_mean_30d  severity_max_30d  \\\n",
       "0    A0001             8006                NaN               NaN   \n",
       "1    A0002             2419                NaN               NaN   \n",
       "2    A0003             2505           2.712840          3.698664   \n",
       "3    A0004             2520                NaN               NaN   \n",
       "4    A0005             2503           3.309361          4.803082   \n",
       "\n",
       "   value_mean_30d  value_std_30d  value_max_30d  \n",
       "0       66.877219      76.434873     287.054630  \n",
       "1       65.946323      76.050874     273.747021  \n",
       "2       64.837749      77.246431     305.024304  \n",
       "3       79.875996      98.571559     375.143159  \n",
       "4       68.436679      77.827009     297.961037  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape after adding time-windowed features: (120, 34)\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/event_derived_model_table_timewindows.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>vendor</th>\n",
       "      <th>site_id_asset</th>\n",
       "      <th>line_id_asset</th>\n",
       "      <th>asset_type_asset</th>\n",
       "      <th>...</th>\n",
       "      <th>severity_max_7d</th>\n",
       "      <th>value_mean_7d</th>\n",
       "      <th>value_std_7d</th>\n",
       "      <th>value_max_7d</th>\n",
       "      <th>event_count_30d</th>\n",
       "      <th>severity_mean_30d</th>\n",
       "      <th>severity_max_30d</th>\n",
       "      <th>value_mean_30d</th>\n",
       "      <th>value_std_30d</th>\n",
       "      <th>value_max_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.688916</td>\n",
       "      <td>76.445526</td>\n",
       "      <td>266.486612</td>\n",
       "      <td>8006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.877219</td>\n",
       "      <td>76.434873</td>\n",
       "      <td>287.054630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.418213</td>\n",
       "      <td>76.509260</td>\n",
       "      <td>273.439054</td>\n",
       "      <td>2419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.946323</td>\n",
       "      <td>76.050874</td>\n",
       "      <td>273.747021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>...</td>\n",
       "      <td>3.698664</td>\n",
       "      <td>66.742084</td>\n",
       "      <td>78.089471</td>\n",
       "      <td>305.024304</td>\n",
       "      <td>2505</td>\n",
       "      <td>2.712840</td>\n",
       "      <td>3.698664</td>\n",
       "      <td>64.837749</td>\n",
       "      <td>77.246431</td>\n",
       "      <td>305.024304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.598842</td>\n",
       "      <td>96.478835</td>\n",
       "      <td>370.493533</td>\n",
       "      <td>2520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.875996</td>\n",
       "      <td>98.571559</td>\n",
       "      <td>375.143159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>...</td>\n",
       "      <td>4.803082</td>\n",
       "      <td>68.796690</td>\n",
       "      <td>79.309037</td>\n",
       "      <td>277.108071</td>\n",
       "      <td>2503</td>\n",
       "      <td>3.309361</td>\n",
       "      <td>4.803082</td>\n",
       "      <td>68.436679</td>\n",
       "      <td>77.827009</td>\n",
       "      <td>297.961037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id site_id line_id             asset_type  is_legacy   connectivity  \\\n",
       "0    A0001      S1   S1-L2         blister_packer      False     mqtt_opcua   \n",
       "1    A0002      S2   S2-L5            print_apply       True  legacy_serial   \n",
       "2    A0003      S4   S4-L2         blister_packer       True  legacy_serial   \n",
       "3    A0004      S1   S1-L2             sterilizer       True  legacy_serial   \n",
       "4    A0005      S4   S4-L2  environmental_monitor       True  legacy_serial   \n",
       "\n",
       "    vendor site_id_asset line_id_asset       asset_type_asset  ...  \\\n",
       "0  VendorB            S1         S1-L2         blister_packer  ...   \n",
       "1  VendorA            S2         S2-L5            print_apply  ...   \n",
       "2  VendorB            S4         S4-L2         blister_packer  ...   \n",
       "3  VendorD            S1         S1-L2             sterilizer  ...   \n",
       "4  VendorA            S4         S4-L2  environmental_monitor  ...   \n",
       "\n",
       "   severity_max_7d value_mean_7d value_std_7d value_max_7d event_count_30d  \\\n",
       "0              NaN     65.688916    76.445526   266.486612            8006   \n",
       "1              NaN     65.418213    76.509260   273.439054            2419   \n",
       "2         3.698664     66.742084    78.089471   305.024304            2505   \n",
       "3              NaN     76.598842    96.478835   370.493533            2520   \n",
       "4         4.803082     68.796690    79.309037   277.108071            2503   \n",
       "\n",
       "   severity_mean_30d  severity_max_30d  value_mean_30d  value_std_30d  \\\n",
       "0                NaN               NaN       66.877219      76.434873   \n",
       "1                NaN               NaN       65.946323      76.050874   \n",
       "2           2.712840          3.698664       64.837749      77.246431   \n",
       "3                NaN               NaN       79.875996      98.571559   \n",
       "4           3.309361          4.803082       68.436679      77.827009   \n",
       "\n",
       "   value_max_30d  \n",
       "0     287.054630  \n",
       "1     273.747021  \n",
       "2     305.024304  \n",
       "3     375.143159  \n",
       "4     297.961037  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 20 — Time-windowed IoT aggregates (7d / 30d) using ts_utc + join back to modeling table\n",
    "#============================================================\n",
    "\n",
    "# This cell strengthens the event-derived feature set by adding recency-aware aggregates:\n",
    "# - event_count_7d, event_count_30d\n",
    "# - severity_max_7d, severity_max_30d (if severity present)\n",
    "# - value_mean_7d, value_mean_30d (if metric_value present)\n",
    "#\n",
    "# We will:\n",
    "# 1) Reload iot_events.parquet\n",
    "# 2) Use ts_utc as the timestamp (it exists in your schema)\n",
    "# 3) Compute per-asset aggregates over trailing windows ending at the dataset's max timestamp\n",
    "# 4) Join these features into event_model_df and persist an updated table\n",
    "\n",
    "iot_path = RAW_DIR / \"iot_events.parquet\"\n",
    "iot = pd.read_parquet(iot_path)\n",
    "\n",
    "# Normalize key columns explicitly based on your schema\n",
    "iot = iot.rename(columns={\"ts_utc\": \"event_ts\", \"metric_value\": \"value\"})\n",
    "iot[\"event_ts\"] = pd.to_datetime(iot[\"event_ts\"], errors=\"coerce\", utc=True)\n",
    "iot[\"asset_id\"] = iot[\"asset_id\"].astype(str).str.strip()\n",
    "\n",
    "# Severity is optional but exists (NaNs allowed)\n",
    "if \"severity\" in iot.columns:\n",
    "    iot[\"severity_num\"] = pd.to_numeric(iot[\"severity\"], errors=\"coerce\")\n",
    "\n",
    "# Define window endpoints\n",
    "t_end = iot[\"event_ts\"].max()\n",
    "if pd.isna(t_end):\n",
    "    raise ValueError(\"ts_utc/event_ts appears to be entirely NaT; cannot compute time windows.\")\n",
    "\n",
    "t_7d = t_end - pd.Timedelta(days=7)\n",
    "t_30d = t_end - pd.Timedelta(days=30)\n",
    "\n",
    "print(\"Time windows end at:\", t_end)\n",
    "print(\"  7d start:\", t_7d)\n",
    "print(\" 30d start:\", t_30d)\n",
    "\n",
    "def window_aggs(df_window: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute per-asset aggregates for a filtered window.\n",
    "    \"\"\"\n",
    "    out = df_window.groupby(\"asset_id\").agg(\n",
    "        **{\n",
    "            f\"event_count_{prefix}\": (\"event_id\", \"count\"),\n",
    "        }\n",
    "    ).reset_index()\n",
    "\n",
    "    # severity aggregates (if present)\n",
    "    if \"severity_num\" in df_window.columns:\n",
    "        sev = df_window.groupby(\"asset_id\")[\"severity_num\"].agg([\"mean\", \"max\"]).reset_index()\n",
    "        sev = sev.rename(columns={\"mean\": f\"severity_mean_{prefix}\", \"max\": f\"severity_max_{prefix}\"})\n",
    "        out = out.merge(sev, on=\"asset_id\", how=\"left\")\n",
    "\n",
    "    # value aggregates\n",
    "    val = pd.to_numeric(df_window[\"value\"], errors=\"coerce\")\n",
    "    dfw = df_window.copy()\n",
    "    dfw[\"value_num\"] = val\n",
    "    v = dfw.groupby(\"asset_id\")[\"value_num\"].agg([\"mean\", \"std\", \"max\"]).reset_index()\n",
    "    v = v.rename(columns={\n",
    "        \"mean\": f\"value_mean_{prefix}\",\n",
    "        \"std\": f\"value_std_{prefix}\",\n",
    "        \"max\": f\"value_max_{prefix}\",\n",
    "    })\n",
    "    out = out.merge(v, on=\"asset_id\", how=\"left\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# Filter windows\n",
    "iot_7d = iot[iot[\"event_ts\"] >= t_7d].copy()\n",
    "iot_30d = iot[iot[\"event_ts\"] >= t_30d].copy()\n",
    "\n",
    "agg_7d = window_aggs(iot_7d, \"7d\")\n",
    "agg_30d = window_aggs(iot_30d, \"30d\")\n",
    "\n",
    "print(\"\\n7d window aggregate sample:\")\n",
    "display(agg_7d.head(5))\n",
    "\n",
    "print(\"\\n30d window aggregate sample:\")\n",
    "display(agg_30d.head(5))\n",
    "\n",
    "# Merge windowed features into event_model_df\n",
    "evt2 = event_model_df.copy()\n",
    "evt2[\"asset_id\"] = evt2[\"asset_id\"].astype(str).str.strip()\n",
    "\n",
    "evt2 = evt2.merge(agg_7d, on=\"asset_id\", how=\"left\")\n",
    "evt2 = evt2.merge(agg_30d, on=\"asset_id\", how=\"left\")\n",
    "\n",
    "# Fill missing counts with 0 (asset had no events in that window)\n",
    "for c in [c for c in evt2.columns if c.startswith(\"event_count_\")]:\n",
    "    evt2[c] = evt2[c].fillna(0).astype(int)\n",
    "\n",
    "print(\"\\nShape after adding time-windowed features:\", evt2.shape)\n",
    "\n",
    "# Persist updated table\n",
    "evt2_path = OUT_DIR / \"event_derived_model_table_timewindows.parquet\"\n",
    "evt2.to_parquet(evt2_path, index=False)\n",
    "print(\"Saved:\", evt2_path)\n",
    "\n",
    "display(evt2.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce59537a-7626-4611-889b-869ee1de4da7",
   "metadata": {},
   "source": [
    "### What Cell 20 Just Did\n",
    "\n",
    "This cell strengthened the event-derived feature set by adding **recency-aware** IoT aggregates over trailing time windows. It reloaded `iot_events.parquet`, explicitly used `ts_utc` as the authoritative event timestamp (renamed to `event_ts`), and defined two trailing windows ending at the dataset’s maximum timestamp: the last 7 days and the last 30 days. For each window, it computed per-asset aggregates such as `event_count_7d`/`event_count_30d` and (when available) windowed severity and value statistics (means, maxima, and standard deviations). It then joined these windowed features back into the event-derived modeling table (`event_model_df`) by `asset_id`, filling missing event counts with zero for assets that had no events in a given window. Finally, it saved the enhanced dataset as `event_derived_model_table_timewindows.parquet`, which is ready for a more temporally realistic modeling pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02c0e751-b422-4eef-9df2-fce70e6c6b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID columns excluded: ['asset_id', 'site_id']\n",
      "Numeric feature columns: ['is_legacy', 'is_legacy_asset', 'event_count', 'severity_mean', 'severity_max', 'value_mean', 'value_std', 'value_max', 'event_count_7d', 'severity_mean_7d', 'severity_max_7d', 'value_mean_7d', 'value_std_7d', 'value_max_7d', 'event_count_30d', 'severity_mean_30d', 'severity_max_30d', 'value_mean_30d', 'value_std_30d', 'value_max_30d']\n",
      "Categorical feature columns: ['line_id', 'asset_type', 'connectivity', 'vendor', 'site_id_asset', 'line_id_asset', 'asset_type_asset', 'connectivity_asset', 'vendor_asset', 'site_name', 'tz']\n",
      "\n",
      "Split shapes:\n",
      "  X_train: (96, 31) | y_train: (96,) | pos_rate: 0.5416666666666666\n",
      "  X_test : (24, 31) | y_test : (24,) | pos_rate: 0.5416666666666666\n",
      "\n",
      "Transformed shapes:\n",
      "  X_train_tx: (96, 108)\n",
      "  X_test_tx : (24, 108)\n",
      "  # features: 108\n",
      "\n",
      "Event-derived + time windows: Logistic Regression\n",
      "  Accuracy : 0.917\n",
      "  Precision: 0.923\n",
      "  Recall   : 0.923\n",
      "  F1       : 0.923\n",
      "  ROC AUC  : 0.951\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "[[10  1]\n",
      " [ 1 12]]\n",
      "\n",
      "Saved:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/preprocess_event_timewindows.joblib\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_event_timewindows.joblib\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_event_timewindows_metrics.json\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/feature_names_event_timewindows.csv\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/event_derived_model_table_timewindows.parquet\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 21 — Model pass with time-windowed features (event-derived label) + metrics + save artifacts\n",
    "#============================================================\n",
    "\n",
    "# Use the enhanced table from Cell 20\n",
    "evt_tw = evt2.copy()\n",
    "\n",
    "target_col = \"target_event\"\n",
    "id_like = [\"asset_id\", \"site_id\", \"event_id\", \"id\", \"uuid\"]\n",
    "id_cols_tw = [c for c in id_like if c in evt_tw.columns]\n",
    "\n",
    "exclude_tw = set(id_cols_tw + [target_col])\n",
    "\n",
    "# Detect numeric/categorical again (new columns were added)\n",
    "numeric_cols_tw = [\n",
    "    c for c in evt_tw.columns\n",
    "    if c not in exclude_tw and pd.api.types.is_numeric_dtype(evt_tw[c])\n",
    "]\n",
    "categorical_cols_tw = [\n",
    "    c for c in evt_tw.columns\n",
    "    if c not in exclude_tw and not pd.api.types.is_numeric_dtype(evt_tw[c])\n",
    "]\n",
    "\n",
    "print(\"ID columns excluded:\", id_cols_tw)\n",
    "print(\"Numeric feature columns:\", numeric_cols_tw)\n",
    "print(\"Categorical feature columns:\", categorical_cols_tw)\n",
    "\n",
    "X_tw = evt_tw[numeric_cols_tw + categorical_cols_tw].copy()\n",
    "y_tw = evt_tw[target_col].astype(\"int8\").copy()\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_tw, y_tw,\n",
    "    test_size=0.20,\n",
    "    random_state=SEED,\n",
    "    stratify=y_tw if y_tw.nunique() > 1 else None\n",
    ")\n",
    "\n",
    "print(\"\\nSplit shapes:\")\n",
    "print(\"  X_train:\", Xtr.shape, \"| y_train:\", ytr.shape, \"| pos_rate:\", float(ytr.mean()))\n",
    "print(\"  X_test :\", Xte.shape, \"| y_test :\", yte.shape, \"| pos_rate:\", float(yte.mean()))\n",
    "\n",
    "# Preprocess\n",
    "num_tx = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "cat_tx = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "])\n",
    "\n",
    "preprocess_tw = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_tx, numeric_cols_tw),\n",
    "        (\"cat\", cat_tx, categorical_cols_tw),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "preprocess_tw.fit(Xtr)\n",
    "Xtr_tx = preprocess_tw.transform(Xtr)\n",
    "Xte_tx = preprocess_tw.transform(Xte)\n",
    "feat_tw = preprocess_tw.get_feature_names_out().tolist()\n",
    "\n",
    "print(\"\\nTransformed shapes:\")\n",
    "print(\"  X_train_tx:\", Xtr_tx.shape)\n",
    "print(\"  X_test_tx :\", Xte_tx.shape)\n",
    "print(\"  # features:\", len(feat_tw))\n",
    "\n",
    "# Model\n",
    "clf_tw = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"lbfgs\",\n",
    ")\n",
    "clf_tw.fit(Xtr_tx, ytr)\n",
    "yp = clf_tw.predict(Xte_tx)\n",
    "\n",
    "acc = accuracy_score(yte, yp)\n",
    "prec = precision_score(yte, yp, zero_division=0)\n",
    "rec = recall_score(yte, yp, zero_division=0)\n",
    "f1 = f1_score(yte, yp, zero_division=0)\n",
    "\n",
    "if ytr.nunique() == 2:\n",
    "    yproba = clf_tw.predict_proba(Xte_tx)[:, 1]\n",
    "    auc = roc_auc_score(yte, yproba)\n",
    "else:\n",
    "    auc = np.nan\n",
    "\n",
    "print(\"\\nEvent-derived + time windows: Logistic Regression\")\n",
    "print(f\"  Accuracy : {acc:.3f}\")\n",
    "print(f\"  Precision: {prec:.3f}\")\n",
    "print(f\"  Recall   : {rec:.3f}\")\n",
    "print(f\"  F1       : {f1:.3f}\")\n",
    "print(f\"  ROC AUC  : {auc:.3f}\" if not np.isnan(auc) else \"  ROC AUC  : n/a\")\n",
    "\n",
    "print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "print(confusion_matrix(yte, yp))\n",
    "\n",
    "# Persist artifacts\n",
    "joblib.dump(preprocess_tw, OUT_DIR / \"preprocess_event_timewindows.joblib\")\n",
    "joblib.dump(clf_tw, OUT_DIR / \"baseline_logreg_event_timewindows.joblib\")\n",
    "\n",
    "pd.Series(feat_tw, name=\"feature_name\").to_csv(OUT_DIR / \"feature_names_event_timewindows.csv\", index=False)\n",
    "\n",
    "with open(OUT_DIR / \"baseline_logreg_event_timewindows_metrics.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"model\": \"LogisticRegression(class_weight=balanced, solver=lbfgs, max_iter=2000)\",\n",
    "            \"accuracy\": float(acc),\n",
    "            \"precision\": float(prec),\n",
    "            \"recall\": float(rec),\n",
    "            \"f1\": float(f1),\n",
    "            \"roc_auc\": float(auc) if not np.isnan(auc) else None,\n",
    "            \"n_features_raw\": int(X_tw.shape[1]),\n",
    "            \"n_features_transformed\": int(len(feat_tw)),\n",
    "            \"target_col\": target_col,\n",
    "            \"id_cols_excluded\": id_cols_tw,\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", OUT_DIR / \"preprocess_event_timewindows.joblib\")\n",
    "print(\" \", OUT_DIR / \"baseline_logreg_event_timewindows.joblib\")\n",
    "print(\" \", OUT_DIR / \"baseline_logreg_event_timewindows_metrics.json\")\n",
    "print(\" \", OUT_DIR / \"feature_names_event_timewindows.csv\")\n",
    "print(\" \", OUT_DIR / \"event_derived_model_table_timewindows.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce729a-4697-4a48-aae9-0b84333fb7d4",
   "metadata": {},
   "source": [
    "### What Cell 21 Just Did\n",
    "\n",
    "This cell trained and evaluated a new baseline model using the **time-windowed** IoT features added in Cell 20. It started from the enhanced event-derived modeling table (`evt2`), excluded ID-like columns, and re-identified numeric vs. categorical feature columns (now including the 7-day and 30-day aggregates). It performed a stratified train/test split, fit a preprocessing pipeline (median imputation + scaling for numeric features; most-frequent imputation + one-hot encoding for categoricals), and transformed both train and test sets. Using the transformed arrays, it trained a balanced logistic regression model and computed evaluation metrics (accuracy, precision, recall, F1, ROC AUC) plus a confusion matrix. Finally, it saved the fitted preprocessor, model, metrics, and feature names with a clear `event_timewindows` prefix so you can compare this recency-aware baseline directly against the earlier event-derived baseline without time windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2afdfa9f-f51d-4e6a-8c08-5d6169d3be04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 time-window features by absolute coefficient magnitude:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>severity_max_30d</td>\n",
       "      <td>0.912779</td>\n",
       "      <td>0.912779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>severity_max</td>\n",
       "      <td>0.912779</td>\n",
       "      <td>0.912779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-0.722313</td>\n",
       "      <td>0.722313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>line_id_asset_S2-L5</td>\n",
       "      <td>-0.722313</td>\n",
       "      <td>0.722313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>asset_type_asset_cartoner</td>\n",
       "      <td>0.479360</td>\n",
       "      <td>0.479360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>0.479360</td>\n",
       "      <td>0.479360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>line_id_S4-L2</td>\n",
       "      <td>-0.456185</td>\n",
       "      <td>0.456185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>line_id_asset_S4-L2</td>\n",
       "      <td>-0.456185</td>\n",
       "      <td>0.456185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>severity_mean_7d</td>\n",
       "      <td>-0.439688</td>\n",
       "      <td>0.439688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>line_id_asset_S1-L2</td>\n",
       "      <td>-0.423009</td>\n",
       "      <td>0.423009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-0.423009</td>\n",
       "      <td>0.423009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>asset_type_asset_print_apply</td>\n",
       "      <td>-0.409788</td>\n",
       "      <td>0.409788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-0.409788</td>\n",
       "      <td>0.409788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>line_id_asset_S2-L1</td>\n",
       "      <td>0.376248</td>\n",
       "      <td>0.376248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>line_id_S2-L1</td>\n",
       "      <td>0.376248</td>\n",
       "      <td>0.376248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>line_id_asset_S1-L1</td>\n",
       "      <td>0.344801</td>\n",
       "      <td>0.344801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>line_id_S1-L1</td>\n",
       "      <td>0.344801</td>\n",
       "      <td>0.344801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>asset_type_asset_bottle_filler</td>\n",
       "      <td>-0.312401</td>\n",
       "      <td>0.312401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>asset_type_bottle_filler</td>\n",
       "      <td>-0.312401</td>\n",
       "      <td>0.312401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>line_id_asset_S2-L2</td>\n",
       "      <td>0.306417</td>\n",
       "      <td>0.306417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>line_id_S2-L2</td>\n",
       "      <td>0.306417</td>\n",
       "      <td>0.306417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>asset_type_asset_weigh_check</td>\n",
       "      <td>-0.287646</td>\n",
       "      <td>0.287646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>asset_type_weigh_check</td>\n",
       "      <td>-0.287646</td>\n",
       "      <td>0.287646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>line_id_asset_S4-L3</td>\n",
       "      <td>0.285649</td>\n",
       "      <td>0.285649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>line_id_S4-L3</td>\n",
       "      <td>0.285649</td>\n",
       "      <td>0.285649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature      coef  abs_coef\n",
       "16                severity_max_30d  0.912779  0.912779\n",
       "4                     severity_max  0.912779  0.912779\n",
       "29                   line_id_S2-L5 -0.722313  0.722313\n",
       "71             line_id_asset_S2-L5 -0.722313  0.722313\n",
       "85       asset_type_asset_cartoner  0.479360  0.479360\n",
       "43             asset_type_cartoner  0.479360  0.479360\n",
       "36                   line_id_S4-L2 -0.456185  0.456185\n",
       "78             line_id_asset_S4-L2 -0.456185  0.456185\n",
       "9                 severity_mean_7d -0.439688  0.439688\n",
       "63             line_id_asset_S1-L2 -0.423009  0.423009\n",
       "21                   line_id_S1-L2 -0.423009  0.423009\n",
       "90    asset_type_asset_print_apply -0.409788  0.409788\n",
       "48          asset_type_print_apply -0.409788  0.409788\n",
       "67             line_id_asset_S2-L1  0.376248  0.376248\n",
       "25                   line_id_S2-L1  0.376248  0.376248\n",
       "62             line_id_asset_S1-L1  0.344801  0.344801\n",
       "20                   line_id_S1-L1  0.344801  0.344801\n",
       "83  asset_type_asset_bottle_filler -0.312401  0.312401\n",
       "41        asset_type_bottle_filler -0.312401  0.312401\n",
       "68             line_id_asset_S2-L2  0.306417  0.306417\n",
       "26                   line_id_S2-L2  0.306417  0.306417\n",
       "93    asset_type_asset_weigh_check -0.287646  0.287646\n",
       "51          asset_type_weigh_check -0.287646  0.287646\n",
       "79             line_id_asset_S4-L3  0.285649  0.285649\n",
       "37                   line_id_S4-L3  0.285649  0.285649"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features pushing toward target_event=1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>severity_max_30d</td>\n",
       "      <td>0.912779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>severity_max</td>\n",
       "      <td>0.912779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>asset_type_asset_cartoner</td>\n",
       "      <td>0.479360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>0.479360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>line_id_asset_S2-L1</td>\n",
       "      <td>0.376248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>line_id_S2-L1</td>\n",
       "      <td>0.376248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>line_id_asset_S1-L1</td>\n",
       "      <td>0.344801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>line_id_S1-L1</td>\n",
       "      <td>0.344801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>line_id_S2-L2</td>\n",
       "      <td>0.306417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>line_id_asset_S2-L2</td>\n",
       "      <td>0.306417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>line_id_S4-L3</td>\n",
       "      <td>0.285649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>line_id_asset_S4-L3</td>\n",
       "      <td>0.285649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>event_count_7d</td>\n",
       "      <td>0.275548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>asset_type_asset_blister_packer</td>\n",
       "      <td>0.274174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>asset_type_blister_packer</td>\n",
       "      <td>0.274174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature      coef\n",
       "16                 severity_max_30d  0.912779\n",
       "4                      severity_max  0.912779\n",
       "85        asset_type_asset_cartoner  0.479360\n",
       "43              asset_type_cartoner  0.479360\n",
       "67              line_id_asset_S2-L1  0.376248\n",
       "25                    line_id_S2-L1  0.376248\n",
       "62              line_id_asset_S1-L1  0.344801\n",
       "20                    line_id_S1-L1  0.344801\n",
       "26                    line_id_S2-L2  0.306417\n",
       "68              line_id_asset_S2-L2  0.306417\n",
       "37                    line_id_S4-L3  0.285649\n",
       "79              line_id_asset_S4-L3  0.285649\n",
       "8                    event_count_7d  0.275548\n",
       "82  asset_type_asset_blister_packer  0.274174\n",
       "40        asset_type_blister_packer  0.274174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features pushing toward target_event=0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-0.722313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>line_id_asset_S2-L5</td>\n",
       "      <td>-0.722313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>line_id_S4-L2</td>\n",
       "      <td>-0.456185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>line_id_asset_S4-L2</td>\n",
       "      <td>-0.456185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>severity_mean_7d</td>\n",
       "      <td>-0.439688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>line_id_asset_S1-L2</td>\n",
       "      <td>-0.423009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-0.423009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>asset_type_asset_print_apply</td>\n",
       "      <td>-0.409788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-0.409788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>asset_type_asset_bottle_filler</td>\n",
       "      <td>-0.312401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>asset_type_bottle_filler</td>\n",
       "      <td>-0.312401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>asset_type_asset_weigh_check</td>\n",
       "      <td>-0.287646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>asset_type_weigh_check</td>\n",
       "      <td>-0.287646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>line_id_asset_S4-L5</td>\n",
       "      <td>-0.275997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>-0.275997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature      coef\n",
       "29                   line_id_S2-L5 -0.722313\n",
       "71             line_id_asset_S2-L5 -0.722313\n",
       "36                   line_id_S4-L2 -0.456185\n",
       "78             line_id_asset_S4-L2 -0.456185\n",
       "9                 severity_mean_7d -0.439688\n",
       "63             line_id_asset_S1-L2 -0.423009\n",
       "21                   line_id_S1-L2 -0.423009\n",
       "90    asset_type_asset_print_apply -0.409788\n",
       "48          asset_type_print_apply -0.409788\n",
       "83  asset_type_asset_bottle_filler -0.312401\n",
       "41        asset_type_bottle_filler -0.312401\n",
       "93    asset_type_asset_weigh_check -0.287646\n",
       "51          asset_type_weigh_check -0.287646\n",
       "81             line_id_asset_S4-L5 -0.275997\n",
       "39                   line_id_S4-L5 -0.275997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time-window IoT drivers (sorted by |coef|):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>severity_max_30d</td>\n",
       "      <td>0.912779</td>\n",
       "      <td>0.912779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>severity_mean_7d</td>\n",
       "      <td>-0.439688</td>\n",
       "      <td>0.439688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>event_count_7d</td>\n",
       "      <td>0.275548</td>\n",
       "      <td>0.275548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>value_std_7d</td>\n",
       "      <td>0.271428</td>\n",
       "      <td>0.271428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>severity_mean_30d</td>\n",
       "      <td>0.266054</td>\n",
       "      <td>0.266054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>severity_max_7d</td>\n",
       "      <td>0.251576</td>\n",
       "      <td>0.251576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>event_count_30d</td>\n",
       "      <td>0.218931</td>\n",
       "      <td>0.218931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>value_std_30d</td>\n",
       "      <td>-0.171814</td>\n",
       "      <td>0.171814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>value_max_30d</td>\n",
       "      <td>0.096640</td>\n",
       "      <td>0.096640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>value_mean_7d</td>\n",
       "      <td>0.085671</td>\n",
       "      <td>0.085671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>value_mean_30d</td>\n",
       "      <td>-0.082817</td>\n",
       "      <td>0.082817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>value_max_7d</td>\n",
       "      <td>-0.058295</td>\n",
       "      <td>0.058295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature      coef  abs_coef\n",
       "16   severity_max_30d  0.912779  0.912779\n",
       "9    severity_mean_7d -0.439688  0.439688\n",
       "8      event_count_7d  0.275548  0.275548\n",
       "12       value_std_7d  0.271428  0.271428\n",
       "15  severity_mean_30d  0.266054  0.266054\n",
       "10    severity_max_7d  0.251576  0.251576\n",
       "14    event_count_30d  0.218931  0.218931\n",
       "18      value_std_30d -0.171814  0.171814\n",
       "19      value_max_30d  0.096640  0.096640\n",
       "11      value_mean_7d  0.085671  0.085671\n",
       "17     value_mean_30d -0.082817  0.082817\n",
       "13       value_max_7d -0.058295  0.058295"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/baseline_logreg_event_timewindows_coefficients.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 22 — Interpretability (time-window model): coefficients + “recency” driver focus\n",
    "#============================================================\n",
    "\n",
    "# Load feature names aligned to preprocess_event_timewindows\n",
    "feat_tw = pd.read_csv(OUT_DIR / \"feature_names_event_timewindows.csv\")[\"feature_name\"].tolist()\n",
    "coefs_tw = clf_tw.coef_.ravel()\n",
    "\n",
    "coef_tw_df = pd.DataFrame({\n",
    "    \"feature\": feat_tw,\n",
    "    \"coef\": coefs_tw,\n",
    "    \"abs_coef\": np.abs(coefs_tw),\n",
    "}).sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "print(\"Top 25 time-window features by absolute coefficient magnitude:\")\n",
    "display(coef_tw_df.head(25))\n",
    "\n",
    "print(\"\\nTop 15 features pushing toward target_event=1:\")\n",
    "display(coef_tw_df.sort_values(\"coef\", ascending=False).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "print(\"\\nTop 15 features pushing toward target_event=0:\")\n",
    "display(coef_tw_df.sort_values(\"coef\", ascending=True).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "# Focus specifically on time-windowed IoT features\n",
    "tw_prefixes = (\n",
    "    \"event_count_7d\", \"event_count_30d\",\n",
    "    \"severity_mean_7d\", \"severity_max_7d\", \"severity_mean_30d\", \"severity_max_30d\",\n",
    "    \"value_mean_7d\", \"value_std_7d\", \"value_max_7d\",\n",
    "    \"value_mean_30d\", \"value_std_30d\", \"value_max_30d\",\n",
    ")\n",
    "\n",
    "tw_drivers = coef_tw_df[coef_tw_df[\"feature\"].str.startswith(tw_prefixes)].copy()\n",
    "\n",
    "print(\"\\nTime-window IoT drivers (sorted by |coef|):\")\n",
    "display(tw_drivers.sort_values(\"abs_coef\", ascending=False).head(30))\n",
    "\n",
    "# Save coefficients\n",
    "coef_tw_path = OUT_DIR / \"baseline_logreg_event_timewindows_coefficients.csv\"\n",
    "coef_tw_df.to_csv(coef_tw_path, index=False)\n",
    "print(\"\\nSaved:\", coef_tw_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05503089-90ff-4700-aba9-cdb3a73ff17c",
   "metadata": {},
   "source": [
    "### What Cell 22 Just Did\n",
    "\n",
    "This cell interpreted the improved event-derived model that includes **7-day and 30-day** IoT aggregates. It paired the logistic regression coefficients from the time-windowed baseline with the transformed feature names produced by the corresponding preprocessing pipeline. It then ranked all features by absolute coefficient magnitude to identify the strongest drivers overall and listed the most positive and most negative coefficients to show what pushes predictions toward higher vs. lower event-derived risk. To directly answer whether recency features matter, it filtered the coefficient table down to the time-windowed IoT features (counts, severity stats, and value stats for 7d/30d) and displayed those drivers sorted by |coef|. Finally, it saved the full coefficient table to `baseline_logreg_event_timewindows_coefficients.csv` so you can reference and report these drivers without rerunning the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "579ab473-a625-45f4-8c10-126b638bc515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>vendor</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>site_name</th>\n",
       "      <th>tz</th>\n",
       "      <th>target_event</th>\n",
       "      <th>predicted_risk</th>\n",
       "      <th>risk_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0068</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0035</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995896</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0034</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L3</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995481</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0005</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989628</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0040</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>conveyor</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>Europe/Dublin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987514</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0017</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L2</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>Europe/Dublin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981607</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0073</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>case_packer</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971558</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0103</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965505</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0056</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>Europe/Dublin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.962926</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0090</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961237</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A0066</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956809</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A0101</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944787</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A0118</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L1</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932425</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A0078</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L4</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910115</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A0112</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>capper</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asset_id site_id line_id             asset_type   vendor   connectivity  \\\n",
       "0     A0068      S2   S2-L3         blister_packer  VendorA  legacy_serial   \n",
       "1     A0035      S1   S1-L1  environmental_monitor  VendorB     mqtt_opcua   \n",
       "2     A0034      S4   S4-L3               cartoner  VendorA  legacy_serial   \n",
       "3     A0005      S4   S4-L2  environmental_monitor  VendorA  legacy_serial   \n",
       "4     A0040      S3   S3-L1               conveyor  VendorA  legacy_serial   \n",
       "5     A0017      S3   S3-L2               cartoner  VendorC  legacy_serial   \n",
       "6     A0073      S1   S1-L3            case_packer  VendorD  legacy_serial   \n",
       "7     A0103      S1   S1-L3  environmental_monitor  VendorA  legacy_serial   \n",
       "8     A0056      S3   S3-L1               cartoner  VendorA  legacy_serial   \n",
       "9     A0090      S1   S1-L5         blister_packer  VendorD  legacy_serial   \n",
       "10    A0066      S1   S1-L5               cartoner  VendorB  legacy_serial   \n",
       "11    A0101      S2   S2-L5               cartoner  VendorC  legacy_serial   \n",
       "12    A0118      S2   S2-L1               cartoner  VendorB     mqtt_opcua   \n",
       "13    A0078      S1   S1-L4  environmental_monitor  VendorC  legacy_serial   \n",
       "14    A0112      S1   S1-L1                 capper  VendorA  legacy_serial   \n",
       "\n",
       "                       site_name                            tz  target_event  \\\n",
       "0      San Diego Device Assembly           America/Los_Angeles             1   \n",
       "1   Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "2          Singapore Sterile Ops                Asia/Singapore             1   \n",
       "3          Singapore Sterile Ops                Asia/Singapore             1   \n",
       "4            Dublin EU Packaging                 Europe/Dublin             1   \n",
       "5            Dublin EU Packaging                 Europe/Dublin             1   \n",
       "6   Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "7   Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "8            Dublin EU Packaging                 Europe/Dublin             1   \n",
       "9   Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "10  Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "11     San Diego Device Assembly           America/Los_Angeles             1   \n",
       "12     San Diego Device Assembly           America/Los_Angeles             1   \n",
       "13  Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "14  Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "\n",
       "    predicted_risk  risk_rank  \n",
       "0         0.996877          1  \n",
       "1         0.995896          2  \n",
       "2         0.995481          3  \n",
       "3         0.989628          4  \n",
       "4         0.987514          5  \n",
       "5         0.981607          6  \n",
       "6         0.971558          7  \n",
       "7         0.965505          8  \n",
       "8         0.962926          9  \n",
       "9         0.961237         10  \n",
       "10        0.956809         11  \n",
       "11        0.944787         12  \n",
       "12        0.932425         13  \n",
       "13        0.910115         14  \n",
       "14        0.901580         15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/asset_risk_scored_timewindows.csv\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/top_drivers_timewindows.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 23 — Score all assets: predicted risk + rank + save a business-friendly output table\n",
    "#============================================================\n",
    "\n",
    "# We'll score using the strongest baseline we have so far:\n",
    "#   event-derived + time windows (preprocess_tw + clf_tw)\n",
    "#\n",
    "# Output columns:\n",
    "# - asset_id, site_name, line_id, asset_type, vendor, connectivity\n",
    "# - target_event (actual label)\n",
    "# - predicted_risk (probability)\n",
    "# - risk_rank (1 = highest risk)\n",
    "#\n",
    "# Plus: a very small “top driver snapshot” using global coefficients (not per-row SHAP),\n",
    "# which is a simple, notebook-safe way to show what generally drives risk.\n",
    "\n",
    "scoring_df = evt_tw.copy()\n",
    "\n",
    "# Build feature matrix for scoring\n",
    "X_score = scoring_df[numeric_cols_tw + categorical_cols_tw].copy()\n",
    "y_true = scoring_df[\"target_event\"].astype(\"int8\").copy()\n",
    "\n",
    "X_score_tx = preprocess_tw.transform(X_score)\n",
    "proba = clf_tw.predict_proba(X_score_tx)[:, 1]\n",
    "\n",
    "scored = scoring_df[id_cols_tw + [\"line_id\", \"asset_type\", \"vendor\", \"connectivity\", \"site_name\", \"tz\"]].copy()\n",
    "# Only keep columns that exist (some may be absent depending on joins)\n",
    "scored = scored[[c for c in scored.columns if c in scoring_df.columns]].copy()\n",
    "\n",
    "scored[\"target_event\"] = y_true.values\n",
    "scored[\"predicted_risk\"] = proba\n",
    "scored[\"risk_rank\"] = scored[\"predicted_risk\"].rank(method=\"first\", ascending=False).astype(int)\n",
    "\n",
    "# Sort high-risk first\n",
    "scored = scored.sort_values([\"predicted_risk\", \"risk_rank\"], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "display(scored.head(15))\n",
    "\n",
    "# Save scored table\n",
    "scored_path = OUT_DIR / \"asset_risk_scored_timewindows.csv\"\n",
    "scored.to_csv(scored_path, index=False)\n",
    "print(\"Saved:\", scored_path)\n",
    "\n",
    "# Also save a compact “top drivers” list for reporting (global coefficients)\n",
    "coef_tw = pd.read_csv(OUT_DIR / \"baseline_logreg_event_timewindows_coefficients.csv\")\n",
    "top_pos = coef_tw.sort_values(\"coef\", ascending=False).head(10)[[\"feature\", \"coef\"]]\n",
    "top_neg = coef_tw.sort_values(\"coef\", ascending=True).head(10)[[\"feature\", \"coef\"]]\n",
    "\n",
    "drivers_path = OUT_DIR / \"top_drivers_timewindows.csv\"\n",
    "drivers = pd.concat(\n",
    "    [\n",
    "        top_pos.assign(direction=\"pushes_risk_up\"),\n",
    "        top_neg.assign(direction=\"pushes_risk_down\"),\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "drivers.to_csv(drivers_path, index=False)\n",
    "print(\"Saved:\", drivers_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c89a9-ed9c-4653-b630-bf7c4849692a",
   "metadata": {},
   "source": [
    "### What Cell 23 Just Did\n",
    "\n",
    "This cell produced a business-friendly “risk ranking” output by scoring every asset with the best-performing baseline model (event-derived label + time-windowed IoT features). It built a scoring feature matrix from the same numeric and categorical columns used during training, transformed it using the fitted time-window preprocessing pipeline, and generated predicted probabilities (`predicted_risk`) from the logistic regression model. It then assembled a compact scored table containing identifying/context columns (asset, site, line, type, vendor, connectivity), the true event-derived label (`target_event`), the predicted risk probability, and a rank order so you can immediately see the highest-risk assets at the top. The scored list was saved to `asset_risk_scored_timewindows.csv` in the run output directory. Finally, it saved a small “global driver” snapshot (`top_drivers_timewindows.csv`) showing the top features that generally push risk up or down according to the model coefficients, which is useful for quick reporting and slide narratives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f6e8f4f-c55c-42c8-b227-73e8cb64243f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold tradeoff table (sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.040025</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057844</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.063005</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.330325</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.331769</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.451429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.547120</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.592831</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.602149</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  precision    recall        f1\n",
       "0    0.000196   0.541667  1.000000  0.702703\n",
       "1    0.000455   0.565217  1.000000  0.722222\n",
       "2    0.001759   0.590909  1.000000  0.742857\n",
       "3    0.005122   0.619048  1.000000  0.764706\n",
       "4    0.007030   0.650000  1.000000  0.787879\n",
       "5    0.040025   0.684211  1.000000  0.812500\n",
       "6    0.057844   0.722222  1.000000  0.838710\n",
       "7    0.063005   0.764706  1.000000  0.866667\n",
       "8    0.330325   0.812500  1.000000  0.896552\n",
       "9    0.331769   0.800000  0.923077  0.857143\n",
       "10   0.451429   0.857143  0.923077  0.888889\n",
       "11   0.547120   0.923077  0.923077  0.923077\n",
       "12   0.592831   0.916667  0.846154  0.880000\n",
       "13   0.600533   0.909091  0.769231  0.833333\n",
       "14   0.602149   0.900000  0.692308  0.782609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.451429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.547120</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.592831</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.602149</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.611010</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.663162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.801117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.833366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.836609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.865775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.877910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.956809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.961237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  precision    recall        f1\n",
       "10   0.451429   0.857143  0.923077  0.888889\n",
       "11   0.547120   0.923077  0.923077  0.923077\n",
       "12   0.592831   0.916667  0.846154  0.880000\n",
       "13   0.600533   0.909091  0.769231  0.833333\n",
       "14   0.602149   0.900000  0.692308  0.782609\n",
       "15   0.611010   0.888889  0.615385  0.727273\n",
       "16   0.663162   1.000000  0.615385  0.761905\n",
       "17   0.801117   1.000000  0.538462  0.700000\n",
       "18   0.833366   1.000000  0.461538  0.631579\n",
       "19   0.836609   1.000000  0.384615  0.555556\n",
       "20   0.865775   1.000000  0.307692  0.470588\n",
       "21   0.877910   1.000000  0.230769  0.375000\n",
       "22   0.956809   1.000000  0.153846  0.266667\n",
       "23   0.961237   1.000000  0.076923  0.142857\n",
       "24   1.000000   1.000000  0.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best-F1 threshold (test split):\n",
      "threshold    0.547120\n",
      "precision    0.923077\n",
      "recall       0.923077\n",
      "f1           0.923077\n",
      "Name: 11, dtype: float64\n",
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/threshold_tradeoffs_event_timewindows.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 24 — Add model evaluation “threshold table” (precision/recall tradeoffs) + save\n",
    "#============================================================\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Recompute probabilities on the test split we used in Cell 21 (Xte_tx, yte)\n",
    "# We still have: Xte_tx, yte, clf_tw\n",
    "proba_test = clf_tw.predict_proba(Xte_tx)[:, 1]\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(yte, proba_test)\n",
    "\n",
    "# precision_recall_curve returns arrays where thresholds has length = len(precisions)-1\n",
    "thr = np.append(thresholds, 1.0)\n",
    "\n",
    "thr_df = pd.DataFrame({\n",
    "    \"threshold\": thr,\n",
    "    \"precision\": precisions,\n",
    "    \"recall\": recalls,\n",
    "})\n",
    "\n",
    "# Add an approximate F1 at each threshold for selection guidance\n",
    "thr_df[\"f1\"] = (2 * thr_df[\"precision\"] * thr_df[\"recall\"]) / (thr_df[\"precision\"] + thr_df[\"recall\"])\n",
    "thr_df[\"f1\"] = thr_df[\"f1\"].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Sort by threshold ascending for readability\n",
    "thr_df = thr_df.sort_values(\"threshold\").reset_index(drop=True)\n",
    "\n",
    "print(\"Threshold tradeoff table (sample):\")\n",
    "display(thr_df.head(15))\n",
    "display(thr_df.tail(15))\n",
    "\n",
    "# Identify “best F1” threshold (on this test split — for reference only)\n",
    "best_idx = thr_df[\"f1\"].idxmax()\n",
    "best_row = thr_df.loc[best_idx]\n",
    "print(\"\\nBest-F1 threshold (test split):\")\n",
    "print(best_row)\n",
    "\n",
    "# Save\n",
    "thr_path = OUT_DIR / \"threshold_tradeoffs_event_timewindows.csv\"\n",
    "thr_df.to_csv(thr_path, index=False)\n",
    "print(\"\\nSaved:\", thr_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483967c7-bfdd-4527-93e2-710eda27a0c6",
   "metadata": {},
   "source": [
    "### What Cell 24 Just Did\n",
    "\n",
    "This cell quantified the precision/recall tradeoff for the time-windowed event-derived model so you can choose an operating threshold that matches the business use case. Using the model’s predicted probabilities on the held-out test set, it computed a full precision–recall curve across many possible decision thresholds. It assembled those results into a threshold table containing `threshold`, `precision`, and `recall`, and it added an approximate `f1` score at each threshold to provide a simple selection heuristic. It also identified the threshold that maximizes F1 on the test split (useful as a reference point, not a final production choice). Finally, it saved the complete threshold tradeoff table to `threshold_tradeoffs_event_timewindows.csv` in the run output directory, enabling you to document and justify the chosen decision threshold in reports or downstream scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76d46054-bd1e-4faa-87ba-94742a79a730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/RUN_SUMMARY.md\n",
      "\n",
      "Preview (tail):\n",
      "\n",
      "- `preprocess.joblib`\n",
      "- `feature_names.csv`\n",
      "- `X_train.npy`\n",
      "- `X_test.npy`\n",
      "- `y_train.npy`\n",
      "- `y_test.npy`\n",
      "- `ids_train.parquet`\n",
      "- `ids_test.parquet`\n",
      "- `qa_summary.json`\n",
      "- `baseline_logreg.joblib`\n",
      "- `baseline_logreg_metrics.json`\n",
      "- `baseline_logreg_coefficients.csv`\n",
      "\n",
      "## Proxy Label Baseline (Important Note)\n",
      "\n",
      "- The original proxy-label baseline used features that directly defined the proxy label (label leakage).\n",
      "- The 1.000 metrics under **Baseline Model (Logistic Regression)** above are therefore not meaningful.\n",
      "- Use the **No-Leak Proxy Baseline** below for an honest proxy-label reference point.\n",
      "\n",
      "### No-Leak Proxy Baseline (Logistic Regression)\n",
      "- **Accuracy:** 0.542\n",
      "- **Precision:** 0.600\n",
      "- **Recall:** 0.462\n",
      "- **F1:** 0.522\n",
      "- **ROC AUC:** 0.503\n",
      "- **Dropped leakage columns:** `connectivity`, `connectivity_asset`, `is_legacy`, `is_legacy_asset`\n",
      "\n",
      "### No-Leak Proxy Artifacts\n",
      "- `feature_columns_noleak.json`\n",
      "- `preprocess_noleak.joblib`\n",
      "- `baseline_logreg_noleak.joblib`\n",
      "- `baseline_logreg_noleak_metrics.json`\n",
      "- `baseline_logreg_noleak_coefficients.csv`\n",
      "- `baseline_comparison_leak_vs_noleak.csv`\n",
      "\n",
      "\n",
      "## Event-Derived Label + Baseline\n",
      "\n",
      "- **Event-derived label:** `target_event` (from `iot_event_labels_by_asset.csv`)\n",
      "- **IoT aggregates added:** `event_count`, `severity_*`, `value_*`\n",
      "- **Accuracy:** 0.792\n",
      "- **Precision:** 0.833\n",
      "- **Recall:** 0.769\n",
      "- **F1:** 0.800\n",
      "- **ROC AUC:** 0.944\n",
      "\n",
      "### Top Event-Derived Drivers (by |coef|)\n",
      "- `severity_max` (coef=1.544)\n",
      "- `line_id_S2-L5` (coef=-0.746)\n",
      "- `line_id_asset_S2-L5` (coef=-0.746)\n",
      "- `severity_mean` (coef=0.476)\n",
      "- `line_id_asset_S4-L2` (coef=-0.459)\n",
      "\n",
      "### Event-Derived Artifacts\n",
      "- `iot_event_aggregates_by_asset.csv`\n",
      "- `iot_event_labels_by_asset.csv`\n",
      "- `event_derived_model_table.parquet`\n",
      "- `preprocess_event.joblib`\n",
      "- `feature_names_event.csv`\n",
      "- `baseline_logreg_event.joblib`\n",
      "- `baseline_logreg_event_metrics.json`\n",
      "- `baseline_logreg_event_coefficients.csv`\n",
      "\n",
      "## Event-Derived + Time Windows Baseline\n",
      "\n",
      "- **Dataset:** `event_derived_model_table_timewindows.parquet`\n",
      "- **Model:** Logistic Regression (balanced)\n",
      "- **Features:** asset master + IoT aggregates + 7d/30d window aggregates\n",
      "- **Accuracy:** 0.917\n",
      "- **Precision:** 0.923\n",
      "- **Recall:** 0.923\n",
      "- **F1:** 0.923\n",
      "- **ROC AUC:** 0.951\n",
      "\n",
      "### Suggested Operating Threshold (based on test-split best F1)\n",
      "- **Threshold:** 0.547120\n",
      "- **Precision @ threshold:** 0.923\n",
      "- **Recall @ threshold:** 0.923\n",
      "- **F1 @ threshold:** 0.923\n",
      "\n",
      "### Time-Window Model Artifacts\n",
      "- `event_derived_model_table_timewindows.parquet`\n",
      "- `preprocess_event_timewindows.joblib`\n",
      "- `feature_names_event_timewindows.csv`\n",
      "- `baseline_logreg_event_timewindows.joblib`\n",
      "- `baseline_logreg_event_timewindows_metrics.json`\n",
      "- `baseline_logreg_event_timewindows_coefficients.csv`\n",
      "- `threshold_tradeoffs_event_timewindows.csv`\n",
      "- `asset_risk_scored_timewindows.csv`\n",
      "- `top_drivers_timewindows.csv`\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 25 — Update RUN_SUMMARY with time-window model + scoring outputs + suggested threshold\n",
    "#============================================================\n",
    "\n",
    "summary_path = OUT_DIR / \"RUN_SUMMARY.md\"\n",
    "text = summary_path.read_text() if summary_path.exists() else \"\"\n",
    "\n",
    "# Load time-window metrics\n",
    "tw_metrics_path = OUT_DIR / \"baseline_logreg_event_timewindows_metrics.json\"\n",
    "tw_metrics = json.loads(tw_metrics_path.read_text()) if tw_metrics_path.exists() else {}\n",
    "\n",
    "# Load “best F1 threshold” info from Cell 24 by recomputing (lightweight) or reading table\n",
    "thr_path = OUT_DIR / \"threshold_tradeoffs_event_timewindows.csv\"\n",
    "thr_df = pd.read_csv(thr_path) if thr_path.exists() else pd.DataFrame()\n",
    "\n",
    "best_thr = None\n",
    "best_f1 = None\n",
    "best_prec = None\n",
    "best_rec = None\n",
    "if not thr_df.empty and \"f1\" in thr_df.columns:\n",
    "    best_row = thr_df.loc[thr_df[\"f1\"].idxmax()]\n",
    "    best_thr = float(best_row[\"threshold\"])\n",
    "    best_f1 = float(best_row[\"f1\"])\n",
    "    best_prec = float(best_row[\"precision\"])\n",
    "    best_rec = float(best_row[\"recall\"])\n",
    "\n",
    "# Build a new block\n",
    "block = []\n",
    "block.append(\"## Event-Derived + Time Windows Baseline\")\n",
    "block.append(\"\")\n",
    "block.append(\"- **Dataset:** `event_derived_model_table_timewindows.parquet`\")\n",
    "block.append(\"- **Model:** Logistic Regression (balanced)\")\n",
    "block.append(\"- **Features:** asset master + IoT aggregates + 7d/30d window aggregates\")\n",
    "if tw_metrics:\n",
    "    block.append(f\"- **Accuracy:** {tw_metrics.get('accuracy'):.3f}\")\n",
    "    block.append(f\"- **Precision:** {tw_metrics.get('precision'):.3f}\")\n",
    "    block.append(f\"- **Recall:** {tw_metrics.get('recall'):.3f}\")\n",
    "    block.append(f\"- **F1:** {tw_metrics.get('f1'):.3f}\")\n",
    "    if tw_metrics.get(\"roc_auc\") is not None:\n",
    "        block.append(f\"- **ROC AUC:** {tw_metrics.get('roc_auc'):.3f}\")\n",
    "block.append(\"\")\n",
    "if best_thr is not None:\n",
    "    block.append(\"### Suggested Operating Threshold (based on test-split best F1)\")\n",
    "    block.append(f\"- **Threshold:** {best_thr:.6f}\")\n",
    "    block.append(f\"- **Precision @ threshold:** {best_prec:.3f}\")\n",
    "    block.append(f\"- **Recall @ threshold:** {best_rec:.3f}\")\n",
    "    block.append(f\"- **F1 @ threshold:** {best_f1:.3f}\")\n",
    "    block.append(\"\")\n",
    "block.append(\"### Time-Window Model Artifacts\")\n",
    "for a in [\n",
    "    \"event_derived_model_table_timewindows.parquet\",\n",
    "    \"preprocess_event_timewindows.joblib\",\n",
    "    \"feature_names_event_timewindows.csv\",\n",
    "    \"baseline_logreg_event_timewindows.joblib\",\n",
    "    \"baseline_logreg_event_timewindows_metrics.json\",\n",
    "    \"baseline_logreg_event_timewindows_coefficients.csv\",\n",
    "    \"threshold_tradeoffs_event_timewindows.csv\",\n",
    "    \"asset_risk_scored_timewindows.csv\",\n",
    "    \"top_drivers_timewindows.csv\",\n",
    "]:\n",
    "    p = OUT_DIR / a\n",
    "    if p.exists():\n",
    "        block.append(f\"- `{a}`\")\n",
    "block.append(\"\")\n",
    "\n",
    "block_text = \"\\n\".join(block)\n",
    "\n",
    "# Insert/replace after Event-Derived Label + Baseline section (best-effort)\n",
    "hdr = \"## Event-Derived + Time Windows Baseline\"\n",
    "if hdr in text:\n",
    "    # Replace existing block from hdr to the next section header or end\n",
    "    pre, post = text.split(hdr, 1)\n",
    "    # remove the old block content (up to next \"## \" header)\n",
    "    rest = hdr + post\n",
    "    lines = rest.splitlines()\n",
    "    # find next header after the first line\n",
    "    cut = None\n",
    "    for i in range(1, len(lines)):\n",
    "        if lines[i].startswith(\"## \") and lines[i] != hdr:\n",
    "            cut = i\n",
    "            break\n",
    "    if cut is None:\n",
    "        text = pre.rstrip() + \"\\n\\n\" + block_text\n",
    "    else:\n",
    "        text = pre.rstrip() + \"\\n\\n\" + block_text + \"\\n\" + \"\\n\".join(lines[cut:])\n",
    "else:\n",
    "    # Append to end\n",
    "    text = text.rstrip() + \"\\n\\n\" + block_text\n",
    "\n",
    "summary_path.write_text(text)\n",
    "print(\"Updated:\", summary_path)\n",
    "\n",
    "print(\"\\nPreview (tail):\\n\")\n",
    "print(\"\\n\".join(text.splitlines()[-90:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b4da00-eec1-4505-8ede-5fd6e8e5e107",
   "metadata": {},
   "source": [
    "### What Cell 25 Just Did\n",
    "\n",
    "This cell updated your `RUN_SUMMARY.md` to include the strongest baseline you’ve built so far: the event-derived model augmented with 7-day and 30-day time-window aggregates. It loaded the saved metrics for the time-window model, extracted the best-F1 operating threshold from the threshold tradeoff table, and wrote a new summary section documenting performance, the recommended threshold, and the key artifacts produced (time-window dataset, preprocessor, model, coefficients, threshold table, and the scored asset risk list). Finally, it saved the updated run summary so the run’s “receipt” fully reflects the most actionable outputs and the most defensible modeling path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "432fd08f-276a-484a-bb06-f6e108c5440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_name</th>\n",
       "      <th>n_assets</th>\n",
       "      <th>avg_predicted_risk</th>\n",
       "      <th>pct_high_risk</th>\n",
       "      <th>n_high_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>38</td>\n",
       "      <td>0.579779</td>\n",
       "      <td>50.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>31</td>\n",
       "      <td>0.507261</td>\n",
       "      <td>54.8</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>26</td>\n",
       "      <td>0.460783</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>25</td>\n",
       "      <td>0.446306</td>\n",
       "      <td>48.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      site_name  n_assets  avg_predicted_risk  pct_high_risk  \\\n",
       "1  Indianapolis Packaging Plant        38            0.579779           50.0   \n",
       "3         Singapore Sterile Ops        31            0.507261           54.8   \n",
       "2     San Diego Device Assembly        26            0.460783           50.0   \n",
       "0           Dublin EU Packaging        25            0.446306           48.0   \n",
       "\n",
       "   n_high_risk  \n",
       "1           19  \n",
       "3           17  \n",
       "2           13  \n",
       "0           12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Line summary (top 20 by avg risk):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_name</th>\n",
       "      <th>line_id</th>\n",
       "      <th>n_assets</th>\n",
       "      <th>avg_predicted_risk</th>\n",
       "      <th>pct_high_risk</th>\n",
       "      <th>n_high_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>S2-L1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797027</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>S4-L3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>83.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.706206</td>\n",
       "      <td>77.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>S2-L2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.678459</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>S3-L2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.665889</td>\n",
       "      <td>66.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.665700</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.650299</td>\n",
       "      <td>66.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>S4-L4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.624533</td>\n",
       "      <td>66.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>S1-L4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.598954</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.588776</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>S4-L1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.572508</td>\n",
       "      <td>66.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.512960</td>\n",
       "      <td>42.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.433926</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>45.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>S3-L3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.358846</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.321698</td>\n",
       "      <td>22.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>S4-L5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.297451</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>S3-L4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.292084</td>\n",
       "      <td>33.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>S2-L4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.279085</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.244560</td>\n",
       "      <td>14.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       site_name line_id  n_assets  avg_predicted_risk  \\\n",
       "10     San Diego Device Assembly   S2-L1         2            0.797027   \n",
       "17         Singapore Sterile Ops   S4-L3         6            0.742960   \n",
       "5   Indianapolis Packaging Plant   S1-L1         9            0.706206   \n",
       "11     San Diego Device Assembly   S2-L2         5            0.678459   \n",
       "1            Dublin EU Packaging   S3-L2         3            0.665889   \n",
       "12     San Diego Device Assembly   S2-L3         5            0.665700   \n",
       "0            Dublin EU Packaging   S3-L1         3            0.650299   \n",
       "18         Singapore Sterile Ops   S4-L4         6            0.624533   \n",
       "8   Indianapolis Packaging Plant   S1-L4         6            0.598954   \n",
       "7   Indianapolis Packaging Plant   S1-L3        10            0.588776   \n",
       "15         Singapore Sterile Ops   S4-L1         6            0.572508   \n",
       "9   Indianapolis Packaging Plant   S1-L5         7            0.512960   \n",
       "6   Indianapolis Packaging Plant   S1-L2         6            0.433926   \n",
       "4            Dublin EU Packaging   S3-L5        11            0.412600   \n",
       "2            Dublin EU Packaging   S3-L3         5            0.358846   \n",
       "16         Singapore Sterile Ops   S4-L2         9            0.321698   \n",
       "19         Singapore Sterile Ops   S4-L5         4            0.297451   \n",
       "3            Dublin EU Packaging   S3-L4         3            0.292084   \n",
       "13     San Diego Device Assembly   S2-L4         7            0.279085   \n",
       "14     San Diego Device Assembly   S2-L5         7            0.244560   \n",
       "\n",
       "    pct_high_risk  n_high_risk  \n",
       "10          100.0            2  \n",
       "17           83.3            5  \n",
       "5            77.8            7  \n",
       "11           80.0            4  \n",
       "1            66.7            2  \n",
       "12           80.0            4  \n",
       "0            66.7            2  \n",
       "18           66.7            4  \n",
       "8            50.0            3  \n",
       "7            50.0            5  \n",
       "15           66.7            4  \n",
       "9            42.9            3  \n",
       "6            16.7            1  \n",
       "4            45.5            5  \n",
       "2            40.0            2  \n",
       "16           22.2            2  \n",
       "19           50.0            2  \n",
       "3            33.3            1  \n",
       "13           28.6            2  \n",
       "14           14.3            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 assets by predicted risk:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>vendor</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>site_name</th>\n",
       "      <th>tz</th>\n",
       "      <th>target_event</th>\n",
       "      <th>predicted_risk</th>\n",
       "      <th>risk_rank</th>\n",
       "      <th>flag_high_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0068</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0035</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995896</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0034</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L3</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995481</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0005</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989628</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0040</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>conveyor</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>Europe/Dublin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987514</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0017</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L2</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>Europe/Dublin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981607</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0073</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>case_packer</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971558</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0103</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965505</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0056</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>Europe/Dublin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.962926</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0090</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961237</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A0066</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956809</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A0101</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944787</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A0118</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L1</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932425</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A0078</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L4</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910115</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A0112</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>capper</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A0025</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>bottle_filler</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.901175</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A0055</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L4</td>\n",
       "      <td>labeler</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895479</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A0044</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889341</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A0061</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882419</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A0006</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L3</td>\n",
       "      <td>capper</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>1</td>\n",
       "      <td>0.877910</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asset_id site_id line_id             asset_type   vendor   connectivity  \\\n",
       "0     A0068      S2   S2-L3         blister_packer  VendorA  legacy_serial   \n",
       "1     A0035      S1   S1-L1  environmental_monitor  VendorB     mqtt_opcua   \n",
       "2     A0034      S4   S4-L3               cartoner  VendorA  legacy_serial   \n",
       "3     A0005      S4   S4-L2  environmental_monitor  VendorA  legacy_serial   \n",
       "4     A0040      S3   S3-L1               conveyor  VendorA  legacy_serial   \n",
       "5     A0017      S3   S3-L2               cartoner  VendorC  legacy_serial   \n",
       "6     A0073      S1   S1-L3            case_packer  VendorD  legacy_serial   \n",
       "7     A0103      S1   S1-L3  environmental_monitor  VendorA  legacy_serial   \n",
       "8     A0056      S3   S3-L1               cartoner  VendorA  legacy_serial   \n",
       "9     A0090      S1   S1-L5         blister_packer  VendorD  legacy_serial   \n",
       "10    A0066      S1   S1-L5               cartoner  VendorB  legacy_serial   \n",
       "11    A0101      S2   S2-L5               cartoner  VendorC  legacy_serial   \n",
       "12    A0118      S2   S2-L1               cartoner  VendorB     mqtt_opcua   \n",
       "13    A0078      S1   S1-L4  environmental_monitor  VendorC  legacy_serial   \n",
       "14    A0112      S1   S1-L1                 capper  VendorA  legacy_serial   \n",
       "15    A0025      S1   S1-L1          bottle_filler  VendorD  legacy_serial   \n",
       "16    A0055      S4   S4-L4                labeler  VendorC     mqtt_opcua   \n",
       "17    A0044      S1   S1-L1         blister_packer  VendorA     mqtt_opcua   \n",
       "18    A0061      S1   S1-L3               cartoner  VendorB     mqtt_opcua   \n",
       "19    A0006      S4   S4-L3                 capper  VendorB  legacy_serial   \n",
       "\n",
       "                       site_name                            tz  target_event  \\\n",
       "0      San Diego Device Assembly           America/Los_Angeles             1   \n",
       "1   Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "2          Singapore Sterile Ops                Asia/Singapore             1   \n",
       "3          Singapore Sterile Ops                Asia/Singapore             1   \n",
       "4            Dublin EU Packaging                 Europe/Dublin             1   \n",
       "5            Dublin EU Packaging                 Europe/Dublin             1   \n",
       "6   Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "7   Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "8            Dublin EU Packaging                 Europe/Dublin             1   \n",
       "9   Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "10  Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "11     San Diego Device Assembly           America/Los_Angeles             1   \n",
       "12     San Diego Device Assembly           America/Los_Angeles             1   \n",
       "13  Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "14  Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "15  Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "16         Singapore Sterile Ops                Asia/Singapore             1   \n",
       "17  Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "18  Indianapolis Packaging Plant  America/Indiana/Indianapolis             1   \n",
       "19         Singapore Sterile Ops                Asia/Singapore             1   \n",
       "\n",
       "    predicted_risk  risk_rank  flag_high_risk  \n",
       "0         0.996877          1               1  \n",
       "1         0.995896          2               1  \n",
       "2         0.995481          3               1  \n",
       "3         0.989628          4               1  \n",
       "4         0.987514          5               1  \n",
       "5         0.981607          6               1  \n",
       "6         0.971558          7               1  \n",
       "7         0.965505          8               1  \n",
       "8         0.962926          9               1  \n",
       "9         0.961237         10               1  \n",
       "10        0.956809         11               1  \n",
       "11        0.944787         12               1  \n",
       "12        0.932425         13               1  \n",
       "13        0.910115         14               1  \n",
       "14        0.901580         15               1  \n",
       "15        0.901175         16               1  \n",
       "16        0.895479         17               1  \n",
       "17        0.889341         18               1  \n",
       "18        0.882419         19               1  \n",
       "19        0.877910         20               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/report_site_summary.csv\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/report_line_summary.csv\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/report_top20_assets.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 26 — reate a compact “report table” for slides: site/line summaries + top risks\n",
    "#============================================================\n",
    "\n",
    "# We will summarize the scored output into:\n",
    "# 1) site-level: count assets, avg predicted risk, % above threshold\n",
    "# 2) line-level: same\n",
    "# 3) a Top-20 risk table for quick executive consumption\n",
    "\n",
    "scored_path = OUT_DIR / \"asset_risk_scored_timewindows.csv\"\n",
    "scored = pd.read_csv(scored_path)\n",
    "\n",
    "threshold = 0.547120  # from Cell 24 best-F1 (documented in RUN_SUMMARY)\n",
    "scored[\"flag_high_risk\"] = (scored[\"predicted_risk\"] >= threshold).astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Site-level summary\n",
    "# -----------------------------\n",
    "site_summary = (\n",
    "    scored.groupby([\"site_name\"])\n",
    "    .agg(\n",
    "        n_assets=(\"asset_id\", \"count\"),\n",
    "        avg_predicted_risk=(\"predicted_risk\", \"mean\"),\n",
    "        pct_high_risk=(\"flag_high_risk\", \"mean\"),\n",
    "        n_high_risk=(\"flag_high_risk\", \"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "site_summary[\"pct_high_risk\"] = (site_summary[\"pct_high_risk\"] * 100).round(1)\n",
    "site_summary = site_summary.sort_values([\"avg_predicted_risk\", \"n_assets\"], ascending=[False, False])\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Line-level summary\n",
    "# -----------------------------\n",
    "line_summary = (\n",
    "    scored.groupby([\"site_name\", \"line_id\"])\n",
    "    .agg(\n",
    "        n_assets=(\"asset_id\", \"count\"),\n",
    "        avg_predicted_risk=(\"predicted_risk\", \"mean\"),\n",
    "        pct_high_risk=(\"flag_high_risk\", \"mean\"),\n",
    "        n_high_risk=(\"flag_high_risk\", \"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "line_summary[\"pct_high_risk\"] = (line_summary[\"pct_high_risk\"] * 100).round(1)\n",
    "line_summary = line_summary.sort_values([\"avg_predicted_risk\", \"n_assets\"], ascending=[False, False])\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Top risks\n",
    "# -----------------------------\n",
    "top20 = scored.sort_values(\"predicted_risk\", ascending=False).head(20).copy()\n",
    "\n",
    "print(\"Site summary:\")\n",
    "display(site_summary)\n",
    "\n",
    "print(\"\\nLine summary (top 20 by avg risk):\")\n",
    "display(line_summary.head(20))\n",
    "\n",
    "print(\"\\nTop 20 assets by predicted risk:\")\n",
    "display(top20)\n",
    "\n",
    "# Save outputs\n",
    "site_path = OUT_DIR / \"report_site_summary.csv\"\n",
    "line_path = OUT_DIR / \"report_line_summary.csv\"\n",
    "top20_path = OUT_DIR / \"report_top20_assets.csv\"\n",
    "\n",
    "site_summary.to_csv(site_path, index=False)\n",
    "line_summary.to_csv(line_path, index=False)\n",
    "top20.to_csv(top20_path, index=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", site_path)\n",
    "print(\" \", line_path)\n",
    "print(\" \", top20_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dba0736-c662-4f54-ba34-7c2c9ee0d7af",
   "metadata": {},
   "source": [
    "### What Cell 26 Just Did\n",
    "\n",
    "This cell generated compact, presentation-ready summary tables from the scored asset risk output. Using the operating threshold (0.547120), it flagged assets as “high risk” when their predicted probability met or exceeded the threshold. It then produced a **site-level** summary showing the number of assets, average predicted risk, count of high-risk assets, and percent high-risk per site. It also produced a **line-level** summary with the same metrics, broken down by site and line, and sorted to surface the highest-risk lines. Finally, it created a **Top 20 assets** table ranked by predicted risk for quick executive review. All three outputs were saved as CSV files (`report_site_summary.csv`, `report_line_summary.csv`, and `report_top20_assets.csv`) so they can be dropped directly into slides or a written report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdeeaa57-e97a-4a0e-aaa4-7200babef72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251212T181645Z/EXPORTS.json\n",
      "\n",
      "Added keys:\n",
      " - EVENT_MODEL_TABLE_TIMEWINDOWS\n",
      " - EVENT_PREPROCESS_TIMEWINDOWS\n",
      " - EVENT_BASELINE_METRICS_TIMEWINDOWS\n",
      " - EVENT_COEFFICIENTS_TIMEWINDOWS\n",
      " - THRESHOLD_TRADEOFFS_TIMEWINDOWS\n",
      " - SCORED_ASSET_RISK_TIMEWINDOWS\n",
      " - TOP_DRIVERS_TIMEWINDOWS\n",
      " - REPORT_SITE_SUMMARY\n",
      " - REPORT_LINE_SUMMARY\n",
      " - REPORT_TOP20_ASSETS\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 27 — Notebook wrap-up: append “report exports” to EXPORTS.json\n",
    "#============================================================\n",
    "\n",
    "exports_path = OUT_DIR / \"EXPORTS.json\"\n",
    "exports = json.loads(Path(exports_path).read_text()) if exports_path.exists() else {}\n",
    "\n",
    "# Add report outputs + time-window artifacts\n",
    "exports_updates = {\n",
    "    \"EVENT_MODEL_TABLE_TIMEWINDOWS\": str((OUT_DIR / \"event_derived_model_table_timewindows.parquet\").resolve()),\n",
    "    \"EVENT_PREPROCESS_TIMEWINDOWS\": str((OUT_DIR / \"preprocess_event_timewindows.joblib\").resolve()),\n",
    "    \"EVENT_BASELINE_METRICS_TIMEWINDOWS\": str((OUT_DIR / \"baseline_logreg_event_timewindows_metrics.json\").resolve()),\n",
    "    \"EVENT_COEFFICIENTS_TIMEWINDOWS\": str((OUT_DIR / \"baseline_logreg_event_timewindows_coefficients.csv\").resolve()),\n",
    "    \"THRESHOLD_TRADEOFFS_TIMEWINDOWS\": str((OUT_DIR / \"threshold_tradeoffs_event_timewindows.csv\").resolve()),\n",
    "    \"SCORED_ASSET_RISK_TIMEWINDOWS\": str((OUT_DIR / \"asset_risk_scored_timewindows.csv\").resolve()),\n",
    "    \"TOP_DRIVERS_TIMEWINDOWS\": str((OUT_DIR / \"top_drivers_timewindows.csv\").resolve()),\n",
    "    \"REPORT_SITE_SUMMARY\": str((OUT_DIR / \"report_site_summary.csv\").resolve()),\n",
    "    \"REPORT_LINE_SUMMARY\": str((OUT_DIR / \"report_line_summary.csv\").resolve()),\n",
    "    \"REPORT_TOP20_ASSETS\": str((OUT_DIR / \"report_top20_assets.csv\").resolve()),\n",
    "}\n",
    "\n",
    "exports.update(exports_updates)\n",
    "\n",
    "with open(exports_path, \"w\") as f:\n",
    "    json.dump(exports, f, indent=2)\n",
    "\n",
    "print(\"Updated:\", exports_path)\n",
    "print(\"\\nAdded keys:\")\n",
    "for k in exports_updates:\n",
    "    print(\" -\", k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e7b39-f38d-4c56-b2ea-7880e3bc5882",
   "metadata": {},
   "source": [
    "### What Cell 27 Just Did\n",
    "\n",
    "This cell updated your `EXPORTS.json` “exports map” so the newest and most actionable outputs are included automatically. It loaded the existing exports file created earlier, then added entries for the time-windowed event-derived dataset, the corresponding preprocessor/model artifacts, the threshold tradeoff table, the scored asset risk output, the global driver snapshot, and the slide-ready report summaries (site, line, and top-20 assets). Finally, it rewrote `EXPORTS.json` in place and printed the keys that were added, ensuring downstream notebooks can reliably pick up these new artifacts without any manual path copying.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f098f0f4-8acd-41f6-8311-981f99fbac62",
   "metadata": {},
   "source": [
    "## Notebook Summary — `02_feature_engineering_and_labels.ipynb`\n",
    "\n",
    "This notebook built a complete, reproducible feature-engineering and labeling pipeline for the **gmp-packaging-risk-analytics** project, producing ready-to-model datasets and a set of artifacts that downstream notebooks can load without rework. It started by establishing run metadata and standardized output paths under a timestamped run directory, then validated the project’s data folders and located the available raw inputs (`assets_master.csv`, `sites_master.csv`, and `iot_events.parquet`). After enriching the master asset table with site context, it attempted a simple **proxy label** (based on legacy status and connectivity), but the notebook explicitly detected and corrected **label leakage** by rebuilding a “no-leak” proxy baseline once it was clear the label-defining columns were being used as features.\n",
    "\n",
    "The notebook then pivoted to a more defensible approach: it leveraged **IoT event data** to create an **event-derived label** and a set of per-asset aggregates (event volume and severity/value statistics). Using this event-derived label, it trained and evaluated a baseline logistic regression model that performed substantially better than the leakage-free proxy baseline. Next, it strengthened the event-derived feature set by adding **time-windowed aggregates** (7-day and 30-day trailing metrics using `ts_utc`), and retrained the model—improving performance further and producing a high-quality baseline with strong ROC AUC.\n",
    "\n",
    "Finally, the notebook operationalized the model outputs: it generated an all-asset **risk score and rank** table, computed **threshold tradeoffs** (precision/recall/F1 across decision thresholds) and captured a recommended operating point, and produced slide-ready **site and line summaries** plus a **Top-20 risk list** for executive reporting. All key paths were consolidated into `EXPORTS.json`, and the run was documented end-to-end in an updated `RUN_SUMMARY.md` so the work is traceable, auditable, and easy to reproduce.\n",
    "\n",
    "### Key Outputs Created (Run Directory)\n",
    "- `RUN_SUMMARY.md` — full “receipt” of the run, including leakage note, baselines, metrics, threshold, and artifacts  \n",
    "- `EXPORTS.json` — single source of truth for all downstream paths  \n",
    "- Event-derived modeling tables:\n",
    "  - `event_derived_model_table.parquet`\n",
    "  - `event_derived_model_table_timewindows.parquet`\n",
    "- Best-performing baseline artifacts (time windows):\n",
    "  - `preprocess_event_timewindows.joblib`\n",
    "  - `baseline_logreg_event_timewindows.joblib`\n",
    "  - `baseline_logreg_event_timewindows_metrics.json`\n",
    "  - `baseline_logreg_event_timewindows_coefficients.csv`\n",
    "  - `threshold_tradeoffs_event_timewindows.csv`\n",
    "- Operational/report outputs:\n",
    "  - `asset_risk_scored_timewindows.csv`\n",
    "  - `report_site_summary.csv`\n",
    "  - `report_line_summary.csv`\n",
    "  - `report_top20_assets.csv`\n",
    "  - `top_drivers_timewindows.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23641bb4-5f7c-44a4-8b67-d8b280da8bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gmp-packaging-risk-analytics)",
   "language": "python",
   "name": "gmp-packaging-risk-analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
