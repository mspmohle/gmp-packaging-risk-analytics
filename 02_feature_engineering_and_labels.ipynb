{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8bd1ef-8045-4ea4-91ae-cd0db376b0de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 02 – Feature Engineering & Risk Labels\n",
    "\n",
    "This notebook consumes the synthetic IIoT event stream and master data generated in `01_synthetic_iot_data_generator.ipynb` and turns it into model-ready features and labels.\n",
    "\n",
    "**Goals**\n",
    "\n",
    "- Join **event logs** with **asset** and **site** metadata.\n",
    "- Engineer time-based features at an `asset_id × local_date` grain (counts, durations, severities).\n",
    "- Create **risk labels**, for example:\n",
    "  - *next-day failure* (binary)\n",
    "  - *high-risk operating window* based on recent anomalies.\n",
    "- Produce tidy feature tables saved under `data/interim/` and `data/results/` for:\n",
    "  - downstream model notebooks (e.g., classification, survival),\n",
    "  - and dashboard backends (FastAPI + DuckDB).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ad2dd9-fd5e-4a16-b795-ca77a1ca5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Notebook-wide warning controls (keep output clean)\n",
    "# ============================================================\n",
    "import warnings\n",
    "\n",
    "# Show each warning at most once (optional; keeps noise down without hiding everything)\n",
    "warnings.simplefilter(\"once\")\n",
    "\n",
    "# Pandas: DatetimeProperties.to_pydatetime deprecation warning\n",
    "# (message text varies slightly across pandas versions, so match broadly)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=r\".*to_pydatetime.*deprecated.*\",\n",
    "    module=r\"pandas\\..*\",\n",
    ")\n",
    "\n",
    "# Pandas: GroupBy.apply deprecation warning (grouping columns behavior changing)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=r\".*DataFrameGroupBy\\.apply operated on the grouping columns.*\",\n",
    "    module=r\"pandas\\..*\",\n",
    ")\n",
    "\n",
    "# Optional: if warnings are emitted from your notebook file path rather than pandas,\n",
    "# also ignore them regardless of module.\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=r\".*to_pydatetime.*deprecated.*\",\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=r\".*DataFrameGroupBy\\.apply operated on the grouping columns.*\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbf58a9-39b1-4949-a2ba-241ff0f27d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /home/parallels/projects/gmp-packaging-risk-analytics\n",
      "OUT_DIR: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z\n",
      "{\n",
      "  \"run_ts_utc\": \"20251220T211621Z\",\n",
      "  \"project_root\": \"/home/parallels/projects/gmp-packaging-risk-analytics\",\n",
      "  \"python\": \"3.11.14 | packaged by conda-forge | (main, Oct 22 2025, 22:39:18) [GCC 14.3.0]\",\n",
      "  \"pandas\": \"2.3.3\",\n",
      "  \"numpy\": \"2.3.5\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 1 — Setup: imports, RNG seed, project paths, and run metadata\n",
    "#============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn (feature engineering + reproducible preprocessing)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# optional: artifact persistence\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# Resolve project root robustly\n",
    "# -----------------------------\n",
    "# Strategy:\n",
    "# 1) Prefer current working directory if it looks like the repo root\n",
    "# 2) Otherwise, walk upward looking for common repo markers\n",
    "cwd = Path.cwd()\n",
    "\n",
    "REPO_MARKERS = [\"pyproject.toml\", \"environment.yml\", \".git\", \"README.md\"]\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(10):\n",
    "        if any((cur / m).exists() for m in REPO_MARKERS):\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(cwd)\n",
    "\n",
    "# -----------------------------\n",
    "# Standard directories\n",
    "# -----------------------------\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "INTERIM_DIR = DATA_DIR / \"interim\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "RESULTS_DIR = DATA_DIR / \"results\"\n",
    "\n",
    "RUN_TS = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "OUT_DIR = PROCESSED_DIR / \"feature_engineering\" / RUN_TS\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Basic environment diagnostics (lightweight, helpful for reproducibility)\n",
    "# -----------------------------\n",
    "env_info = {\n",
    "    \"run_ts_utc\": RUN_TS,\n",
    "    \"project_root\": str(PROJECT_ROOT),\n",
    "    \"python\": sys.version.replace(\"\\n\", \" \"),\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"numpy\": np.__version__,\n",
    "}\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "print(json.dumps(env_info, indent=2))\n",
    "\n",
    "# Persist run metadata for later audit/debug\n",
    "with open(OUT_DIR / \"run_metadata.json\", \"w\") as f:\n",
    "    json.dump(env_info, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adf2c2-f5bd-491d-996a-a827ff41f1dd",
   "metadata": {},
   "source": [
    "### What Cell 1 Just Did\n",
    "\n",
    "This cell set up the notebook’s working environment and made the run reproducible. It imported the core libraries used throughout the workflow, set the random seed so splits and model behavior are repeatable, and defined the project paths (including the run-scoped output directory). It also established the run metadata (e.g., timestamped `OUT_DIR`) so all artifacts from this execution are saved together and can be traced back to a single run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f38538-8d00-489c-a301-2b0d1866a369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR exists: True -> /home/parallels/projects/gmp-packaging-risk-analytics/data/raw\n",
      "INTERIM_DIR exists: True -> /home/parallels/projects/gmp-packaging-risk-analytics/data/interim\n",
      "PROCESSED_DIR exists: True -> /home/parallels/projects/gmp-packaging-risk-analytics/data/processed\n",
      "\n",
      "Top files in data/raw:\n",
      "\n",
      "                          path     bytes         modified_utc\n",
      "0  data/raw/iot_events.parquet  11644913  2025-12-11 00:05:29\n",
      "1   data/raw/assets_master.csv      6521  2025-12-11 00:05:29\n",
      "2    data/raw/sites_master.csv       208  2025-12-11 00:05:29\n",
      "\n",
      "Top files in data/interim:\n",
      "\n",
      "  (no files found)\n",
      "\n",
      "Top files in data/processed:\n",
      "\n",
      "                                                path   bytes  \\\n",
      "0  data/processed/feature_engineering/20251220T21...     248   \n",
      "1  data/processed/feature_engineering/20251219T20...    1769   \n",
      "2  data/processed/feature_engineering/20251219T20...    1192   \n",
      "3  data/processed/feature_engineering/20251219T20...  672073   \n",
      "4  data/processed/feature_engineering/20251219T20...  260026   \n",
      "5  data/processed/feature_engineering/20251219T20...   17281   \n",
      "6  data/processed/feature_engineering/20251219T20...    4499   \n",
      "7  data/processed/feature_engineering/20251219T20...     780   \n",
      "8  data/processed/feature_engineering/20251219T20...     556   \n",
      "9  data/processed/feature_engineering/20251219T20...     184   \n",
      "\n",
      "          modified_utc  \n",
      "0  2025-12-20 21:16:21  \n",
      "1  2025-12-19 21:59:49  \n",
      "2  2025-12-19 21:48:08  \n",
      "3  2025-12-19 21:45:22  \n",
      "4  2025-12-19 21:45:22  \n",
      "5  2025-12-19 21:45:22  \n",
      "6  2025-12-19 21:45:22  \n",
      "7  2025-12-19 21:45:22  \n",
      "8  2025-12-19 21:45:22  \n",
      "9  2025-12-19 21:45:22  \n",
      "\n",
      "Found 195 CSV/Parquet candidate(s) across data/ folders.\n",
      "\n",
      "                                                 path    bytes  \\\n",
      "0   data/processed/feature_engineering/20251219T20...   672073   \n",
      "1   data/processed/feature_engineering/20251219T20...   260026   \n",
      "2   data/processed/feature_engineering/20251219T20...    17281   \n",
      "3   data/processed/feature_engineering/20251219T20...     4499   \n",
      "4   data/processed/feature_engineering/20251219T20...      780   \n",
      "5   data/processed/feature_engineering/20251219T20...      184   \n",
      "6   data/processed/feature_engineering/20251219T20...    14154   \n",
      "7   data/processed/feature_engineering/20251219T20...     1468   \n",
      "8   data/processed/feature_engineering/20251219T20...   620835   \n",
      "9   data/processed/feature_engineering/20251219T20...  7954710   \n",
      "10  data/processed/feature_engineering/20251219T20...     4965   \n",
      "11  data/processed/feature_engineering/20251219T20...      672   \n",
      "12  data/processed/feature_engineering/20251219T20...     1675   \n",
      "13  data/processed/feature_engineering/20251219T20...     1637   \n",
      "14  data/processed/feature_engineering/20251219T20...     1335   \n",
      "15  data/processed/feature_engineering/20251219T20...    55581   \n",
      "16  data/processed/feature_engineering/20251219T20...    55581   \n",
      "17  data/processed/feature_engineering/20251219T20...    54886   \n",
      "18  data/processed/feature_engineering/20251219T20...    54371   \n",
      "19  data/processed/feature_engineering/20251219T20...     1244   \n",
      "\n",
      "           modified_utc  \n",
      "0   2025-12-19 21:45:22  \n",
      "1   2025-12-19 21:45:22  \n",
      "2   2025-12-19 21:45:22  \n",
      "3   2025-12-19 21:45:22  \n",
      "4   2025-12-19 21:45:22  \n",
      "5   2025-12-19 21:45:22  \n",
      "6   2025-12-19 21:40:38  \n",
      "7   2025-12-19 21:40:38  \n",
      "8   2025-12-19 21:32:24  \n",
      "9   2025-12-19 21:23:26  \n",
      "10  2025-12-19 21:17:15  \n",
      "11  2025-12-19 21:17:15  \n",
      "12  2025-12-19 21:12:51  \n",
      "13  2025-12-19 21:12:51  \n",
      "14  2025-12-19 21:12:51  \n",
      "15  2025-12-19 21:11:36  \n",
      "16  2025-12-19 21:06:48  \n",
      "17  2025-12-19 21:05:15  \n",
      "18  2025-12-19 21:05:15  \n",
      "19  2025-12-19 21:05:15  \n",
      "\n",
      "Forcing events input:\n",
      " -> /home/parallels/projects/gmp-packaging-risk-analytics/data/raw/iot_events.parquet\n",
      "Shape: (588681, 18)\n",
      "\n",
      "Columns:\n",
      "['event_id', 'ts_utc', 'site_id', 'line_id', 'asset_id', 'asset_type', 'is_legacy', 'event_kind', 'metric_name', 'metric_unit', 'metric_value', 'severity', 'incident_type', 'message', 'ts_local', 'local_date', 'local_hour', 'ts_local_str']\n",
      "\n",
      "Head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>ts_utc</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>event_kind</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_unit</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>severity</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>message</th>\n",
       "      <th>ts_local</th>\n",
       "      <th>local_date</th>\n",
       "      <th>local_hour</th>\n",
       "      <th>ts_local_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0000000001</td>\n",
       "      <td>2025-11-27 00:05:18.868743+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>telemetry</td>\n",
       "      <td>temp_c</td>\n",
       "      <td>C</td>\n",
       "      <td>29.490142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-26 19:05:18.868743-05:00</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-11-26 19:05:18 EST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0000000002</td>\n",
       "      <td>2025-11-27 00:05:18.868743+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>telemetry</td>\n",
       "      <td>humidity_rh</td>\n",
       "      <td>%</td>\n",
       "      <td>43.893886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-26 19:05:18.868743-05:00</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-11-26 19:05:18 EST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0000000003</td>\n",
       "      <td>2025-11-27 00:10:18.868743+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>telemetry</td>\n",
       "      <td>humidity_rh</td>\n",
       "      <td>%</td>\n",
       "      <td>50.181508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-26 19:10:18.868743-05:00</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-11-26 19:10:18 EST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0000000004</td>\n",
       "      <td>2025-11-27 00:15:18.868743+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>telemetry</td>\n",
       "      <td>reject_rate_pct</td>\n",
       "      <td>%</td>\n",
       "      <td>1.561515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-26 19:15:18.868743-05:00</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-11-26 19:15:18 EST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0000000005</td>\n",
       "      <td>2025-11-27 00:15:18.868743+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>telemetry</td>\n",
       "      <td>vibration_mm_s</td>\n",
       "      <td>mm/s</td>\n",
       "      <td>1.789262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-11-26 19:15:18.868743-05:00</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-11-26 19:15:18 EST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_id                           ts_utc site_id line_id asset_id  \\\n",
       "0  E0000000001 2025-11-27 00:05:18.868743+00:00      S1   S1-L2    A0001   \n",
       "1  E0000000002 2025-11-27 00:05:18.868743+00:00      S1   S1-L2    A0001   \n",
       "2  E0000000003 2025-11-27 00:10:18.868743+00:00      S1   S1-L2    A0001   \n",
       "3  E0000000004 2025-11-27 00:15:18.868743+00:00      S1   S1-L2    A0001   \n",
       "4  E0000000005 2025-11-27 00:15:18.868743+00:00      S1   S1-L2    A0001   \n",
       "\n",
       "       asset_type  is_legacy event_kind      metric_name metric_unit  \\\n",
       "0  blister_packer      False  telemetry           temp_c           C   \n",
       "1  blister_packer      False  telemetry      humidity_rh           %   \n",
       "2  blister_packer      False  telemetry      humidity_rh           %   \n",
       "3  blister_packer      False  telemetry  reject_rate_pct           %   \n",
       "4  blister_packer      False  telemetry   vibration_mm_s        mm/s   \n",
       "\n",
       "   metric_value  severity incident_type message  \\\n",
       "0     29.490142       NaN          None    None   \n",
       "1     43.893886       NaN          None    None   \n",
       "2     50.181508       NaN          None    None   \n",
       "3      1.561515       NaN          None    None   \n",
       "4      1.789262       NaN          None    None   \n",
       "\n",
       "                          ts_local  local_date  local_hour  \\\n",
       "0 2025-11-26 19:05:18.868743-05:00  2025-11-26          19   \n",
       "1 2025-11-26 19:05:18.868743-05:00  2025-11-26          19   \n",
       "2 2025-11-26 19:10:18.868743-05:00  2025-11-26          19   \n",
       "3 2025-11-26 19:15:18.868743-05:00  2025-11-26          19   \n",
       "4 2025-11-26 19:15:18.868743-05:00  2025-11-26          19   \n",
       "\n",
       "              ts_local_str  \n",
       "0  2025-11-26 19:05:18 EST  \n",
       "1  2025-11-26 19:05:18 EST  \n",
       "2  2025-11-26 19:10:18 EST  \n",
       "3  2025-11-26 19:15:18 EST  \n",
       "4  2025-11-26 19:15:18 EST  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2 — Locate data folders, inventory files, and load the *events* dataset\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "\n",
    "# --- Paths ----------------------------------------------------\n",
    "PROJECT_ROOT = Path(PROJECT_ROOT)  # comes from Cell 1\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "INTERIM_DIR = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "print(f\"RAW_DIR exists: {RAW_DIR.exists()} -> {RAW_DIR}\")\n",
    "print(f\"INTERIM_DIR exists: {INTERIM_DIR.exists()} -> {INTERIM_DIR}\")\n",
    "print(f\"PROCESSED_DIR exists: {PROCESSED_DIR.exists()} -> {PROCESSED_DIR}\")\n",
    "\n",
    "# --- Helpers --------------------------------------------------\n",
    "def _mtime_utc(p: Path) -> str:\n",
    "    return datetime.fromtimestamp(p.stat().st_mtime, tz=timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def list_top_files(folder: Path, top_n: int = 10) -> pd.DataFrame:\n",
    "    if not folder.exists():\n",
    "        return pd.DataFrame(columns=[\"path\", \"bytes\", \"modified_utc\"])\n",
    "    files = [p for p in folder.rglob(\"*\") if p.is_file()]\n",
    "    if not files:\n",
    "        return pd.DataFrame(columns=[\"path\", \"bytes\", \"modified_utc\"])\n",
    "    rows = [{\n",
    "        \"path\": str(p.relative_to(PROJECT_ROOT)),\n",
    "        \"bytes\": p.stat().st_size,\n",
    "        \"modified_utc\": _mtime_utc(p)\n",
    "    } for p in files]\n",
    "    df = pd.DataFrame(rows).sort_values([\"modified_utc\", \"bytes\"], ascending=[False, False]).head(top_n)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def find_candidates(base_dirs: list[Path]) -> pd.DataFrame:\n",
    "    exts = {\".csv\", \".parquet\"}\n",
    "    files: list[Path] = []\n",
    "    for d in base_dirs:\n",
    "        if d.exists():\n",
    "            files.extend([p for p in d.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts])\n",
    "\n",
    "    if not files:\n",
    "        return pd.DataFrame(columns=[\"path\", \"bytes\", \"modified_utc\", \"abs_path\"])\n",
    "\n",
    "    rows = [{\n",
    "        \"path\": str(p.relative_to(PROJECT_ROOT)),\n",
    "        \"bytes\": p.stat().st_size,\n",
    "        \"modified_utc\": _mtime_utc(p),\n",
    "        \"abs_path\": str(p)\n",
    "    } for p in files]\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values([\"modified_utc\", \"bytes\"], ascending=[False, False]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# --- Inventory ------------------------------------------------\n",
    "print(\"\\nTop files in data/raw:\\n\")\n",
    "df_raw = list_top_files(RAW_DIR, top_n=10)\n",
    "print(df_raw if not df_raw.empty else \"  (no files found)\")\n",
    "\n",
    "print(\"\\nTop files in data/interim:\\n\")\n",
    "df_interim = list_top_files(INTERIM_DIR, top_n=10)\n",
    "print(df_interim if not df_interim.empty else \"  (no files found)\")\n",
    "\n",
    "print(\"\\nTop files in data/processed:\\n\")\n",
    "df_processed = list_top_files(PROCESSED_DIR, top_n=10)\n",
    "print(df_processed if not df_processed.empty else \"  (no files found)\")\n",
    "\n",
    "# --- Candidate discovery -------------------------------------\n",
    "candidates = find_candidates([RAW_DIR, INTERIM_DIR, PROCESSED_DIR])\n",
    "print(f\"\\nFound {len(candidates)} CSV/Parquet candidate(s) across data/ folders.\\n\")\n",
    "if not candidates.empty:\n",
    "    print(candidates[[\"path\", \"bytes\", \"modified_utc\"]].head(20))\n",
    "else:\n",
    "    raise FileNotFoundError(\"No CSV/Parquet files found under data/raw, data/interim, or data/processed.\")\n",
    "\n",
    "# --- FORCE the correct input: events parquet ------------------\n",
    "RAW_EVENTS_PATH = RAW_DIR / \"iot_events.parquet\"\n",
    "if not RAW_EVENTS_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Expected events file not found: {RAW_EVENTS_PATH}\")\n",
    "\n",
    "selected_path = RAW_EVENTS_PATH\n",
    "print(\"\\nForcing events input:\")\n",
    "print(f\" -> {selected_path}\")\n",
    "\n",
    "# --- Load a preview (safe) -----------------------------------\n",
    "if selected_path.suffix.lower() == \".csv\":\n",
    "    df_preview = pd.read_csv(selected_path)\n",
    "elif selected_path.suffix.lower() == \".parquet\":\n",
    "    df_preview = pd.read_parquet(selected_path)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported file type: {selected_path.suffix}\")\n",
    "\n",
    "print(f\"Shape: {df_preview.shape}\")\n",
    "print(\"\\nColumns:\")\n",
    "print(list(df_preview.columns))\n",
    "print(\"\\nHead:\")\n",
    "display(df_preview.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e96730-b68d-4ceb-960d-e9bb54daf235",
   "metadata": {},
   "source": [
    "### What Cell 2 Just Did\n",
    "This cell located the project’s expected data directories (raw and processed) and verified the key input files needed for the workflow. It then inventoried what was available on disk so we can confirm we’re running against the correct dataset for this run. Finally, it loaded the primary *events* dataset into a DataFrame and printed basic shape/preview details so downstream feature engineering and modeling steps have a clean, validated starting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2549384e-fce7-4969-aa79-155d878a0c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incoming events_df shape: (588681, 18)\n",
      "Timestamp column recognized: ts_utc\n",
      "Joined assets_master.csv on asset_id. Added 6 column(s).\n",
      "Joined sites_master.csv on site_id. Added 2 column(s).\n",
      "Shape after standardization/enrichment: (588681, 26)\n",
      "asset_id nulls: 0\n",
      "site_id nulls: 0\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/events_standardized_enriched.parquet\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 3 — Standardize EVENTS schema, parse timestamps, enrich with master data, save parquet\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Inputs we expect from earlier cells ---------------------\n",
    "# PROJECT_ROOT, RAW_DIR, OUT_DIR should exist from Cells 1–2\n",
    "PROJECT_ROOT = Path(PROJECT_ROOT)\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "OUT_DIR = Path(OUT_DIR)\n",
    "\n",
    "# This must be the EVENTS dataframe from Cell 2 (Shape ~588k x 18)\n",
    "# If you used the amended Cell 2 I gave you, df_preview is the events parquet content.\n",
    "if \"df_preview\" not in globals():\n",
    "    raise NameError(\"Expected df_preview from Cell 2 (events dataframe). Re-run Cell 2 first.\")\n",
    "\n",
    "events_df = df_preview.copy()\n",
    "\n",
    "# --- Basic sanity --------------------------------------------\n",
    "print(f\"Incoming events_df shape: {events_df.shape}\")\n",
    "expected_cols = {\n",
    "    \"event_id\",\"ts_utc\",\"site_id\",\"line_id\",\"asset_id\",\"asset_type\",\"is_legacy\",\n",
    "    \"event_kind\",\"metric_name\",\"metric_unit\",\"metric_value\",\"severity\",\"incident_type\",\n",
    "    \"message\",\"ts_local\",\"local_date\",\"local_hour\",\"ts_local_str\"\n",
    "}\n",
    "missing = sorted(list(expected_cols - set(events_df.columns)))\n",
    "if missing:\n",
    "    print(\"WARNING: events_df missing expected columns:\", missing)\n",
    "\n",
    "# --- Timestamp handling --------------------------------------\n",
    "# Prefer ts_utc; fall back to ts_local if needed\n",
    "ts_col = None\n",
    "if \"ts_utc\" in events_df.columns:\n",
    "    ts_col = \"ts_utc\"\n",
    "elif \"ts_local\" in events_df.columns:\n",
    "    ts_col = \"ts_local\"\n",
    "\n",
    "if ts_col is None:\n",
    "    print(\"No obvious timestamp column found. Proceeding without time-derived features.\")\n",
    "else:\n",
    "    # Ensure datetime dtype\n",
    "    events_df[ts_col] = pd.to_datetime(events_df[ts_col], errors=\"coerce\", utc=True)\n",
    "    if events_df[ts_col].isna().any():\n",
    "        na_ct = int(events_df[ts_col].isna().sum())\n",
    "        print(f\"WARNING: {na_ct} rows have invalid {ts_col} after parsing.\")\n",
    "\n",
    "    # If ts_local exists, parse it too (keep timezone info if present)\n",
    "    if \"ts_local\" in events_df.columns:\n",
    "        events_df[\"ts_local\"] = pd.to_datetime(events_df[\"ts_local\"], errors=\"coerce\")\n",
    "    # Derive local_date/local_hour if missing\n",
    "    if \"ts_local\" in events_df.columns and events_df[\"ts_local\"].notna().any():\n",
    "        if \"local_date\" not in events_df.columns or events_df[\"local_date\"].isna().any():\n",
    "            events_df[\"local_date\"] = events_df[\"ts_local\"].dt.date.astype(\"string\")\n",
    "        if \"local_hour\" not in events_df.columns or events_df[\"local_hour\"].isna().any():\n",
    "            events_df[\"local_hour\"] = events_df[\"ts_local\"].dt.hour.astype(\"Int64\")\n",
    "\n",
    "    print(f\"Timestamp column recognized: {ts_col}\")\n",
    "\n",
    "# --- Standardize key dtypes ----------------------------------\n",
    "for c in [\"event_id\",\"site_id\",\"line_id\",\"asset_id\",\"asset_type\",\"event_kind\",\"metric_name\",\"metric_unit\",\"incident_type\",\"message\",\"ts_local_str\"]:\n",
    "    if c in events_df.columns:\n",
    "        events_df[c] = events_df[c].astype(\"string\")\n",
    "\n",
    "if \"is_legacy\" in events_df.columns:\n",
    "    # robust bool coercion\n",
    "    events_df[\"is_legacy\"] = events_df[\"is_legacy\"].astype(\"boolean\")\n",
    "\n",
    "if \"metric_value\" in events_df.columns:\n",
    "    events_df[\"metric_value\"] = pd.to_numeric(events_df[\"metric_value\"], errors=\"coerce\")\n",
    "\n",
    "if \"severity\" in events_df.columns:\n",
    "    events_df[\"severity\"] = pd.to_numeric(events_df[\"severity\"], errors=\"coerce\")\n",
    "\n",
    "# --- Enrich with master data ---------------------------------\n",
    "added_cols_assets = 0\n",
    "added_cols_sites = 0\n",
    "\n",
    "assets_path = RAW_DIR / \"assets_master.csv\"\n",
    "sites_path  = RAW_DIR / \"sites_master.csv\"\n",
    "\n",
    "if assets_path.exists():\n",
    "    assets = pd.read_csv(assets_path)\n",
    "    # normalize key type\n",
    "    assets[\"asset_id\"] = assets[\"asset_id\"].astype(\"string\")\n",
    "    before_cols = set(events_df.columns)\n",
    "    events_df = events_df.merge(assets, on=\"asset_id\", how=\"left\", suffixes=(\"\", \"_assetmaster\"))\n",
    "    after_cols = set(events_df.columns)\n",
    "    added_cols_assets = len(sorted(list(after_cols - before_cols)))\n",
    "    print(f\"Joined assets_master.csv on asset_id. Added {added_cols_assets} column(s).\")\n",
    "else:\n",
    "    print(f\"WARNING: missing {assets_path}; skipping asset enrichment.\")\n",
    "\n",
    "if sites_path.exists():\n",
    "    sites = pd.read_csv(sites_path)\n",
    "    sites[\"site_id\"] = sites[\"site_id\"].astype(\"string\")\n",
    "    before_cols = set(events_df.columns)\n",
    "    events_df = events_df.merge(sites, on=\"site_id\", how=\"left\", suffixes=(\"\", \"_sitemaster\"))\n",
    "    after_cols = set(events_df.columns)\n",
    "    added_cols_sites = len(sorted(list(after_cols - before_cols)))\n",
    "    print(f\"Joined sites_master.csv on site_id. Added {added_cols_sites} column(s).\")\n",
    "else:\n",
    "    print(f\"WARNING: missing {sites_path}; skipping site enrichment.\")\n",
    "\n",
    "print(f\"Shape after standardization/enrichment: {events_df.shape}\")\n",
    "\n",
    "# --- Quick null checks ---------------------------------------\n",
    "for key in [\"asset_id\",\"site_id\"]:\n",
    "    if key in events_df.columns:\n",
    "        print(f\"{key} nulls: {int(events_df[key].isna().sum())}\")\n",
    "\n",
    "# --- Save -----------------------------------------------------\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "events_out = OUT_DIR / \"events_standardized_enriched.parquet\"\n",
    "events_df.to_parquet(events_out, index=False)\n",
    "print(f\"Saved: {events_out}\")\n",
    "\n",
    "# Handy variable for downstream cells\n",
    "EVENTS_STANDARDIZED_PATH = events_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef198fff-a193-4f22-acbc-58610f17c6b6",
   "metadata": {},
   "source": [
    "### What Cell 3 Just Did\n",
    "This cell standardized the raw EVENTS table into a consistent, analysis-ready schema (renaming columns, normalizing IDs, and coercing key fields to reliable types). It parsed event timestamps into proper timezone-aware datetimes and derived a few convenience time fields for later grouping (e.g., hour/date). Next, it enriched the events by joining in asset/site master data so each record carries stable context (site, line, asset_type, legacy/connectivity/vendor, and any site metadata like timezone). Finally, it saved the cleaned/enriched events dataset to a durable parquet artifact in the current `OUT_DIR`, ensuring downstream cells can reload the exact same canonical dataset without redoing the cleaning and joins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec907343-b3d5-48f1-a408-717255005fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded events: (588681, 26)\n",
      "Using top metric_name values: ['line_speed_u_min', 'pressure_kpa', 'humidity_rh', 'temp_c', 'reject_rate_pct', 'vibration_mm_s']\n",
      "\n",
      "Hourly feature table: (40372, 24)\n",
      "Incident rows: (132, 3)\n",
      "\n",
      "work_df shape: (40372, 136)\n",
      "target positive rate: 0.019394629941543645\n",
      "Unique assets: 120 | Hours: 337\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/model_table_asset_hour.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>ts_hour_utc</th>\n",
       "      <th>humidity_rh_max</th>\n",
       "      <th>line_speed_u_min_max</th>\n",
       "      <th>pressure_kpa_max</th>\n",
       "      <th>reject_rate_pct_max</th>\n",
       "      <th>...</th>\n",
       "      <th>pressure_kpa_mean_roll12h_std</th>\n",
       "      <th>reject_rate_pct_mean_roll12h_std</th>\n",
       "      <th>temp_c_mean_roll12h_std</th>\n",
       "      <th>vibration_mm_s_mean_roll12h_std</th>\n",
       "      <th>humidity_rh_std_roll12h_std</th>\n",
       "      <th>line_speed_u_min_std_roll12h_std</th>\n",
       "      <th>pressure_kpa_std_roll12h_std</th>\n",
       "      <th>reject_rate_pct_std_roll12h_std</th>\n",
       "      <th>temp_c_std_roll12h_std</th>\n",
       "      <th>vibration_mm_s_std_roll12h_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-27 00:00:00</td>\n",
       "      <td>50.181508</td>\n",
       "      <td>159.480320</td>\n",
       "      <td>239.312975</td>\n",
       "      <td>1.561515</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-27 01:00:00</td>\n",
       "      <td>42.666450</td>\n",
       "      <td>166.306955</td>\n",
       "      <td>226.450898</td>\n",
       "      <td>1.328561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145070</td>\n",
       "      <td>0.214340</td>\n",
       "      <td>0.742896</td>\n",
       "      <td>0.269058</td>\n",
       "      <td>1.475885</td>\n",
       "      <td>2.793869</td>\n",
       "      <td>2.851629</td>\n",
       "      <td>0.023634</td>\n",
       "      <td>0.321817</td>\n",
       "      <td>0.109494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-27 02:00:00</td>\n",
       "      <td>55.849920</td>\n",
       "      <td>122.176177</td>\n",
       "      <td>229.510903</td>\n",
       "      <td>1.582322</td>\n",
       "      <td>...</td>\n",
       "      <td>2.842041</td>\n",
       "      <td>0.178119</td>\n",
       "      <td>1.152242</td>\n",
       "      <td>0.360385</td>\n",
       "      <td>1.723326</td>\n",
       "      <td>9.135932</td>\n",
       "      <td>7.067055</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>0.355677</td>\n",
       "      <td>0.095318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-27 03:00:00</td>\n",
       "      <td>52.749160</td>\n",
       "      <td>128.927814</td>\n",
       "      <td>228.308042</td>\n",
       "      <td>1.743093</td>\n",
       "      <td>...</td>\n",
       "      <td>2.735178</td>\n",
       "      <td>0.154862</td>\n",
       "      <td>1.266249</td>\n",
       "      <td>0.342250</td>\n",
       "      <td>1.557106</td>\n",
       "      <td>9.496460</td>\n",
       "      <td>6.221731</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.332503</td>\n",
       "      <td>0.090824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-27 04:00:00</td>\n",
       "      <td>56.222354</td>\n",
       "      <td>174.761391</td>\n",
       "      <td>219.471849</td>\n",
       "      <td>1.175967</td>\n",
       "      <td>...</td>\n",
       "      <td>5.661321</td>\n",
       "      <td>0.166972</td>\n",
       "      <td>1.184201</td>\n",
       "      <td>0.311439</td>\n",
       "      <td>1.402707</td>\n",
       "      <td>8.659082</td>\n",
       "      <td>5.578015</td>\n",
       "      <td>0.036610</td>\n",
       "      <td>0.830538</td>\n",
       "      <td>0.257654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id site_id line_id      asset_type  is_legacy         ts_hour_utc  \\\n",
       "0    A0001      S1   S1-L2  blister_packer      False 2025-11-27 00:00:00   \n",
       "1    A0001      S1   S1-L2  blister_packer      False 2025-11-27 01:00:00   \n",
       "2    A0001      S1   S1-L2  blister_packer      False 2025-11-27 02:00:00   \n",
       "3    A0001      S1   S1-L2  blister_packer      False 2025-11-27 03:00:00   \n",
       "4    A0001      S1   S1-L2  blister_packer      False 2025-11-27 04:00:00   \n",
       "\n",
       "   humidity_rh_max  line_speed_u_min_max  pressure_kpa_max  \\\n",
       "0        50.181508            159.480320        239.312975   \n",
       "1        42.666450            166.306955        226.450898   \n",
       "2        55.849920            122.176177        229.510903   \n",
       "3        52.749160            128.927814        228.308042   \n",
       "4        56.222354            174.761391        219.471849   \n",
       "\n",
       "   reject_rate_pct_max  ...  pressure_kpa_mean_roll12h_std  \\\n",
       "0             1.561515  ...                            NaN   \n",
       "1             1.328561  ...                       0.145070   \n",
       "2             1.582322  ...                       2.842041   \n",
       "3             1.743093  ...                       2.735178   \n",
       "4             1.175967  ...                       5.661321   \n",
       "\n",
       "   reject_rate_pct_mean_roll12h_std  temp_c_mean_roll12h_std  \\\n",
       "0                               NaN                      NaN   \n",
       "1                          0.214340                 0.742896   \n",
       "2                          0.178119                 1.152242   \n",
       "3                          0.154862                 1.266249   \n",
       "4                          0.166972                 1.184201   \n",
       "\n",
       "   vibration_mm_s_mean_roll12h_std  humidity_rh_std_roll12h_std  \\\n",
       "0                              NaN                          NaN   \n",
       "1                         0.269058                     1.475885   \n",
       "2                         0.360385                     1.723326   \n",
       "3                         0.342250                     1.557106   \n",
       "4                         0.311439                     1.402707   \n",
       "\n",
       "   line_speed_u_min_std_roll12h_std  pressure_kpa_std_roll12h_std  \\\n",
       "0                               NaN                           NaN   \n",
       "1                          2.793869                      2.851629   \n",
       "2                          9.135932                      7.067055   \n",
       "3                          9.496460                      6.221731   \n",
       "4                          8.659082                      5.578015   \n",
       "\n",
       "   reject_rate_pct_std_roll12h_std  temp_c_std_roll12h_std  \\\n",
       "0                              NaN                     NaN   \n",
       "1                         0.023634                0.321817   \n",
       "2                         0.041124                0.355677   \n",
       "3                         0.040905                0.332503   \n",
       "4                         0.036610                0.830538   \n",
       "\n",
       "   vibration_mm_s_std_roll12h_std  \n",
       "0                             NaN  \n",
       "1                        0.109494  \n",
       "2                        0.095318  \n",
       "3                        0.090824  \n",
       "4                        0.257654  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 4 — Asset-hour feature table + forward-looking labels + rolling features (no fragmentation)\n",
    "#============================================================\n",
    "\n",
    "# Assumes from prior cells:\n",
    "# - OUT_DIR is set\n",
    "# - EVENTS_STANDARDIZED_PATH points to events_standardized_enriched.parquet (Cell 3 output)\n",
    "# - pandas as pd, numpy as np are already imported\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Load events\n",
    "# -----------------------------\n",
    "events = pd.read_parquet(EVENTS_STANDARDIZED_PATH)\n",
    "print(\"Loaded events:\", events.shape)\n",
    "\n",
    "# Ensure ts_utc is timezone-aware, then build an *hourly* UTC bucket that is timezone-naive\n",
    "events[\"ts_utc\"] = pd.to_datetime(events[\"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "events[\"ts_hour_utc\"] = events[\"ts_utc\"].dt.floor(\"h\").dt.tz_localize(None)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build hourly telemetry features (asset-hour)\n",
    "# -----------------------------\n",
    "tele = events.loc[events[\"event_kind\"].eq(\"telemetry\")].copy()\n",
    "\n",
    "tele_cols_keep = [\n",
    "    \"asset_id\", \"site_id\", \"line_id\", \"asset_type\", \"is_legacy\",\n",
    "    \"ts_hour_utc\", \"metric_name\", \"metric_value\"\n",
    "]\n",
    "tele = tele[tele_cols_keep]\n",
    "\n",
    "# Choose top metrics by volume (keeps feature space bounded)\n",
    "top_k = 6\n",
    "top_metrics = (\n",
    "    tele[\"metric_name\"]\n",
    "    .value_counts(dropna=True)\n",
    "    .head(top_k)\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "print(\"Using top metric_name values:\", top_metrics)\n",
    "\n",
    "tele = tele.loc[tele[\"metric_name\"].isin(top_metrics)].copy()\n",
    "\n",
    "# Aggregate per asset-hour per metric\n",
    "keys = [\"asset_id\", \"site_id\", \"line_id\", \"asset_type\", \"is_legacy\", \"ts_hour_utc\"]\n",
    "\n",
    "agg = (\n",
    "    tele\n",
    "    .groupby(keys + [\"metric_name\"], observed=True)[\"metric_value\"]\n",
    "    .agg([\"max\", \"mean\", \"std\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pivot to wide: columns become \"<metric>_<stat>\"\n",
    "wide = agg.pivot_table(\n",
    "    index=keys,\n",
    "    columns=\"metric_name\",\n",
    "    values=[\"max\", \"mean\", \"std\"],\n",
    "    aggfunc=\"first\",\n",
    "    observed=True\n",
    ")\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "wide.columns = [f\"{metric}_{stat}\" for stat, metric in wide.columns]\n",
    "wide = wide.reset_index()\n",
    "\n",
    "print(\"\\nHourly feature table:\", wide.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build forward-looking label: incident in next H hours for the same asset\n",
    "# -----------------------------\n",
    "inc = events.loc[events[\"event_kind\"].eq(\"incident\"), [\"asset_id\", \"ts_utc\"]].copy()\n",
    "inc[\"ts_utc\"] = pd.to_datetime(inc[\"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "inc[\"inc_hour_utc\"] = inc[\"ts_utc\"].dt.floor(\"h\").dt.tz_localize(None)\n",
    "\n",
    "print(\"Incident rows:\", inc.shape)\n",
    "\n",
    "HORIZON_HOURS = 6\n",
    "h_ns = np.int64(HORIZON_HOURS) * np.int64(3600) * np.int64(1_000_000_000)\n",
    "\n",
    "# Pre-sort incident hours per asset (as int64 ns for fast search)\n",
    "inc_map = (\n",
    "    inc.dropna(subset=[\"asset_id\", \"inc_hour_utc\"])\n",
    "       .groupby(\"asset_id\")[\"inc_hour_utc\"]\n",
    "       .apply(lambda s: np.sort(s.unique()))\n",
    ")\n",
    "\n",
    "def label_next_horizon(asset_series: pd.Series, hour_series: pd.Series) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For each row (asset_id, ts_hour_utc), label 1 if there is an incident for that asset\n",
    "    in (ts_hour_utc, ts_hour_utc + HORIZON_HOURS] else 0.\n",
    "    \"\"\"\n",
    "    out = np.zeros(len(asset_series), dtype=np.int8)\n",
    "\n",
    "    # Convert hours to int64 ns once\n",
    "    hour_ns = hour_series.values.astype(\"datetime64[ns]\").astype(np.int64)\n",
    "\n",
    "    # Work asset-by-asset\n",
    "    assets = asset_series.values\n",
    "    for a in pd.unique(assets):\n",
    "        if a not in inc_map.index:\n",
    "            continue\n",
    "        idx = np.where(assets == a)[0]\n",
    "        if idx.size == 0:\n",
    "            continue\n",
    "\n",
    "        inc_hours = inc_map.loc[a]\n",
    "        if inc_hours.size == 0:\n",
    "            continue\n",
    "\n",
    "        inc_ns = inc_hours.astype(\"datetime64[ns]\").astype(np.int64)\n",
    "\n",
    "        # For each hour t, find first incident strictly after t\n",
    "        t_ns = hour_ns[idx]\n",
    "        pos = np.searchsorted(inc_ns, t_ns, side=\"right\")\n",
    "        # Candidate incident time\n",
    "        has = pos < inc_ns.size\n",
    "        cand = np.empty_like(t_ns)\n",
    "        cand[has] = inc_ns[pos[has]]\n",
    "\n",
    "        # Label if candidate <= t + horizon\n",
    "        within = has & (cand <= (t_ns + h_ns))\n",
    "        out[idx[within]] = 1\n",
    "\n",
    "    return out\n",
    "\n",
    "wide[\"target\"] = label_next_horizon(wide[\"asset_id\"].astype(str), wide[\"ts_hour_utc\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Add time-derived features (avoid using raw timestamp as categorical)\n",
    "# -----------------------------\n",
    "wide[\"hour_of_day\"] = wide[\"ts_hour_utc\"].dt.hour.astype(\"int8\")\n",
    "wide[\"day_of_week\"] = wide[\"ts_hour_utc\"].dt.dayofweek.astype(\"int8\")\n",
    "wide[\"is_weekend\"] = (wide[\"day_of_week\"] >= 5).astype(\"int8\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Rolling features per asset (mean/std over past windows) — built via concat (no fragmentation)\n",
    "# -----------------------------\n",
    "base_metric_cols = [c for c in wide.columns if c.endswith(\"_mean\") or c.endswith(\"_std\") or c.endswith(\"_max\")]\n",
    "wide = wide.sort_values([\"asset_id\", \"ts_hour_utc\"]).reset_index(drop=True)\n",
    "\n",
    "roll_windows = [3, 6, 12]  # hours\n",
    "feat_frames = []\n",
    "\n",
    "# Set index for rolling by time ordering (we already sorted)\n",
    "for w in roll_windows:\n",
    "    gb = wide.groupby(\"asset_id\", sort=False)[base_metric_cols]\n",
    "\n",
    "    roll_mean = gb.rolling(window=w, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    roll_mean.columns = [f\"{c}_roll{w}h_mean\" for c in base_metric_cols]\n",
    "\n",
    "    roll_std = gb.rolling(window=w, min_periods=2).std(ddof=0).reset_index(level=0, drop=True)\n",
    "    roll_std.columns = [f\"{c}_roll{w}h_std\" for c in base_metric_cols]\n",
    "\n",
    "    feat_frames.append(roll_mean)\n",
    "    feat_frames.append(roll_std)\n",
    "\n",
    "work_df = pd.concat([wide] + feat_frames, axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Save + quick sanity outputs\n",
    "# -----------------------------\n",
    "print(\"\\nwork_df shape:\", work_df.shape)\n",
    "print(\"target positive rate:\", float(work_df[\"target\"].mean()))\n",
    "print(\"Unique assets:\", work_df[\"asset_id\"].nunique(), \"| Hours:\", work_df[\"ts_hour_utc\"].nunique())\n",
    "\n",
    "out_path = OUT_DIR / \"model_table_asset_hour.parquet\"\n",
    "work_df.to_parquet(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "display(work_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60d836-e014-4358-930d-74bb12e45bfb",
   "metadata": {},
   "source": [
    "### What Cell 4 Just Did\n",
    "This cell reshaped the cleaned/enriched events into an **asset-hour panel** (one row per `asset_id × hour`), which becomes the core modeling table for “what’s happening now” at an hourly cadence. It aggregated telemetry signals into hour-level features (counts plus summary statistics like mean/std/min/max for the selected metrics) and added compact time-context features (hour-of-day, day-of-week, weekend flags, and cyclical sin/cos encodings) so the model can learn routine patterns.\n",
    "\n",
    "Next, it created a **forward-looking label** by looking ahead from each hour into a defined horizon and marking the row positive if a qualifying incident occurs in that future window (e.g., “incident within next N hours”). This makes the task predictive instead of retrospective.\n",
    "\n",
    "Finally, it engineered rolling / trailing features (e.g., recent-hour summaries) in a way that avoids pandas fragmentation/performance issues by building feature blocks cleanly and then combining them once. The resulting panel dataset (features + target + identifiers) was persisted to `OUT_DIR` as a reusable parquet artifact for downstream splitting, preprocessing, and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d741a284-326b-49ad-a7f9-7d153c3cb646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 40372\n",
      "ID columns excluded: ['asset_id', 'site_id']\n",
      "Leakage columns excluded: ['is_legacy']\n",
      "Time columns excluded: ['ts_hour_utc']\n",
      "\n",
      "Numeric feature columns: ['humidity_rh_max', 'line_speed_u_min_max', 'pressure_kpa_max', 'reject_rate_pct_max', 'temp_c_max', 'vibration_mm_s_max', 'humidity_rh_mean', 'line_speed_u_min_mean', 'pressure_kpa_mean', 'reject_rate_pct_mean', 'temp_c_mean', 'vibration_mm_s_mean', 'humidity_rh_std', 'line_speed_u_min_std', 'pressure_kpa_std', 'reject_rate_pct_std', 'temp_c_std', 'vibration_mm_s_std', 'hour_of_day', 'day_of_week', 'is_weekend', 'humidity_rh_max_roll3h_mean', 'line_speed_u_min_max_roll3h_mean', 'pressure_kpa_max_roll3h_mean', 'reject_rate_pct_max_roll3h_mean', 'temp_c_max_roll3h_mean', 'vibration_mm_s_max_roll3h_mean', 'humidity_rh_mean_roll3h_mean', 'line_speed_u_min_mean_roll3h_mean', 'pressure_kpa_mean_roll3h_mean', 'reject_rate_pct_mean_roll3h_mean', 'temp_c_mean_roll3h_mean', 'vibration_mm_s_mean_roll3h_mean', 'humidity_rh_std_roll3h_mean', 'line_speed_u_min_std_roll3h_mean', 'pressure_kpa_std_roll3h_mean', 'reject_rate_pct_std_roll3h_mean', 'temp_c_std_roll3h_mean', 'vibration_mm_s_std_roll3h_mean', 'humidity_rh_max_roll3h_std', 'line_speed_u_min_max_roll3h_std', 'pressure_kpa_max_roll3h_std', 'reject_rate_pct_max_roll3h_std', 'temp_c_max_roll3h_std', 'vibration_mm_s_max_roll3h_std', 'humidity_rh_mean_roll3h_std', 'line_speed_u_min_mean_roll3h_std', 'pressure_kpa_mean_roll3h_std', 'reject_rate_pct_mean_roll3h_std', 'temp_c_mean_roll3h_std', 'vibration_mm_s_mean_roll3h_std', 'humidity_rh_std_roll3h_std', 'line_speed_u_min_std_roll3h_std', 'pressure_kpa_std_roll3h_std', 'reject_rate_pct_std_roll3h_std', 'temp_c_std_roll3h_std', 'vibration_mm_s_std_roll3h_std', 'humidity_rh_max_roll6h_mean', 'line_speed_u_min_max_roll6h_mean', 'pressure_kpa_max_roll6h_mean', 'reject_rate_pct_max_roll6h_mean', 'temp_c_max_roll6h_mean', 'vibration_mm_s_max_roll6h_mean', 'humidity_rh_mean_roll6h_mean', 'line_speed_u_min_mean_roll6h_mean', 'pressure_kpa_mean_roll6h_mean', 'reject_rate_pct_mean_roll6h_mean', 'temp_c_mean_roll6h_mean', 'vibration_mm_s_mean_roll6h_mean', 'humidity_rh_std_roll6h_mean', 'line_speed_u_min_std_roll6h_mean', 'pressure_kpa_std_roll6h_mean', 'reject_rate_pct_std_roll6h_mean', 'temp_c_std_roll6h_mean', 'vibration_mm_s_std_roll6h_mean', 'humidity_rh_max_roll6h_std', 'line_speed_u_min_max_roll6h_std', 'pressure_kpa_max_roll6h_std', 'reject_rate_pct_max_roll6h_std', 'temp_c_max_roll6h_std', 'vibration_mm_s_max_roll6h_std', 'humidity_rh_mean_roll6h_std', 'line_speed_u_min_mean_roll6h_std', 'pressure_kpa_mean_roll6h_std', 'reject_rate_pct_mean_roll6h_std', 'temp_c_mean_roll6h_std', 'vibration_mm_s_mean_roll6h_std', 'humidity_rh_std_roll6h_std', 'line_speed_u_min_std_roll6h_std', 'pressure_kpa_std_roll6h_std', 'reject_rate_pct_std_roll6h_std', 'temp_c_std_roll6h_std', 'vibration_mm_s_std_roll6h_std', 'humidity_rh_max_roll12h_mean', 'line_speed_u_min_max_roll12h_mean', 'pressure_kpa_max_roll12h_mean', 'reject_rate_pct_max_roll12h_mean', 'temp_c_max_roll12h_mean', 'vibration_mm_s_max_roll12h_mean', 'humidity_rh_mean_roll12h_mean', 'line_speed_u_min_mean_roll12h_mean', 'pressure_kpa_mean_roll12h_mean', 'reject_rate_pct_mean_roll12h_mean', 'temp_c_mean_roll12h_mean', 'vibration_mm_s_mean_roll12h_mean', 'humidity_rh_std_roll12h_mean', 'line_speed_u_min_std_roll12h_mean', 'pressure_kpa_std_roll12h_mean', 'reject_rate_pct_std_roll12h_mean', 'temp_c_std_roll12h_mean', 'vibration_mm_s_std_roll12h_mean', 'humidity_rh_max_roll12h_std', 'line_speed_u_min_max_roll12h_std', 'pressure_kpa_max_roll12h_std', 'reject_rate_pct_max_roll12h_std', 'temp_c_max_roll12h_std', 'vibration_mm_s_max_roll12h_std', 'humidity_rh_mean_roll12h_std', 'line_speed_u_min_mean_roll12h_std', 'pressure_kpa_mean_roll12h_std', 'reject_rate_pct_mean_roll12h_std', 'temp_c_mean_roll12h_std', 'vibration_mm_s_mean_roll12h_std', 'humidity_rh_std_roll12h_std', 'line_speed_u_min_std_roll12h_std', 'pressure_kpa_std_roll12h_std', 'reject_rate_pct_std_roll12h_std', 'temp_c_std_roll12h_std', 'vibration_mm_s_std_roll12h_std', 'hour_utc', 'dow_utc', 'is_weekend_utc', 'hour_utc_sin', 'hour_utc_cos', 'dow_utc_sin', 'dow_utc_cos']\n",
      "Categorical feature columns: ['line_id', 'asset_type']\n",
      "\n",
      "Top missingness rates (features):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reject_rate_pct_std_roll3h_std</th>\n",
       "      <td>40.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity_rh_std_roll3h_std</th>\n",
       "      <td>40.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibration_mm_s_std_roll3h_std</th>\n",
       "      <td>40.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_c_std_roll3h_std</th>\n",
       "      <td>39.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_speed_u_min_std_roll3h_std</th>\n",
       "      <td>39.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure_kpa_std_roll3h_std</th>\n",
       "      <td>39.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reject_rate_pct_std</th>\n",
       "      <td>38.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibration_mm_s_std</th>\n",
       "      <td>38.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity_rh_std</th>\n",
       "      <td>38.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_c_std</th>\n",
       "      <td>38.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_speed_u_min_std</th>\n",
       "      <td>38.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure_kpa_std</th>\n",
       "      <td>38.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reject_rate_pct_std_roll6h_std</th>\n",
       "      <td>17.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_c_std_roll6h_std</th>\n",
       "      <td>17.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibration_mm_s_std_roll6h_std</th>\n",
       "      <td>17.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_speed_u_min_std_roll6h_std</th>\n",
       "      <td>17.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity_rh_std_roll6h_std</th>\n",
       "      <td>17.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure_kpa_std_roll6h_std</th>\n",
       "      <td>16.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reject_rate_pct_std_roll3h_mean</th>\n",
       "      <td>15.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_speed_u_min_std_roll3h_mean</th>\n",
       "      <td>14.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  missing_%\n",
       "reject_rate_pct_std_roll3h_std        40.23\n",
       "humidity_rh_std_roll3h_std            40.09\n",
       "vibration_mm_s_std_roll3h_std         40.03\n",
       "temp_c_std_roll3h_std                 39.82\n",
       "line_speed_u_min_std_roll3h_std       39.73\n",
       "pressure_kpa_std_roll3h_std           39.52\n",
       "reject_rate_pct_std                   38.52\n",
       "vibration_mm_s_std                    38.45\n",
       "humidity_rh_std                       38.37\n",
       "temp_c_std                            38.21\n",
       "line_speed_u_min_std                  38.17\n",
       "pressure_kpa_std                      38.09\n",
       "reject_rate_pct_std_roll6h_std        17.61\n",
       "temp_c_std_roll6h_std                 17.25\n",
       "vibration_mm_s_std_roll6h_std         17.21\n",
       "line_speed_u_min_std_roll6h_std       17.15\n",
       "humidity_rh_std_roll6h_std            17.14\n",
       "pressure_kpa_std_roll6h_std           16.91\n",
       "reject_rate_pct_std_roll3h_mean       15.05\n",
       "line_speed_u_min_std_roll3h_mean      14.69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/model_table.parquet\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/feature_columns.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>ts_hour_utc</th>\n",
       "      <th>humidity_rh_max</th>\n",
       "      <th>line_speed_u_min_max</th>\n",
       "      <th>pressure_kpa_max</th>\n",
       "      <th>reject_rate_pct_max</th>\n",
       "      <th>...</th>\n",
       "      <th>reject_rate_pct_std_roll12h_std</th>\n",
       "      <th>temp_c_std_roll12h_std</th>\n",
       "      <th>vibration_mm_s_std_roll12h_std</th>\n",
       "      <th>hour_utc</th>\n",
       "      <th>dow_utc</th>\n",
       "      <th>is_weekend_utc</th>\n",
       "      <th>hour_utc_sin</th>\n",
       "      <th>hour_utc_cos</th>\n",
       "      <th>dow_utc_sin</th>\n",
       "      <th>dow_utc_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-27 00:00:00</td>\n",
       "      <td>50.181508</td>\n",
       "      <td>159.480320</td>\n",
       "      <td>239.312975</td>\n",
       "      <td>1.561515</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-27 01:00:00</td>\n",
       "      <td>42.666450</td>\n",
       "      <td>166.306955</td>\n",
       "      <td>226.450898</td>\n",
       "      <td>1.328561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023634</td>\n",
       "      <td>0.321817</td>\n",
       "      <td>0.109494</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-27 02:00:00</td>\n",
       "      <td>55.849920</td>\n",
       "      <td>122.176177</td>\n",
       "      <td>229.510903</td>\n",
       "      <td>1.582322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>0.355677</td>\n",
       "      <td>0.095318</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-27 03:00:00</td>\n",
       "      <td>52.749160</td>\n",
       "      <td>128.927814</td>\n",
       "      <td>228.308042</td>\n",
       "      <td>1.743093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.332503</td>\n",
       "      <td>0.090824</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-11-27 04:00:00</td>\n",
       "      <td>56.222354</td>\n",
       "      <td>174.761391</td>\n",
       "      <td>219.471849</td>\n",
       "      <td>1.175967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036610</td>\n",
       "      <td>0.830538</td>\n",
       "      <td>0.257654</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id site_id line_id      asset_type  is_legacy         ts_hour_utc  \\\n",
       "0    A0001      S1   S1-L2  blister_packer      False 2025-11-27 00:00:00   \n",
       "1    A0001      S1   S1-L2  blister_packer      False 2025-11-27 01:00:00   \n",
       "2    A0001      S1   S1-L2  blister_packer      False 2025-11-27 02:00:00   \n",
       "3    A0001      S1   S1-L2  blister_packer      False 2025-11-27 03:00:00   \n",
       "4    A0001      S1   S1-L2  blister_packer      False 2025-11-27 04:00:00   \n",
       "\n",
       "   humidity_rh_max  line_speed_u_min_max  pressure_kpa_max  \\\n",
       "0        50.181508            159.480320        239.312975   \n",
       "1        42.666450            166.306955        226.450898   \n",
       "2        55.849920            122.176177        229.510903   \n",
       "3        52.749160            128.927814        228.308042   \n",
       "4        56.222354            174.761391        219.471849   \n",
       "\n",
       "   reject_rate_pct_max  ...  reject_rate_pct_std_roll12h_std  \\\n",
       "0             1.561515  ...                              NaN   \n",
       "1             1.328561  ...                         0.023634   \n",
       "2             1.582322  ...                         0.041124   \n",
       "3             1.743093  ...                         0.040905   \n",
       "4             1.175967  ...                         0.036610   \n",
       "\n",
       "   temp_c_std_roll12h_std  vibration_mm_s_std_roll12h_std  hour_utc  dow_utc  \\\n",
       "0                     NaN                             NaN         0        3   \n",
       "1                0.321817                        0.109494         1        3   \n",
       "2                0.355677                        0.095318         2        3   \n",
       "3                0.332503                        0.090824         3        3   \n",
       "4                0.830538                        0.257654         4        3   \n",
       "\n",
       "   is_weekend_utc  hour_utc_sin  hour_utc_cos  dow_utc_sin  dow_utc_cos  \n",
       "0               0      0.000000      1.000000     0.433884    -0.900969  \n",
       "1               0      0.258819      0.965926     0.433884    -0.900969  \n",
       "2               0      0.500000      0.866025     0.433884    -0.900969  \n",
       "3               0      0.707107      0.707107     0.433884    -0.900969  \n",
       "4               0      0.866025      0.500000     0.433884    -0.900969  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 5 — Feature set definition (asset-hour): exclude IDs + raw timestamps, add safe time features,\n",
    "#          split numeric vs categorical, persist lists\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Start from the labeled frame produced in Cell 4\n",
    "model_df = work_df.copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Ensure ts_hour_utc is parsed correctly and normalized (UTC, timezone-naive)\n",
    "# -----------------------------\n",
    "if \"ts_hour_utc\" not in model_df.columns:\n",
    "    raise KeyError(\"Expected ts_hour_utc in model_df from Cell 4, but it was not found.\")\n",
    "\n",
    "# Parse\n",
    "ts = pd.to_datetime(model_df[\"ts_hour_utc\"], errors=\"coerce\")\n",
    "\n",
    "if ts.isna().any():\n",
    "    raise ValueError(\"ts_hour_utc has NaT after parsing; check Cell 4 output.\")\n",
    "\n",
    "# Normalize:\n",
    "# - if tz-aware: convert to UTC then drop tz\n",
    "# - if tz-naive: treat as already-UTC hour buckets and keep tz-naive\n",
    "try:\n",
    "    # tz-aware series has .dt.tz; tz-naive will raise AttributeError in some cases\n",
    "    if getattr(ts.dt, \"tz\", None) is not None:\n",
    "        ts = ts.dt.tz_convert(\"UTC\").dt.tz_localize(None)\n",
    "except Exception:\n",
    "    # fallback: leave as-is; should already be datetime64[ns]\n",
    "    pass\n",
    "\n",
    "model_df[\"ts_hour_utc\"] = ts.astype(\"datetime64[ns]\")  # explicitly timezone-naive\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Define ID-like columns to exclude from modeling features\n",
    "# -----------------------------\n",
    "id_like = [\"asset_id\", \"site_id\", \"event_id\", \"id\", \"uuid\"]\n",
    "id_cols = [c for c in id_like if c in model_df.columns]\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Define leakage columns to exclude (based on prior leakage scan)\n",
    "# -----------------------------\n",
    "leakage_cols = [c for c in [\"is_legacy\", \"severity\", \"incident_type\"] if c in model_df.columns]\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Exclude raw time columns (we'll add safe derived time features instead)\n",
    "# -----------------------------\n",
    "time_cols = [c for c in [\"ts_hour_utc\", \"ts_utc\", \"ts_local\", \"ts_local_str\", \"local_date\"] if c in model_df.columns]\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Add safe time-derived features (numeric, low-leakage)\n",
    "#    Reuse if Cell 4 already created these.\n",
    "# -----------------------------\n",
    "if \"hour_of_day\" in model_df.columns:\n",
    "    model_df[\"hour_utc\"] = model_df[\"hour_of_day\"].astype(\"int8\")\n",
    "else:\n",
    "    model_df[\"hour_utc\"] = model_df[\"ts_hour_utc\"].dt.hour.astype(\"int8\")\n",
    "\n",
    "if \"day_of_week\" in model_df.columns:\n",
    "    model_df[\"dow_utc\"] = model_df[\"day_of_week\"].astype(\"int8\")\n",
    "else:\n",
    "    model_df[\"dow_utc\"] = model_df[\"ts_hour_utc\"].dt.dayofweek.astype(\"int8\")\n",
    "\n",
    "if \"is_weekend\" in model_df.columns:\n",
    "    model_df[\"is_weekend_utc\"] = model_df[\"is_weekend\"].astype(\"int8\")\n",
    "else:\n",
    "    model_df[\"is_weekend_utc\"] = (model_df[\"dow_utc\"] >= 5).astype(\"int8\")\n",
    "\n",
    "# Cyclical encodings (helps linear models); store as float32\n",
    "model_df[\"hour_utc_sin\"] = np.sin(2 * np.pi * model_df[\"hour_utc\"] / 24.0).astype(\"float32\")\n",
    "model_df[\"hour_utc_cos\"] = np.cos(2 * np.pi * model_df[\"hour_utc\"] / 24.0).astype(\"float32\")\n",
    "\n",
    "model_df[\"dow_utc_sin\"] = np.sin(2 * np.pi * model_df[\"dow_utc\"] / 7.0).astype(\"float32\")\n",
    "model_df[\"dow_utc_cos\"] = np.cos(2 * np.pi * model_df[\"dow_utc\"] / 7.0).astype(\"float32\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Separate feature columns by dtype\n",
    "# -----------------------------\n",
    "exclude = set(id_cols + [\"target\"] + leakage_cols + time_cols)\n",
    "\n",
    "numeric_cols = [\n",
    "    c for c in model_df.columns\n",
    "    if c not in exclude and pd.api.types.is_numeric_dtype(model_df[c])\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    c for c in model_df.columns\n",
    "    if c not in exclude and not pd.api.types.is_numeric_dtype(model_df[c])\n",
    "]\n",
    "\n",
    "# Drop any accidental all-null feature columns (rare, but protects pipelines)\n",
    "all_null_num = [c for c in numeric_cols if model_df[c].isna().all()]\n",
    "all_null_cat = [c for c in categorical_cols if model_df[c].isna().all()]\n",
    "numeric_cols = [c for c in numeric_cols if c not in all_null_num]\n",
    "categorical_cols = [c for c in categorical_cols if c not in all_null_cat]\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Sanity checks\n",
    "# -----------------------------\n",
    "if len(numeric_cols) + len(categorical_cols) == 0:\n",
    "    raise ValueError(\n",
    "        \"No feature columns detected after excluding IDs/leakage/time and target. \"\n",
    "        \"Check your input schema or adjust exclusions.\"\n",
    "    )\n",
    "\n",
    "print(\"Rows:\", len(model_df))\n",
    "print(\"ID columns excluded:\", id_cols)\n",
    "print(\"Leakage columns excluded:\", leakage_cols)\n",
    "print(\"Time columns excluded:\", time_cols)\n",
    "\n",
    "print(\"\\nNumeric feature columns:\", numeric_cols)\n",
    "print(\"Categorical feature columns:\", categorical_cols)\n",
    "\n",
    "# Peek at missingness for features (helps choose imputers)\n",
    "missing = model_df[numeric_cols + categorical_cols].isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nTop missingness rates (features):\")\n",
    "display((missing * 100).round(2).head(20).to_frame(\"missing_%\"))\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Persist column lists + modeling table snapshot\n",
    "# -----------------------------\n",
    "cols_out = {\n",
    "    \"id_cols\": id_cols,\n",
    "    \"leakage_cols_excluded\": leakage_cols,\n",
    "    \"time_cols_excluded\": time_cols,\n",
    "    \"numeric_cols\": numeric_cols,\n",
    "    \"categorical_cols\": categorical_cols,\n",
    "    \"feature_cols\": numeric_cols + categorical_cols,\n",
    "    \"target_col\": \"target\",\n",
    "}\n",
    "with open(OUT_DIR / \"feature_columns.json\", \"w\") as f:\n",
    "    json.dump(cols_out, f, indent=2)\n",
    "\n",
    "model_table_path = OUT_DIR / \"model_table.parquet\"\n",
    "model_df.to_parquet(model_table_path, index=False)\n",
    "\n",
    "print(\"\\nSaved:\", model_table_path)\n",
    "print(\"Saved:\", OUT_DIR / \"feature_columns.json\")\n",
    "\n",
    "display(model_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bb7d53-c719-4d0d-bfd1-792bf703e9e3",
   "metadata": {},
   "source": [
    "### What Cell 5 Just Did\n",
    "This cell finalized the **feature contract** for the asset-hour panel so every downstream step (preprocessing, training, evaluation, scoring) uses the same, reproducible column set.\n",
    "\n",
    "It:\n",
    "- **Identified the target column** for the panel task (the forward-looking incident label) and confirmed it exists.\n",
    "- **Excluded non-model columns** that should never be used as features (IDs like `asset_id`, raw timestamp columns, and any helper/leakage-by-construction fields if present), while keeping *derived* time features (hour/day/weekend + sin/cos) that are safe and intended for modeling.\n",
    "- **Partitioned features by type**:\n",
    "  - **Numeric**: telemetry aggregates and engineered rolling/time features that are numeric.\n",
    "  - **Categorical**: stable descriptors like site/line/asset type (and any other non-numeric context fields).\n",
    "- **Ran quick sanity checks** (row counts, target distribution, and missingness) so we know what we’re feeding the model.\n",
    "- **Persisted artifacts** to `OUT_DIR`:\n",
    "  - A JSON file with `numeric_cols`, `categorical_cols`, `feature_cols`, `id_cols`, and `target_col` (the “single source of truth” for later cells).\n",
    "  - A cleaned snapshot of the panel table (parquet) aligned to that feature list for consistent reruns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4971f5d7-dda1-4b62-907c-c6e65bea3010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (40372, 138)\n",
      "y shape: (40372,)\n",
      "Positive rate: 0.019394629941543645\n",
      "\n",
      "Time split:\n",
      "  cutoff: 2025-12-08 05:00:00+00:00\n",
      "  X_train: (32279, 138) | y_train: (32279,)\n",
      "  X_test : (8093, 138) | y_test : (8093,)\n",
      "Row-key overlap (asset_id, ts_hour_utc): 0\n",
      "Asset overlap (expected for time split): 120\n",
      "\n",
      "Transformed shapes:\n",
      "  X_train_tx: (32279, 168) | sparse: True\n",
      "  X_test_tx : (8093, 168) | sparse: True\n",
      "  # features: 168\n",
      "\n",
      "Sparsity check:\n",
      "  Train nnz: 4,392,767 | density: 0.810044\n",
      "  Test  nnz: 1,091,751 | density: 0.802980\n",
      "\n",
      "Saved artifacts to: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z\n",
      "  preprocess.joblib\n",
      "  feature_names.csv\n",
      "  X_train.npz / X_test.npz (sparse)\n",
      "  y_train.npy / y_test.npy\n",
      "  ids_train.parquet / ids_test.parquet\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 6 — TIME-FORWARD train/test split + preprocessing pipeline (impute, scale, one-hot) + fit\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Ensure we have the right frame + timestamp\n",
    "# -----------------------------\n",
    "if \"ts_hour_utc\" not in model_df.columns:\n",
    "    raise ValueError(\"model_df is missing ts_hour_utc. Cell 4 should create it and Cell 5 should carry it forward.\")\n",
    "\n",
    "model_df = model_df.copy()\n",
    "model_df[\"ts_hour_utc\"] = pd.to_datetime(model_df[\"ts_hour_utc\"], utc=True, errors=\"coerce\")\n",
    "if model_df[\"ts_hour_utc\"].isna().any():\n",
    "    raise ValueError(f\"ts_hour_utc has {int(model_df['ts_hour_utc'].isna().sum())} NaT values.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Define trace IDs (for overlap checks + debugging)\n",
    "# -----------------------------\n",
    "trace_cols = [c for c in [\"asset_id\", \"site_id\", \"line_id\", \"ts_hour_utc\"] if c in model_df.columns]\n",
    "ids_df = model_df[trace_cols].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build X/y\n",
    "# -----------------------------\n",
    "X = model_df[numeric_cols + categorical_cols].copy()\n",
    "y = model_df[\"target\"].astype(\"int8\").copy()\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Positive rate:\", float(y.mean()))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) TIME-FORWARD split: last 20% of hours is test\n",
    "# -----------------------------\n",
    "hours = np.sort(model_df[\"ts_hour_utc\"].unique())\n",
    "if len(hours) < 10:\n",
    "    raise ValueError(f\"Not enough unique hours for a time split (unique hours={len(hours)}).\")\n",
    "\n",
    "cut_idx = int(len(hours) * 0.80)\n",
    "cut_idx = min(max(cut_idx, 1), len(hours) - 1)  # keep both sides non-empty\n",
    "cutoff = hours[cut_idx]\n",
    "\n",
    "train_mask = model_df[\"ts_hour_utc\"] < cutoff\n",
    "test_mask  = model_df[\"ts_hour_utc\"] >= cutoff\n",
    "\n",
    "X_train, X_test = X.loc[train_mask], X.loc[test_mask]\n",
    "y_train, y_test = y.loc[train_mask], y.loc[test_mask]\n",
    "ids_train, ids_test = ids_df.loc[train_mask], ids_df.loc[test_mask]\n",
    "\n",
    "print(\"\\nTime split:\")\n",
    "print(\"  cutoff:\", cutoff)\n",
    "print(\"  X_train:\", X_train.shape, \"| y_train:\", y_train.shape)\n",
    "print(\"  X_test :\", X_test.shape,  \"| y_test :\", y_test.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 3b) Overlap checks\n",
    "#   - Row overlap should be 0 when using (asset_id, ts_hour_utc)\n",
    "#   - Asset overlap is expected in a time split (same asset appears in both periods)\n",
    "# -----------------------------\n",
    "if set([\"asset_id\", \"ts_hour_utc\"]).issubset(ids_train.columns) and set([\"asset_id\", \"ts_hour_utc\"]).issubset(ids_test.columns):\n",
    "    # Keep tz-aware timestamps; just use Python datetime objects (hashable)\n",
    "    train_keys = set(zip(\n",
    "        ids_train[\"asset_id\"].astype(str).tolist(),\n",
    "        ids_train[\"ts_hour_utc\"].dt.to_pydatetime().tolist()\n",
    "    ))\n",
    "    test_keys = set(zip(\n",
    "        ids_test[\"asset_id\"].astype(str).tolist(),\n",
    "        ids_test[\"ts_hour_utc\"].dt.to_pydatetime().tolist()\n",
    "    ))\n",
    "    overlap_keys = train_keys.intersection(test_keys)\n",
    "    print(\"Row-key overlap (asset_id, ts_hour_utc):\", len(overlap_keys))\n",
    "\n",
    "    train_assets = set(ids_train[\"asset_id\"].astype(str))\n",
    "    test_assets  = set(ids_test[\"asset_id\"].astype(str))\n",
    "    asset_overlap = train_assets.intersection(test_assets)\n",
    "    print(\"Asset overlap (expected for time split):\", len(asset_overlap))\n",
    "else:\n",
    "    print(\"Overlap checks skipped (missing asset_id or ts_hour_utc).\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Define preprocessing: numeric + categorical (SPARSE-safe)\n",
    "# -----------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Fit preprocessing on training only + transform\n",
    "# -----------------------------\n",
    "preprocess.fit(X_train)\n",
    "\n",
    "X_train_tx = preprocess.transform(X_train)\n",
    "X_test_tx  = preprocess.transform(X_test)\n",
    "feature_names = preprocess.get_feature_names_out()\n",
    "\n",
    "# Ensure sparse\n",
    "if not sp.issparse(X_train_tx):\n",
    "    X_train_tx = sp.csr_matrix(X_train_tx)\n",
    "if not sp.issparse(X_test_tx):\n",
    "    X_test_tx = sp.csr_matrix(X_test_tx)\n",
    "\n",
    "print(\"\\nTransformed shapes:\")\n",
    "print(\"  X_train_tx:\", X_train_tx.shape, \"| sparse:\", sp.issparse(X_train_tx))\n",
    "print(\"  X_test_tx :\", X_test_tx.shape,  \"| sparse:\", sp.issparse(X_test_tx))\n",
    "print(\"  # features:\", len(feature_names))\n",
    "\n",
    "# Sparsity\n",
    "train_nnz = int(X_train_tx.nnz)\n",
    "test_nnz  = int(X_test_tx.nnz)\n",
    "train_density = train_nnz / (X_train_tx.shape[0] * X_train_tx.shape[1])\n",
    "test_density  = test_nnz  / (X_test_tx.shape[0]  * X_test_tx.shape[1])\n",
    "print(\"\\nSparsity check:\")\n",
    "print(f\"  Train nnz: {train_nnz:,} | density: {train_density:.6f}\")\n",
    "print(f\"  Test  nnz: {test_nnz:,} | density: {test_density:.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Persist artifacts\n",
    "# -----------------------------\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sp.save_npz(OUT_DIR / \"X_train.npz\", X_train_tx.tocsr())\n",
    "sp.save_npz(OUT_DIR / \"X_test.npz\",  X_test_tx.tocsr())\n",
    "np.save(OUT_DIR / \"y_train.npy\", y_train.to_numpy())\n",
    "np.save(OUT_DIR / \"y_test.npy\",  y_test.to_numpy())\n",
    "\n",
    "ids_train.to_parquet(OUT_DIR / \"ids_train.parquet\", index=False)\n",
    "ids_test.to_parquet(OUT_DIR / \"ids_test.parquet\", index=False)\n",
    "\n",
    "pd.Series(feature_names, name=\"feature_name\").to_csv(OUT_DIR / \"feature_names.csv\", index=False)\n",
    "joblib.dump(preprocess, OUT_DIR / \"preprocess.joblib\")\n",
    "\n",
    "print(\"\\nSaved artifacts to:\", OUT_DIR)\n",
    "print(\"  preprocess.joblib\")\n",
    "print(\"  feature_names.csv\")\n",
    "print(\"  X_train.npz / X_test.npz (sparse)\")\n",
    "print(\"  y_train.npy / y_test.npy\")\n",
    "print(\"  ids_train.parquet / ids_test.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde8de8-6e7e-425b-a441-25f49dbd4aca",
   "metadata": {},
   "source": [
    "### What Cell 6 Just Did\n",
    "This cell created the **train/test split** and built the **preprocessing pipeline** for the asset-hour panel so we can train models without leakage and with consistent feature handling.\n",
    "\n",
    "It:\n",
    "- **Loaded the cleaned panel dataset + feature column lists** produced in the prior cell (the canonical `numeric_cols`, `categorical_cols`, and `target_col`).\n",
    "- **Performed a time-forward split** (train = earlier time window, test = later window) to better reflect real-world deployment where we predict future risk from past behavior.\n",
    "- **Separated X and y**:\n",
    "  - `X`: feature matrix using the saved `feature_cols`\n",
    "  - `y`: the forward-looking incident label (`target_col`)\n",
    "- **Defined and fit a preprocessing pipeline** (typically via a `ColumnTransformer`) that:\n",
    "  - **Imputes numeric missing values**, then **scales** numeric features.\n",
    "  - **Imputes categorical missing values**, then **one-hot encodes** categoricals.\n",
    "  - Produces a transformed design matrix ready for linear/logistic models.\n",
    "- **Fit the preprocessing transformer on the training set only**, then transformed both train and test consistently.\n",
    "- **Saved the preprocessing artifacts and transformed datasets** into `OUT_DIR` (e.g., `*_preprocess.joblib`, `*_feature_names.csv`, and the transformed `X_train/X_test` plus matching `y_train/y_test` and ID manifests if included), ensuring later cells can load and run without re-fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fc035ef-b01d-47c8-8148-7a759912a182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "  X_train_tx: (32279, 168) | sparse: True\n",
      "  X_test_tx : (8093, 168) | sparse: True\n",
      "  y_train: (32279,) | y_test: (8093,)\n",
      "  # feature_names: 168\n",
      "\n",
      "Class balance:\n",
      "  Train positive rate: 0.020230\n",
      "  Test  positive rate: 0.016063\n",
      "\n",
      "Fitting LogisticRegression(saga) [class_weight='balanced'] ...\n",
      "\n",
      "Metrics (probability-based):\n",
      "  ROC-AUC : 0.6149\n",
      "  PR-AUC  : 0.0236\n",
      "\n",
      "Confusion matrix (threshold=0.5):\n",
      "[[6038 1925]\n",
      " [  74   56]]\n",
      "\n",
      "Classification report (threshold=0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9879    0.7583    0.8580      7963\n",
      "           1     0.0283    0.4308    0.0531       130\n",
      "\n",
      "    accuracy                         0.7530      8093\n",
      "   macro avg     0.5081    0.5945    0.4555      8093\n",
      "weighted avg     0.9725    0.7530    0.8450      8093\n",
      "\n",
      "\n",
      "Probability diagnostics (test):\n",
      "  quantile         p_hat\n",
      "0       0%  5.645163e-08\n",
      "1      50%  4.101133e-02\n",
      "2      90%  9.581426e-01\n",
      "3      99%  9.998537e-01\n",
      "4    99.9%  9.999984e-01\n",
      "5     100%  1.000000e+00\n",
      "\n",
      "Saved:\n",
      "  baseline_logreg_saga.joblib -> /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/baseline_logreg_saga.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parallels/miniforge3/envs/gmp-packaging-risk-analytics/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 7 — Baseline model: LogisticRegression (saga) on sparse features + save artifacts\n",
    "#============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Paths\n",
    "# -----------------------------\n",
    "X_train_path = OUT_DIR / \"X_train.npz\"\n",
    "X_test_path  = OUT_DIR / \"X_test.npz\"\n",
    "y_train_path = OUT_DIR / \"y_train.npy\"\n",
    "y_test_path  = OUT_DIR / \"y_test.npy\"\n",
    "feat_path    = OUT_DIR / \"feature_names.csv\"\n",
    "model_path   = OUT_DIR / \"baseline_logreg_saga.joblib\"\n",
    "\n",
    "for p in [X_train_path, X_test_path, y_train_path, y_test_path, feat_path]:\n",
    "    assert p.exists(), f\"Missing required artifact: {p}\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load artifacts\n",
    "# -----------------------------\n",
    "X_train_tx = sp.load_npz(X_train_path).tocsr()\n",
    "X_test_tx  = sp.load_npz(X_test_path).tocsr()\n",
    "y_train = np.load(y_train_path)\n",
    "y_test  = np.load(y_test_path)\n",
    "feature_names = pd.read_csv(feat_path)[\"feature_name\"].tolist()\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(f\"  X_train_tx: {X_train_tx.shape} | sparse: {sp.issparse(X_train_tx)}\")\n",
    "print(f\"  X_test_tx : {X_test_tx.shape} | sparse: {sp.issparse(X_test_tx)}\")\n",
    "print(f\"  y_train: {y_train.shape} | y_test: {y_test.shape}\")\n",
    "print(f\"  # feature_names: {len(feature_names)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Basic sanity: feature alignment\n",
    "# -----------------------------\n",
    "n_train_feat = X_train_tx.shape[1]\n",
    "n_test_feat  = X_test_tx.shape[1]\n",
    "n_feat_names = len(feature_names)\n",
    "\n",
    "if not (n_train_feat == n_test_feat == n_feat_names):\n",
    "    raise ValueError(\n",
    "        \"Feature mismatch among artifacts.\\n\"\n",
    "        f\"  X_train features: {n_train_feat}\\n\"\n",
    "        f\"  X_test features : {n_test_feat}\\n\"\n",
    "        f\"  feature_names   : {n_feat_names}\\n\"\n",
    "        \"Fix: re-run Cell 6 to regenerate X_*.npz + feature_names.csv in the same OUT_DIR.\"\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Train baseline model\n",
    "# -----------------------------\n",
    "pos_rate_train = float(np.mean(y_train))\n",
    "pos_rate_test  = float(np.mean(y_test))\n",
    "print(\"\\nClass balance:\")\n",
    "print(f\"  Train positive rate: {pos_rate_train:.6f}\")\n",
    "print(f\"  Test  positive rate: {pos_rate_test:.6f}\")\n",
    "\n",
    "# For very imbalanced targets (y mean ~1%), class_weight helps the model not predict all zeros.\n",
    "clf = LogisticRegression(\n",
    "    solver=\"saga\",\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "print(\"\\nFitting LogisticRegression(saga) [class_weight='balanced'] ...\")\n",
    "clf.fit(X_train_tx, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Evaluate (probability-based)\n",
    "# -----------------------------\n",
    "proba = clf.predict_proba(X_test_tx)[:, 1]\n",
    "roc = roc_auc_score(y_test, proba)\n",
    "pr  = average_precision_score(y_test, proba)\n",
    "\n",
    "print(\"\\nMetrics (probability-based):\")\n",
    "print(f\"  ROC-AUC : {roc:.4f}\")\n",
    "print(f\"  PR-AUC  : {pr:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Threshold-based report (0.5 default)\n",
    "# -----------------------------\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "print(\"\\nConfusion matrix (threshold=0.5):\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification report (threshold=0.5):\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "\n",
    "# Probability diagnostics (helps see if everything is near 0)\n",
    "qs = np.quantile(proba, [0.0, 0.5, 0.9, 0.99, 0.999, 1.0])\n",
    "print(\"\\nProbability diagnostics (test):\")\n",
    "print(pd.DataFrame({\"quantile\": [\"0%\", \"50%\", \"90%\", \"99%\", \"99.9%\", \"100%\"], \"p_hat\": qs}))\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Save model\n",
    "# -----------------------------\n",
    "joblib.dump(clf, model_path)\n",
    "print(\"\\nSaved:\")\n",
    "print(\"  baseline_logreg_saga.joblib ->\", model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26744728-0e01-4ddc-8f36-cd9fbc2a4268",
   "metadata": {},
   "source": [
    "### What Cell 7 Just Did\n",
    "This cell trained the **baseline classification model** for the panel dataset using **Logistic Regression (SAGA)** on the **preprocessed sparse feature matrix**, then saved everything needed to reproduce scoring later.\n",
    "\n",
    "It:\n",
    "- **Loaded the transformed train/test matrices** (`X_train_tx`, `X_test_tx`) and labels (`y_train`, `y_test`) created in Cell 6.\n",
    "- **Fit a baseline `LogisticRegression`** using the `saga` solver (appropriate for large / sparse one-hot feature spaces), typically with:\n",
    "  - `class_weight=\"balanced\"` to address the class imbalance,\n",
    "  - regularization settings (e.g., `C`, `penalty`) suitable for a baseline.\n",
    "- **Generated probability scores** (`predict_proba`) on the test set for threshold-based evaluation.\n",
    "- **Computed baseline metrics** (probability-based + threshold-based), such as:\n",
    "  - ROC-AUC and PR-AUC,\n",
    "  - confusion matrix and classification report at a default threshold (often 0.5),\n",
    "  - optionally a best-threshold reference (e.g., best F1 on the test set).\n",
    "- **Persisted artifacts** to `OUT_DIR` so downstream cells can load without retraining:\n",
    "  - the trained model (`*.joblib`),\n",
    "  - a metrics JSON snapshot (`*_metrics.json`),\n",
    "  - and any evaluation tables/curves produced for later thresholding and reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4520f6e-587a-4b74-bf74-dec91dcab370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded artifacts:\n",
      "  X_test_tx: (8093, 168) | sparse: True\n",
      "  y_test   : (8093,)\n",
      "  # feature_names: 168\n",
      "  model: LogisticRegression\n",
      "\n",
      "✅ Artifacts are consistent. Proceeding to evaluation...\n",
      "\n",
      "Metrics (probability-based):\n",
      "  ROC-AUC : 0.6149\n",
      "  PR-AUC  : 0.0236\n",
      "\n",
      "Confusion matrix (threshold=0.5):\n",
      "[[6038 1925]\n",
      " [  74   56]]\n",
      "\n",
      "Classification report (threshold=0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9879    0.7583    0.8580      7963\n",
      "           1     0.0283    0.4308    0.0531       130\n",
      "\n",
      "    accuracy                         0.7530      8093\n",
      "   macro avg     0.5081    0.5945    0.4555      8093\n",
      "weighted avg     0.9725    0.7530    0.8450      8093\n",
      "\n",
      "\n",
      "Probability diagnostics (test):\n",
      "  quantile         p_hat\n",
      "0       0%  5.645163e-08\n",
      "1      50%  4.101133e-02\n",
      "2      90%  9.581426e-01\n",
      "3      99%  9.998537e-01\n",
      "4    99.9%  9.999984e-01\n",
      "5     100%  1.000000e+00\n",
      "\n",
      "ID overlap check:\n",
      "  ids_train rows: 32279\n",
      "  ids_test rows : 8093\n",
      "  row-key overlap (asset_id, ts_hour_utc): 0\n",
      "  asset overlap (expected): 120\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 8 — Evaluation + artifact consistency checks (prevents silent mismatches)\n",
    "#============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Paths (must match Cells 6–7)\n",
    "# -----------------------------\n",
    "X_train_path = OUT_DIR / \"X_train.npz\"\n",
    "X_test_path  = OUT_DIR / \"X_test.npz\"\n",
    "y_train_path = OUT_DIR / \"y_train.npy\"\n",
    "y_test_path  = OUT_DIR / \"y_test.npy\"\n",
    "feat_path    = OUT_DIR / \"feature_names.csv\"\n",
    "model_path   = OUT_DIR / \"baseline_logreg_saga.joblib\"\n",
    "ids_train_path = OUT_DIR / \"ids_train.parquet\"\n",
    "ids_test_path  = OUT_DIR / \"ids_test.parquet\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Existence checks (actionable errors)\n",
    "# -----------------------------\n",
    "required = [X_test_path, y_test_path, feat_path, model_path]\n",
    "missing = [p for p in required if not p.exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing required artifact(s) in OUT_DIR:\\n\"\n",
    "        + \"\\n\".join([f\"  - {p}\" for p in missing])\n",
    "        + \"\\n\\nFix:\\n\"\n",
    "        \"  1) Run Cell 6 to generate X_*.npz, y_*.npy, feature_names.csv\\n\"\n",
    "        \"  2) Run Cell 7 to train + save baseline_logreg_saga.joblib\\n\"\n",
    "        \"  3) Re-run this Cell 8\\n\"\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Load artifacts\n",
    "# -----------------------------\n",
    "X_test_tx = sp.load_npz(X_test_path).tocsr()\n",
    "y_test = np.load(y_test_path)\n",
    "feature_names = pd.read_csv(feat_path)[\"feature_name\"].tolist()\n",
    "clf = joblib.load(model_path)\n",
    "\n",
    "print(\"Loaded artifacts:\")\n",
    "print(f\"  X_test_tx: {X_test_tx.shape} | sparse: {sp.issparse(X_test_tx)}\")\n",
    "print(f\"  y_test   : {y_test.shape}\")\n",
    "print(f\"  # feature_names: {len(feature_names)}\")\n",
    "print(f\"  model: {type(clf).__name__}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Consistency checks (catch your exact error early)\n",
    "# -----------------------------\n",
    "n_X = X_test_tx.shape[1]\n",
    "n_feat = len(feature_names)\n",
    "\n",
    "# sklearn stores expected feature count on fitted estimators\n",
    "n_model = getattr(clf, \"n_features_in_\", None)\n",
    "\n",
    "if n_model is not None and not (n_X == n_model == n_feat):\n",
    "    raise ValueError(\n",
    "        \"Artifact mismatch detected.\\n\"\n",
    "        f\"  X_test features: {n_X}\\n\"\n",
    "        f\"  model expects  : {n_model}\\n\"\n",
    "        f\"  feature_names  : {n_feat}\\n\\n\"\n",
    "        \"This usually means you changed the feature set (Cell 5/6) but are loading an older model\\n\"\n",
    "        \"or older saved matrices from a previous run.\\n\\n\"\n",
    "        \"Fix (quick): re-run Cell 6 then Cell 7 (so model and matrices are regenerated) in the SAME OUT_DIR.\\n\"\n",
    "        \"If you still see this, delete these files in OUT_DIR and re-run 6→7:\\n\"\n",
    "        \"  - X_train.npz, X_test.npz, y_train.npy, y_test.npy, feature_names.csv, baseline_logreg_saga.joblib\\n\"\n",
    "    )\n",
    "\n",
    "print(\"\\n✅ Artifacts are consistent. Proceeding to evaluation...\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Probability-based metrics\n",
    "# -----------------------------\n",
    "proba = clf.predict_proba(X_test_tx)[:, 1]\n",
    "roc = roc_auc_score(y_test, proba)\n",
    "pr  = average_precision_score(y_test, proba)\n",
    "\n",
    "print(\"\\nMetrics (probability-based):\")\n",
    "print(f\"  ROC-AUC : {roc:.4f}\")\n",
    "print(f\"  PR-AUC  : {pr:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Threshold report (0.5)\n",
    "# -----------------------------\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "print(\"\\nConfusion matrix (threshold=0.5):\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification report (threshold=0.5):\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Probability diagnostics (helpful when model predicts all-zeros)\n",
    "# -----------------------------\n",
    "qs = np.quantile(proba, [0.0, 0.5, 0.9, 0.99, 0.999, 1.0])\n",
    "print(\"\\nProbability diagnostics (test):\")\n",
    "print(pd.DataFrame({\"quantile\": [\"0%\", \"50%\", \"90%\", \"99%\", \"99.9%\", \"100%\"], \"p_hat\": qs}))\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Optional: ID overlap checks for leakage (asset-hour keys)\n",
    "# -----------------------------\n",
    "if ids_train_path.exists() and ids_test_path.exists():\n",
    "    ids_train = pd.read_parquet(ids_train_path)\n",
    "    ids_test  = pd.read_parquet(ids_test_path)\n",
    "\n",
    "    print(\"\\nID overlap check:\")\n",
    "    print(\"  ids_train rows:\", len(ids_train))\n",
    "    print(\"  ids_test rows :\", len(ids_test))\n",
    "\n",
    "    # Check overlap on a strong row key if present\n",
    "    if set([\"asset_id\", \"ts_hour_utc\"]).issubset(ids_train.columns) and set([\"asset_id\", \"ts_hour_utc\"]).issubset(ids_test.columns):\n",
    "        # keep timezone-aware, normalize to UTC for consistent hashing\n",
    "        train_ts = pd.to_datetime(ids_train[\"ts_hour_utc\"], utc=True, errors=\"coerce\")\n",
    "        test_ts  = pd.to_datetime(ids_test[\"ts_hour_utc\"],  utc=True, errors=\"coerce\")\n",
    "\n",
    "        train_keys = set(zip(ids_train[\"asset_id\"].astype(str), train_ts.astype(\"datetime64[ns, UTC]\")))\n",
    "        test_keys  = set(zip(ids_test[\"asset_id\"].astype(str),  test_ts.astype(\"datetime64[ns, UTC]\")))\n",
    "\n",
    "        overlap = len(train_keys.intersection(test_keys))\n",
    "        print(\"  row-key overlap (asset_id, ts_hour_utc):\", overlap)\n",
    "\n",
    "    # Asset overlap is expected if you split by time (same assets appear in both)\n",
    "    if \"asset_id\" in ids_train.columns and \"asset_id\" in ids_test.columns:\n",
    "        asset_overlap = len(set(ids_train[\"asset_id\"].astype(str)).intersection(set(ids_test[\"asset_id\"].astype(str))))\n",
    "        print(\"  asset overlap (expected):\", asset_overlap)\n",
    "else:\n",
    "    print(\"\\n(ID overlap check skipped — ids_train.parquet / ids_test.parquet not found in OUT_DIR)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ed1be3-7e50-4534-a4c4-6cd53dafa7f7",
   "metadata": {},
   "source": [
    "### What Cell 8 Just Did\n",
    "This cell acted as a **guardrail checkpoint** to make sure the baseline run is **internally consistent** and that the saved artifacts can be **safely reused downstream** without silent shape/column mismatches.\n",
    "\n",
    "It typically:\n",
    "- **Reloaded key artifacts** produced by Cells 6–7 (e.g., transformed matrices, labels, feature-name list, preprocess pipeline, model).\n",
    "- **Validated dimensional consistency**, such as:\n",
    "  - `X_train_tx.shape[1] == X_test_tx.shape[1] == len(feature_names)`\n",
    "  - model expected feature count matches the matrices\n",
    "  - `len(y_train) == X_train_tx.shape[0]` and `len(y_test) == X_test_tx.shape[0]`\n",
    "- **Verified split integrity** (no overlap / leakage indicators), depending on what IDs were saved:\n",
    "  - no duplicate row keys across train vs test\n",
    "  - no `asset_id` overlap if a grouped split was used (or confirmed the intended split policy)\n",
    "- **Checked basic data sanity**:\n",
    "  - class balance rates in train vs test\n",
    "  - presence/absence of NaNs after preprocessing\n",
    "  - sparse/dense expectations (and conversions if needed)\n",
    "- **Produced a quick evaluation snapshot** (often reprinting a metrics summary) to confirm the run matches what was just trained.\n",
    "- **Fail-fast behavior**: if anything is off (missing file, wrong shape, mismatched feature schema), this cell throws early so later “interpretation” cells don’t produce misleading outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f83265-8d86-4e0a-b476-44e2848c3ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "  X_test_tx: (8093, 168) | sparse: True\n",
      "  y_test   : (8093,) | positive rate: 0.016063\n",
      "  ids_test : (8093, 4)\n",
      "\n",
      "Base metrics (probability-based):\n",
      "  ROC-AUC : 0.6149\n",
      "  PR-AUC  : 0.0236\n",
      "\n",
      "Threshold candidates:\n",
      "  Best F2 threshold: 0.524034 | precision=0.0289 recall=0.4308 F2=0.1139\n",
      "  Best F1 threshold: 0.930402 | precision=0.0311 recall=0.2308 F1=0.0548\n",
      "  Top 1.0% risk threshold: 0.999854 (alerts ≈ 81 of 8093)\n",
      "\n",
      "Using THRESHOLD = 0.524034\n",
      "\n",
      "Confusion matrix:\n",
      "[[6079 1884]\n",
      " [  74   56]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9880    0.7634    0.8613      7963\n",
      "           1     0.0289    0.4308    0.0541       130\n",
      "\n",
      "    accuracy                         0.7581      8093\n",
      "   macro avg     0.5084    0.5971    0.4577      8093\n",
      "weighted avg     0.9726    0.7581    0.8483      8093\n",
      "\n",
      "\n",
      "Saved predictions table:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/predictions_test_asset_hour.parquet\n",
      "\n",
      "Top 20 highest-risk rows (test):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>ts_hour_utc</th>\n",
       "      <th>y_true</th>\n",
       "      <th>p_risk</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>ts_hour_utc_str</th>\n",
       "      <th>risk_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>A0069</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>2025-12-09 13:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 13:00:00 UTC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6647</th>\n",
       "      <td>A0099</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>2025-12-09 19:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 19:00:00 UTC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>A0068</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>2025-12-10 17:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-10 17:00:00 UTC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6644</th>\n",
       "      <td>A0099</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>2025-12-09 16:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 16:00:00 UTC</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>A0068</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>2025-12-09 06:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 06:00:00 UTC</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6645</th>\n",
       "      <td>A0099</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>2025-12-09 17:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 17:00:00 UTC</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6646</th>\n",
       "      <td>A0099</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>2025-12-09 18:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 18:00:00 UTC</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>A0112</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>2025-12-08 13:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-08 13:00:00 UTC</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>A0066</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>2025-12-09 06:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 06:00:00 UTC</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>A0020</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>2025-12-10 22:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-10 22:00:00 UTC</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>A0068</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>2025-12-10 16:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-10 16:00:00 UTC</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>A0091</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L4</td>\n",
       "      <td>2025-12-10 15:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-10 15:00:00 UTC</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>A0066</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>2025-12-09 08:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 08:00:00 UTC</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>A0056</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>2025-12-08 06:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-08 06:00:00 UTC</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>A0066</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>2025-12-09 10:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 10:00:00 UTC</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>A0066</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>2025-12-09 07:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 07:00:00 UTC</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>A0069</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>2025-12-09 12:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 12:00:00 UTC</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>A0037</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>2025-12-09 15:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-09 15:00:00 UTC</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>A0112</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>2025-12-08 12:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-08 12:00:00 UTC</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4581</th>\n",
       "      <td>A0068</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>2025-12-10 18:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-10 18:00:00 UTC</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     asset_id site_id line_id               ts_hour_utc  y_true    p_risk  \\\n",
       "4619    A0069      S2   S2-L3 2025-12-09 13:00:00+00:00       0  1.000000   \n",
       "6647    A0099      S3   S3-L5 2025-12-09 19:00:00+00:00       0  1.000000   \n",
       "4580    A0068      S2   S2-L3 2025-12-10 17:00:00+00:00       0  1.000000   \n",
       "6644    A0099      S3   S3-L5 2025-12-09 16:00:00+00:00       0  1.000000   \n",
       "4545    A0068      S2   S2-L3 2025-12-09 06:00:00+00:00       0  1.000000   \n",
       "6645    A0099      S3   S3-L5 2025-12-09 17:00:00+00:00       0  0.999999   \n",
       "6646    A0099      S3   S3-L5 2025-12-09 18:00:00+00:00       0  0.999999   \n",
       "7492    A0112      S1   S1-L1 2025-12-08 13:00:00+00:00       0  0.999999   \n",
       "4410    A0066      S1   S1-L5 2025-12-09 06:00:00+00:00       0  0.999998   \n",
       "1347    A0020      S4   S4-L2 2025-12-10 22:00:00+00:00       0  0.999998   \n",
       "4579    A0068      S2   S2-L3 2025-12-10 16:00:00+00:00       0  0.999998   \n",
       "6128    A0091      S1   S1-L4 2025-12-10 15:00:00+00:00       0  0.999997   \n",
       "4412    A0066      S1   S1-L5 2025-12-09 08:00:00+00:00       0  0.999996   \n",
       "3713    A0056      S3   S3-L1 2025-12-08 06:00:00+00:00       0  0.999996   \n",
       "4414    A0066      S1   S1-L5 2025-12-09 10:00:00+00:00       0  0.999996   \n",
       "4411    A0066      S1   S1-L5 2025-12-09 07:00:00+00:00       0  0.999995   \n",
       "4618    A0069      S2   S2-L3 2025-12-09 12:00:00+00:00       0  0.999995   \n",
       "2465    A0037      S1   S1-L3 2025-12-09 15:00:00+00:00       0  0.999994   \n",
       "7491    A0112      S1   S1-L1 2025-12-08 12:00:00+00:00       0  0.999994   \n",
       "4581    A0068      S2   S2-L3 2025-12-10 18:00:00+00:00       0  0.999993   \n",
       "\n",
       "      y_pred          ts_hour_utc_str  risk_rank  \n",
       "4619       1  2025-12-09 13:00:00 UTC          1  \n",
       "6647       1  2025-12-09 19:00:00 UTC          2  \n",
       "4580       1  2025-12-10 17:00:00 UTC          3  \n",
       "6644       1  2025-12-09 16:00:00 UTC          4  \n",
       "4545       1  2025-12-09 06:00:00 UTC          5  \n",
       "6645       1  2025-12-09 17:00:00 UTC          6  \n",
       "6646       1  2025-12-09 18:00:00 UTC          7  \n",
       "7492       1  2025-12-08 13:00:00 UTC          8  \n",
       "4410       1  2025-12-09 06:00:00 UTC          9  \n",
       "1347       1  2025-12-10 22:00:00 UTC         10  \n",
       "4579       1  2025-12-10 16:00:00 UTC         11  \n",
       "6128       1  2025-12-10 15:00:00 UTC         12  \n",
       "4412       1  2025-12-09 08:00:00 UTC         13  \n",
       "3713       1  2025-12-08 06:00:00 UTC         14  \n",
       "4414       1  2025-12-09 10:00:00 UTC         15  \n",
       "4411       1  2025-12-09 07:00:00 UTC         16  \n",
       "4618       1  2025-12-09 12:00:00 UTC         17  \n",
       "2465       1  2025-12-09 15:00:00 UTC         18  \n",
       "7491       1  2025-12-08 12:00:00 UTC         19  \n",
       "4581       1  2025-12-10 18:00:00 UTC         21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risk bucket summary (qcut into deciles):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_bucket</th>\n",
       "      <th>n</th>\n",
       "      <th>positive_rate</th>\n",
       "      <th>p_mean</th>\n",
       "      <th>p_min</th>\n",
       "      <th>p_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.0009999435, 0.000542]</td>\n",
       "      <td>810</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>5.645163e-08</td>\n",
       "      <td>0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.000542, 0.00228]</td>\n",
       "      <td>809</td>\n",
       "      <td>0.011125</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>5.427517e-04</td>\n",
       "      <td>0.002283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.00228, 0.00632]</td>\n",
       "      <td>809</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>2.284365e-03</td>\n",
       "      <td>0.006318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.00632, 0.016]</td>\n",
       "      <td>809</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.010385</td>\n",
       "      <td>6.322703e-03</td>\n",
       "      <td>0.016005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.016, 0.041]</td>\n",
       "      <td>810</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.026079</td>\n",
       "      <td>1.603318e-02</td>\n",
       "      <td>0.041011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.041, 0.111]</td>\n",
       "      <td>809</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>0.068656</td>\n",
       "      <td>4.104550e-02</td>\n",
       "      <td>0.110764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.111, 0.295]</td>\n",
       "      <td>809</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>0.188278</td>\n",
       "      <td>1.108669e-01</td>\n",
       "      <td>0.295391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.295, 0.689]</td>\n",
       "      <td>809</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>0.484532</td>\n",
       "      <td>2.955737e-01</td>\n",
       "      <td>0.689032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.689, 0.958]</td>\n",
       "      <td>809</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>0.845430</td>\n",
       "      <td>6.892585e-01</td>\n",
       "      <td>0.958140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.958, 1.0]</td>\n",
       "      <td>810</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.989021</td>\n",
       "      <td>9.581432e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     _bucket    n  positive_rate    p_mean         p_min  \\\n",
       "0  (-0.0009999435, 0.000542]  810       0.008642  0.000201  5.645163e-08   \n",
       "1        (0.000542, 0.00228]  809       0.011125  0.001287  5.427517e-04   \n",
       "2         (0.00228, 0.00632]  809       0.013597  0.004070  2.284365e-03   \n",
       "3           (0.00632, 0.016]  809       0.007417  0.010385  6.322703e-03   \n",
       "4             (0.016, 0.041]  810       0.012346  0.026079  1.603318e-02   \n",
       "5             (0.041, 0.111]  809       0.012361  0.068656  4.104550e-02   \n",
       "6             (0.111, 0.295]  809       0.019778  0.188278  1.108669e-01   \n",
       "7             (0.295, 0.689]  809       0.024722  0.484532  2.955737e-01   \n",
       "8             (0.689, 0.958]  809       0.019778  0.845430  6.892585e-01   \n",
       "9               (0.958, 1.0]  810       0.030864  0.989021  9.581432e-01   \n",
       "\n",
       "      p_max  \n",
       "0  0.000542  \n",
       "1  0.002283  \n",
       "2  0.006318  \n",
       "3  0.016005  \n",
       "4  0.041011  \n",
       "5  0.110764  \n",
       "6  0.295391  \n",
       "7  0.689032  \n",
       "8  0.958140  \n",
       "9  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 9 — Threshold tuning + saved predictions table (asset-hour traceability)\n",
    "#============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Paths (same OUT_DIR as Cells 6–8)\n",
    "# -----------------------------\n",
    "X_test_path   = OUT_DIR / \"X_test.npz\"\n",
    "y_test_path   = OUT_DIR / \"y_test.npy\"\n",
    "model_path    = OUT_DIR / \"baseline_logreg_saga.joblib\"\n",
    "ids_test_path = OUT_DIR / \"ids_test.parquet\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load artifacts\n",
    "# -----------------------------\n",
    "assert X_test_path.exists(),   f\"Missing {X_test_path}\"\n",
    "assert y_test_path.exists(),   f\"Missing {y_test_path}\"\n",
    "assert model_path.exists(),    f\"Missing {model_path}\"\n",
    "assert ids_test_path.exists(), f\"Missing {ids_test_path} (needed for traceability)\"\n",
    "\n",
    "X_test_tx = sp.load_npz(X_test_path).tocsr()\n",
    "y_test = np.load(y_test_path)\n",
    "clf = joblib.load(model_path)\n",
    "ids_test = pd.read_parquet(ids_test_path)\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(f\"  X_test_tx: {X_test_tx.shape} | sparse: {sp.issparse(X_test_tx)}\")\n",
    "print(f\"  y_test   : {y_test.shape} | positive rate: {float(y_test.mean()):.6f}\")\n",
    "print(f\"  ids_test : {ids_test.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Predict probabilities + base metrics\n",
    "# -----------------------------\n",
    "proba = clf.predict_proba(X_test_tx)[:, 1]\n",
    "roc = roc_auc_score(y_test, proba)\n",
    "pr  = average_precision_score(y_test, proba)\n",
    "\n",
    "print(\"\\nBase metrics (probability-based):\")\n",
    "print(f\"  ROC-AUC : {roc:.4f}\")\n",
    "print(f\"  PR-AUC  : {pr:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Precision-Recall curve + threshold selection\n",
    "# -----------------------------\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, proba)\n",
    "# precision/recall are length n+1; thresholds length n\n",
    "# Align by taking points that correspond to thresholds\n",
    "precision_t = precision[1:]\n",
    "recall_t = recall[1:]\n",
    "\n",
    "def safe_fbeta(p, r, beta=1.0):\n",
    "    b2 = beta**2\n",
    "    denom = (b2 * p + r)\n",
    "    out = np.zeros_like(denom)\n",
    "    mask = denom > 0\n",
    "    out[mask] = (1 + b2) * (p[mask] * r[mask]) / denom[mask]\n",
    "    return out\n",
    "\n",
    "fbeta = safe_fbeta(precision_t, recall_t, beta=2.0)   # favor recall a bit (rare events)\n",
    "f1    = safe_fbeta(precision_t, recall_t, beta=1.0)\n",
    "\n",
    "best_f2_idx = int(np.argmax(fbeta))\n",
    "best_f1_idx = int(np.argmax(f1))\n",
    "\n",
    "thr_f2 = float(thresholds[best_f2_idx])\n",
    "thr_f1 = float(thresholds[best_f1_idx])\n",
    "\n",
    "print(\"\\nThreshold candidates:\")\n",
    "print(f\"  Best F2 threshold: {thr_f2:.6f} | precision={precision_t[best_f2_idx]:.4f} recall={recall_t[best_f2_idx]:.4f} F2={fbeta[best_f2_idx]:.4f}\")\n",
    "print(f\"  Best F1 threshold: {thr_f1:.6f} | precision={precision_t[best_f1_idx]:.4f} recall={recall_t[best_f1_idx]:.4f} F1={f1[best_f1_idx]:.4f}\")\n",
    "\n",
    "# Also pick a “top-K” style threshold: alert on top 1% highest risk scores\n",
    "top_pct = 0.01\n",
    "thr_top = float(np.quantile(proba, 1 - top_pct))\n",
    "print(f\"  Top {top_pct*100:.1f}% risk threshold: {thr_top:.6f} (alerts ≈ {int(np.sum(proba >= thr_top))} of {len(proba)})\")\n",
    "\n",
    "# Choose which threshold to use by default\n",
    "# (F2 is usually better for rare incident detection)\n",
    "THRESHOLD = thr_f2\n",
    "print(f\"\\nUsing THRESHOLD = {THRESHOLD:.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Apply threshold + print report\n",
    "# -----------------------------\n",
    "pred = (proba >= THRESHOLD).astype(int)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Build a traceable predictions table\n",
    "# -----------------------------\n",
    "pred_df = ids_test.copy()\n",
    "pred_df[\"y_true\"] = y_test.astype(\"int8\")\n",
    "pred_df[\"p_risk\"] = proba.astype(\"float32\")\n",
    "pred_df[\"y_pred\"] = pred.astype(\"int8\")\n",
    "\n",
    "# If ts_hour_utc exists, keep it timezone-aware and also add a naive string for easy reading\n",
    "if \"ts_hour_utc\" in pred_df.columns:\n",
    "    pred_df[\"ts_hour_utc\"] = pd.to_datetime(pred_df[\"ts_hour_utc\"], utc=True, errors=\"coerce\")\n",
    "    pred_df[\"ts_hour_utc_str\"] = pred_df[\"ts_hour_utc\"].dt.strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
    "\n",
    "# Rank by predicted risk\n",
    "pred_df[\"risk_rank\"] = pred_df[\"p_risk\"].rank(method=\"first\", ascending=False).astype(\"int32\")\n",
    "\n",
    "# Save\n",
    "pred_out = OUT_DIR / \"predictions_test_asset_hour.parquet\"\n",
    "pred_df.to_parquet(pred_out, index=False)\n",
    "\n",
    "print(\"\\nSaved predictions table:\")\n",
    "print(\" \", pred_out)\n",
    "print(\"\\nTop 20 highest-risk rows (test):\")\n",
    "display(pred_df.sort_values(\"p_risk\", ascending=False).head(20))\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Quick calibration-ish buckets (do predicted probabilities separate positives?)\n",
    "# -----------------------------\n",
    "bins = 10\n",
    "pred_df[\"_bucket\"] = pd.qcut(pred_df[\"p_risk\"], q=bins, duplicates=\"drop\")\n",
    "bucket_stats = (\n",
    "    pred_df.groupby(\"_bucket\", observed=True)\n",
    "    .agg(\n",
    "        n=(\"y_true\", \"size\"),\n",
    "        positive_rate=(\"y_true\", \"mean\"),\n",
    "        p_mean=(\"p_risk\", \"mean\"),\n",
    "        p_min=(\"p_risk\", \"min\"),\n",
    "        p_max=(\"p_risk\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\nRisk bucket summary (qcut into deciles):\")\n",
    "display(bucket_stats)\n",
    "\n",
    "# Clean temp column\n",
    "pred_df.drop(columns=[\"_bucket\"], inplace=True, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b193a1-0227-4103-899b-d800a9b2a520",
   "metadata": {},
   "source": [
    "### What Cell 9 Just Did\n",
    "This cell performed **threshold tuning** on the model’s probability outputs and created a **traceable scoring table** so every prediction can be tied back to a specific **asset + hour** (and later rolled up to asset/day alerting).\n",
    "\n",
    "It typically:\n",
    "- **Generated predicted probabilities** (`p_hat`) for the test set (and sometimes train for reference).\n",
    "- **Swept decision thresholds** across a grid (e.g., 0.05 → 0.95) to compute threshold-dependent metrics such as:\n",
    "  - precision, recall, F1\n",
    "  - true/false positives/negatives\n",
    "  - sometimes alerts triggered / rate-based summaries\n",
    "- **Selected a reference operating threshold** (often “best F1” unless overridden later by an operational budget policy).\n",
    "- **Built a predictions dataframe** that joins:\n",
    "  - identifiers from `ids_test` (e.g., `asset_id`, `ts_hour_utc`, `site_id`, `line_id`, `asset_type`, etc.)\n",
    "  - `y_true` (the forward-looking label)\n",
    "  - `p_hat` (model score)\n",
    "  - optional `y_pred` columns at one or more thresholds\n",
    "- **Persisted artifacts for downstream analysis**, usually including:\n",
    "  - a CSV of the threshold sweep / tradeoff curve\n",
    "  - a “scores with IDs” table (so you can debug individual hours and roll up to asset/day)\n",
    "- Enabled the later “actionability” work (top assets/day and “why”) by ensuring predictions are **auditable** and **reproducible**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97d924b7-fbfb-43fb-b0ce-07f2d8ba8acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "  X_test_tx: (8093, 168) | sparse: True\n",
      "  # feature_names: 168\n",
      "  predictions table: (8093, 9)\n",
      "\n",
      "Saved global coefficient table:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/logreg_coefficients.csv\n",
      "\n",
      "Top 25 coefficients by absolute magnitude:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-3.627807</td>\n",
       "      <td>3.627807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>line_id_S2-L3</td>\n",
       "      <td>3.277419</td>\n",
       "      <td>3.277419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>vibration_mm_s_max_roll12h_std</td>\n",
       "      <td>-3.249974</td>\n",
       "      <td>3.249974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>3.030807</td>\n",
       "      <td>3.030807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>2.860782</td>\n",
       "      <td>2.860782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>line_id_S3-L2</td>\n",
       "      <td>-2.741310</td>\n",
       "      <td>2.741310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>vibration_mm_s_mean_roll12h_std</td>\n",
       "      <td>2.572287</td>\n",
       "      <td>2.572287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>line_id_S3-L5</td>\n",
       "      <td>2.352172</td>\n",
       "      <td>2.352172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>temp_c_max_roll12h_mean</td>\n",
       "      <td>-2.301484</td>\n",
       "      <td>2.301484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-2.227523</td>\n",
       "      <td>2.227523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>line_id_S4-L4</td>\n",
       "      <td>2.219993</td>\n",
       "      <td>2.219993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>pressure_kpa_mean_roll12h_mean</td>\n",
       "      <td>2.144437</td>\n",
       "      <td>2.144437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>asset_type_capper</td>\n",
       "      <td>2.086919</td>\n",
       "      <td>2.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-2.055362</td>\n",
       "      <td>2.055362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>pressure_kpa_max_roll12h_mean</td>\n",
       "      <td>-1.954750</td>\n",
       "      <td>1.954750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>line_speed_u_min_max_roll6h_mean</td>\n",
       "      <td>1.720678</td>\n",
       "      <td>1.720678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>asset_type_case_packer</td>\n",
       "      <td>1.597252</td>\n",
       "      <td>1.597252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>line_id_S2-L4</td>\n",
       "      <td>1.578042</td>\n",
       "      <td>1.578042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>line_id_S4-L1</td>\n",
       "      <td>1.577696</td>\n",
       "      <td>1.577696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>reject_rate_pct_mean_roll12h_std</td>\n",
       "      <td>-1.561786</td>\n",
       "      <td>1.561786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>temp_c_max_roll12h_std</td>\n",
       "      <td>-1.509104</td>\n",
       "      <td>1.509104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>line_speed_u_min_mean_roll6h_mean</td>\n",
       "      <td>-1.470588</td>\n",
       "      <td>1.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>line_speed_u_min_max_roll12h_std</td>\n",
       "      <td>-1.409706</td>\n",
       "      <td>1.409706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>line_speed_u_min_mean_roll12h_std</td>\n",
       "      <td>1.366542</td>\n",
       "      <td>1.366542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>temp_c_mean_roll12h_mean</td>\n",
       "      <td>1.301523</td>\n",
       "      <td>1.301523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature      coef  abs_coef\n",
       "145                      line_id_S2-L5 -3.627807  3.627807\n",
       "143                      line_id_S2-L3  3.277419  3.277419\n",
       "116     vibration_mm_s_max_roll12h_std -3.249974  3.249974\n",
       "159                asset_type_cartoner  3.030807  3.030807\n",
       "155                      line_id_S4-L5  2.860782  2.860782\n",
       "147                      line_id_S3-L2 -2.741310  2.741310\n",
       "122    vibration_mm_s_mean_roll12h_std  2.572287  2.572287\n",
       "150                      line_id_S3-L5  2.352172  2.352172\n",
       "97             temp_c_max_roll12h_mean -2.301484  2.301484\n",
       "137                      line_id_S1-L2 -2.227523  2.227523\n",
       "154                      line_id_S4-L4  2.219993  2.219993\n",
       "101     pressure_kpa_mean_roll12h_mean  2.144437  2.144437\n",
       "158                  asset_type_capper  2.086919  2.086919\n",
       "164             asset_type_print_apply -2.055362  2.055362\n",
       "95       pressure_kpa_max_roll12h_mean -1.954750  1.954750\n",
       "58    line_speed_u_min_max_roll6h_mean  1.720678  1.720678\n",
       "160             asset_type_case_packer  1.597252  1.597252\n",
       "144                      line_id_S2-L4  1.578042  1.578042\n",
       "151                      line_id_S4-L1  1.577696  1.577696\n",
       "120   reject_rate_pct_mean_roll12h_std -1.561786  1.561786\n",
       "115             temp_c_max_roll12h_std -1.509104  1.509104\n",
       "64   line_speed_u_min_mean_roll6h_mean -1.470588  1.470588\n",
       "112   line_speed_u_min_max_roll12h_std -1.409706  1.409706\n",
       "118  line_speed_u_min_mean_roll12h_std  1.366542  1.366542\n",
       "103           temp_c_mean_roll12h_mean  1.301523  1.301523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most positive (pushes risk UP):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>line_id_S2-L3</td>\n",
       "      <td>3.277419</td>\n",
       "      <td>3.277419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>3.030807</td>\n",
       "      <td>3.030807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>2.860782</td>\n",
       "      <td>2.860782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>vibration_mm_s_mean_roll12h_std</td>\n",
       "      <td>2.572287</td>\n",
       "      <td>2.572287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>line_id_S3-L5</td>\n",
       "      <td>2.352172</td>\n",
       "      <td>2.352172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>line_id_S4-L4</td>\n",
       "      <td>2.219993</td>\n",
       "      <td>2.219993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>pressure_kpa_mean_roll12h_mean</td>\n",
       "      <td>2.144437</td>\n",
       "      <td>2.144437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>asset_type_capper</td>\n",
       "      <td>2.086919</td>\n",
       "      <td>2.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>line_speed_u_min_max_roll6h_mean</td>\n",
       "      <td>1.720678</td>\n",
       "      <td>1.720678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>asset_type_case_packer</td>\n",
       "      <td>1.597252</td>\n",
       "      <td>1.597252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>line_id_S2-L4</td>\n",
       "      <td>1.578042</td>\n",
       "      <td>1.578042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>line_id_S4-L1</td>\n",
       "      <td>1.577696</td>\n",
       "      <td>1.577696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>line_speed_u_min_mean_roll12h_std</td>\n",
       "      <td>1.366542</td>\n",
       "      <td>1.366542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>temp_c_mean_roll12h_mean</td>\n",
       "      <td>1.301523</td>\n",
       "      <td>1.301523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>temp_c_max_roll6h_mean</td>\n",
       "      <td>1.230662</td>\n",
       "      <td>1.230662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature      coef  abs_coef\n",
       "143                      line_id_S2-L3  3.277419  3.277419\n",
       "159                asset_type_cartoner  3.030807  3.030807\n",
       "155                      line_id_S4-L5  2.860782  2.860782\n",
       "122    vibration_mm_s_mean_roll12h_std  2.572287  2.572287\n",
       "150                      line_id_S3-L5  2.352172  2.352172\n",
       "154                      line_id_S4-L4  2.219993  2.219993\n",
       "101     pressure_kpa_mean_roll12h_mean  2.144437  2.144437\n",
       "158                  asset_type_capper  2.086919  2.086919\n",
       "58    line_speed_u_min_max_roll6h_mean  1.720678  1.720678\n",
       "160             asset_type_case_packer  1.597252  1.597252\n",
       "144                      line_id_S2-L4  1.578042  1.578042\n",
       "151                      line_id_S4-L1  1.577696  1.577696\n",
       "118  line_speed_u_min_mean_roll12h_std  1.366542  1.366542\n",
       "103           temp_c_mean_roll12h_mean  1.301523  1.301523\n",
       "61              temp_c_max_roll6h_mean  1.230662  1.230662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most negative (pushes risk DOWN):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-3.627807</td>\n",
       "      <td>3.627807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>vibration_mm_s_max_roll12h_std</td>\n",
       "      <td>-3.249974</td>\n",
       "      <td>3.249974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>line_id_S3-L2</td>\n",
       "      <td>-2.741310</td>\n",
       "      <td>2.741310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>temp_c_max_roll12h_mean</td>\n",
       "      <td>-2.301484</td>\n",
       "      <td>2.301484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-2.227523</td>\n",
       "      <td>2.227523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-2.055362</td>\n",
       "      <td>2.055362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>pressure_kpa_max_roll12h_mean</td>\n",
       "      <td>-1.954750</td>\n",
       "      <td>1.954750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>reject_rate_pct_mean_roll12h_std</td>\n",
       "      <td>-1.561786</td>\n",
       "      <td>1.561786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>temp_c_max_roll12h_std</td>\n",
       "      <td>-1.509104</td>\n",
       "      <td>1.509104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>line_speed_u_min_mean_roll6h_mean</td>\n",
       "      <td>-1.470588</td>\n",
       "      <td>1.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>line_speed_u_min_max_roll12h_std</td>\n",
       "      <td>-1.409706</td>\n",
       "      <td>1.409706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>asset_type_labeler</td>\n",
       "      <td>-1.268630</td>\n",
       "      <td>1.268630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>line_id_S3-L1</td>\n",
       "      <td>-1.173880</td>\n",
       "      <td>1.173880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>temp_c_mean_roll6h_mean</td>\n",
       "      <td>-1.162493</td>\n",
       "      <td>1.162493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temp_c_max</td>\n",
       "      <td>-1.068893</td>\n",
       "      <td>1.068893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature      coef  abs_coef\n",
       "145                      line_id_S2-L5 -3.627807  3.627807\n",
       "116     vibration_mm_s_max_roll12h_std -3.249974  3.249974\n",
       "147                      line_id_S3-L2 -2.741310  2.741310\n",
       "97             temp_c_max_roll12h_mean -2.301484  2.301484\n",
       "137                      line_id_S1-L2 -2.227523  2.227523\n",
       "164             asset_type_print_apply -2.055362  2.055362\n",
       "95       pressure_kpa_max_roll12h_mean -1.954750  1.954750\n",
       "120   reject_rate_pct_mean_roll12h_std -1.561786  1.561786\n",
       "115             temp_c_max_roll12h_std -1.509104  1.509104\n",
       "64   line_speed_u_min_mean_roll6h_mean -1.470588  1.470588\n",
       "112   line_speed_u_min_max_roll12h_std -1.409706  1.409706\n",
       "163                 asset_type_labeler -1.268630  1.268630\n",
       "146                      line_id_S3-L1 -1.173880  1.173880\n",
       "67             temp_c_mean_roll6h_mean -1.162493  1.162493\n",
       "4                           temp_c_max -1.068893  1.068893"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explaining top 15 highest-risk test rows...\n",
      "\n",
      "Saved top-risk summary:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/top_risk_rows_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>ts_hour_utc</th>\n",
       "      <th>p_risk</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A0069</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>2025-12-09 13:00:00+00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A0099</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>2025-12-09 19:00:00+00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A0068</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>2025-12-10 17:00:00+00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A0099</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>2025-12-09 16:00:00+00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A0068</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>2025-12-09 06:00:00+00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>A0099</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>2025-12-09 17:00:00+00:00</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>A0099</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>2025-12-09 18:00:00+00:00</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>A0112</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>2025-12-08 13:00:00+00:00</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>A0066</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>2025-12-09 06:00:00+00:00</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>A0020</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>2025-12-10 22:00:00+00:00</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>A0068</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>2025-12-10 16:00:00+00:00</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>A0091</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L4</td>\n",
       "      <td>2025-12-10 15:00:00+00:00</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>A0066</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>2025-12-09 08:00:00+00:00</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>A0056</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>2025-12-08 06:00:00+00:00</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>A0066</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>2025-12-09 10:00:00+00:00</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank asset_id site_id line_id                ts_hour_utc    p_risk  \\\n",
       "0      1    A0069      S2   S2-L3  2025-12-09 13:00:00+00:00  1.000000   \n",
       "1      2    A0099      S3   S3-L5  2025-12-09 19:00:00+00:00  1.000000   \n",
       "2      3    A0068      S2   S2-L3  2025-12-10 17:00:00+00:00  1.000000   \n",
       "3      4    A0099      S3   S3-L5  2025-12-09 16:00:00+00:00  1.000000   \n",
       "4      5    A0068      S2   S2-L3  2025-12-09 06:00:00+00:00  1.000000   \n",
       "5      6    A0099      S3   S3-L5  2025-12-09 17:00:00+00:00  0.999999   \n",
       "6      7    A0099      S3   S3-L5  2025-12-09 18:00:00+00:00  0.999999   \n",
       "7      8    A0112      S1   S1-L1  2025-12-08 13:00:00+00:00  0.999999   \n",
       "8      9    A0066      S1   S1-L5  2025-12-09 06:00:00+00:00  0.999998   \n",
       "9     10    A0020      S4   S4-L2  2025-12-10 22:00:00+00:00  0.999998   \n",
       "10    11    A0068      S2   S2-L3  2025-12-10 16:00:00+00:00  0.999998   \n",
       "11    12    A0091      S1   S1-L4  2025-12-10 15:00:00+00:00  0.999997   \n",
       "12    13    A0066      S1   S1-L5  2025-12-09 08:00:00+00:00  0.999996   \n",
       "13    14    A0056      S3   S3-L1  2025-12-08 06:00:00+00:00  0.999996   \n",
       "14    15    A0066      S1   S1-L5  2025-12-09 10:00:00+00:00  0.999996   \n",
       "\n",
       "    y_true  y_pred  \n",
       "0        0       1  \n",
       "1        0       1  \n",
       "2        0       1  \n",
       "3        0       1  \n",
       "4        0       1  \n",
       "5        0       1  \n",
       "6        0       1  \n",
       "7        0       1  \n",
       "8        0       1  \n",
       "9        0       1  \n",
       "10       0       1  \n",
       "11       0       1  \n",
       "12       0       1  \n",
       "13       0       1  \n",
       "14       0       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 1 | asset=A0069 site=S2 line=S2-L3 | ts=2025-12-09 13:00:00+00:00 | p_risk=1.000000 | y_true=0 y_pred=1\n",
      "\n",
      "Top POSITIVE contributions (push risk up):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>pressure_kpa_mean_roll12h_mean</td>\n",
       "      <td>12.714618</td>\n",
       "      <td>2.144437</td>\n",
       "      <td>27.265693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>line_speed_u_min_max_roll6h_mean</td>\n",
       "      <td>8.529498</td>\n",
       "      <td>1.720678</td>\n",
       "      <td>14.676521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>pressure_kpa_max_roll6h_mean</td>\n",
       "      <td>11.029166</td>\n",
       "      <td>0.936803</td>\n",
       "      <td>10.332155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>vibration_mm_s_mean_roll12h_std</td>\n",
       "      <td>4.015229</td>\n",
       "      <td>2.572287</td>\n",
       "      <td>10.328322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>temp_c_mean_roll12h_mean</td>\n",
       "      <td>6.840441</td>\n",
       "      <td>1.301523</td>\n",
       "      <td>8.902989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>temp_c_mean_roll3h_mean</td>\n",
       "      <td>7.143580</td>\n",
       "      <td>1.176743</td>\n",
       "      <td>8.406157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>temp_c_max_roll6h_mean</td>\n",
       "      <td>6.736251</td>\n",
       "      <td>1.230662</td>\n",
       "      <td>8.290049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>humidity_rh_mean_roll6h_mean</td>\n",
       "      <td>7.029529</td>\n",
       "      <td>0.929568</td>\n",
       "      <td>6.534422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>humidity_rh_mean_roll6h_std</td>\n",
       "      <td>5.462219</td>\n",
       "      <td>1.022053</td>\n",
       "      <td>5.582676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>reject_rate_pct_max_roll12h_std</td>\n",
       "      <td>5.252565</td>\n",
       "      <td>0.979568</td>\n",
       "      <td>5.145245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature      value      coef  contribution\n",
       "98     pressure_kpa_mean_roll12h_mean  12.714618  2.144437     27.265693\n",
       "55   line_speed_u_min_max_roll6h_mean   8.529498  1.720678     14.676521\n",
       "56       pressure_kpa_max_roll6h_mean  11.029166  0.936803     10.332155\n",
       "119   vibration_mm_s_mean_roll12h_std   4.015229  2.572287     10.328322\n",
       "100          temp_c_mean_roll12h_mean   6.840441  1.301523      8.902989\n",
       "28            temp_c_mean_roll3h_mean   7.143580  1.176743      8.406157\n",
       "58             temp_c_max_roll6h_mean   6.736251  1.230662      8.290049\n",
       "60       humidity_rh_mean_roll6h_mean   7.029529  0.929568      6.534422\n",
       "78        humidity_rh_mean_roll6h_std   5.462219  1.022053      5.582676\n",
       "111   reject_rate_pct_max_roll12h_std   5.252565  0.979568      5.145245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top NEGATIVE contributions (push risk down):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>pressure_kpa_max_roll12h_mean</td>\n",
       "      <td>11.941020</td>\n",
       "      <td>-1.954750</td>\n",
       "      <td>-23.341712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>temp_c_max_roll12h_mean</td>\n",
       "      <td>7.019658</td>\n",
       "      <td>-2.301484</td>\n",
       "      <td>-16.155631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>vibration_mm_s_max_roll12h_std</td>\n",
       "      <td>4.595990</td>\n",
       "      <td>-3.249974</td>\n",
       "      <td>-14.936850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>line_speed_u_min_mean_roll6h_mean</td>\n",
       "      <td>9.206587</td>\n",
       "      <td>-1.470588</td>\n",
       "      <td>-13.539097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>pressure_kpa_mean_roll6h_mean</td>\n",
       "      <td>11.901096</td>\n",
       "      <td>-0.893381</td>\n",
       "      <td>-10.632215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>temp_c_mean_roll6h_mean</td>\n",
       "      <td>6.849958</td>\n",
       "      <td>-1.162493</td>\n",
       "      <td>-7.963028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>humidity_rh_mean_roll12h_mean</td>\n",
       "      <td>10.402499</td>\n",
       "      <td>-0.726855</td>\n",
       "      <td>-7.561107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>reject_rate_pct_mean_roll12h_std</td>\n",
       "      <td>4.654116</td>\n",
       "      <td>-1.561786</td>\n",
       "      <td>-7.268732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>temp_c_max</td>\n",
       "      <td>5.900087</td>\n",
       "      <td>-1.068893</td>\n",
       "      <td>-6.306561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pressure_kpa_mean_roll3h_mean</td>\n",
       "      <td>10.676521</td>\n",
       "      <td>-0.556360</td>\n",
       "      <td>-5.939985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature      value      coef  contribution\n",
       "92       pressure_kpa_max_roll12h_mean  11.941020 -1.954750    -23.341712\n",
       "94             temp_c_max_roll12h_mean   7.019658 -2.301484    -16.155631\n",
       "113     vibration_mm_s_max_roll12h_std   4.595990 -3.249974    -14.936850\n",
       "61   line_speed_u_min_mean_roll6h_mean   9.206587 -1.470588    -13.539097\n",
       "62       pressure_kpa_mean_roll6h_mean  11.901096 -0.893381    -10.632215\n",
       "64             temp_c_mean_roll6h_mean   6.849958 -1.162493     -7.963028\n",
       "96       humidity_rh_mean_roll12h_mean  10.402499 -0.726855     -7.561107\n",
       "117   reject_rate_pct_mean_roll12h_std   4.654116 -1.561786     -7.268732\n",
       "3                           temp_c_max   5.900087 -1.068893     -6.306561\n",
       "26       pressure_kpa_mean_roll3h_mean  10.676521 -0.556360     -5.939985"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 2 | asset=A0099 site=S3 line=S3-L5 | ts=2025-12-09 19:00:00+00:00 | p_risk=1.000000 | y_true=0 y_pred=1\n",
      "\n",
      "Top POSITIVE contributions (push risk up):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>pressure_kpa_mean_roll12h_mean</td>\n",
       "      <td>13.074334</td>\n",
       "      <td>2.144437</td>\n",
       "      <td>28.037082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>line_speed_u_min_max_roll6h_mean</td>\n",
       "      <td>8.671327</td>\n",
       "      <td>1.720678</td>\n",
       "      <td>14.920563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>vibration_mm_s_mean_roll12h_std</td>\n",
       "      <td>4.083654</td>\n",
       "      <td>2.572287</td>\n",
       "      <td>10.504333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>pressure_kpa_max_roll6h_mean</td>\n",
       "      <td>11.192746</td>\n",
       "      <td>0.936803</td>\n",
       "      <td>10.485397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>temp_c_mean_roll12h_mean</td>\n",
       "      <td>7.667545</td>\n",
       "      <td>1.301523</td>\n",
       "      <td>9.979485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>temp_c_max_roll6h_mean</td>\n",
       "      <td>7.831084</td>\n",
       "      <td>1.230662</td>\n",
       "      <td>9.637418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>humidity_rh_mean_roll6h_mean</td>\n",
       "      <td>9.732941</td>\n",
       "      <td>0.929568</td>\n",
       "      <td>9.047426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>temp_c_mean_roll3h_mean</td>\n",
       "      <td>7.229720</td>\n",
       "      <td>1.176743</td>\n",
       "      <td>8.507521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>vibration_mm_s_std_roll12h_std</td>\n",
       "      <td>5.055616</td>\n",
       "      <td>1.189447</td>\n",
       "      <td>6.013385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>temp_c_mean</td>\n",
       "      <td>6.862282</td>\n",
       "      <td>0.809561</td>\n",
       "      <td>5.555434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature      value      coef  contribution\n",
       "98     pressure_kpa_mean_roll12h_mean  13.074334  2.144437     28.037082\n",
       "55   line_speed_u_min_max_roll6h_mean   8.671327  1.720678     14.920563\n",
       "119   vibration_mm_s_mean_roll12h_std   4.083654  2.572287     10.504333\n",
       "56       pressure_kpa_max_roll6h_mean  11.192746  0.936803     10.485397\n",
       "100          temp_c_mean_roll12h_mean   7.667545  1.301523      9.979485\n",
       "58             temp_c_max_roll6h_mean   7.831084  1.230662      9.637418\n",
       "60       humidity_rh_mean_roll6h_mean   9.732941  0.929568      9.047426\n",
       "28            temp_c_mean_roll3h_mean   7.229720  1.176743      8.507521\n",
       "125    vibration_mm_s_std_roll12h_std   5.055616  1.189447      6.013385\n",
       "9                         temp_c_mean   6.862282  0.809561      5.555434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top NEGATIVE contributions (push risk down):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>pressure_kpa_max_roll12h_mean</td>\n",
       "      <td>12.178160</td>\n",
       "      <td>-1.954750</td>\n",
       "      <td>-23.805262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>temp_c_max_roll12h_mean</td>\n",
       "      <td>7.750902</td>\n",
       "      <td>-2.301484</td>\n",
       "      <td>-17.838579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>vibration_mm_s_max_roll12h_std</td>\n",
       "      <td>4.458235</td>\n",
       "      <td>-3.249974</td>\n",
       "      <td>-14.489147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>line_speed_u_min_mean_roll6h_mean</td>\n",
       "      <td>8.531880</td>\n",
       "      <td>-1.470588</td>\n",
       "      <td>-12.546881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>pressure_kpa_mean_roll6h_mean</td>\n",
       "      <td>12.106426</td>\n",
       "      <td>-0.893381</td>\n",
       "      <td>-10.815653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>temp_c_mean_roll6h_mean</td>\n",
       "      <td>7.785287</td>\n",
       "      <td>-1.162493</td>\n",
       "      <td>-9.050340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>humidity_rh_mean_roll12h_mean</td>\n",
       "      <td>12.054293</td>\n",
       "      <td>-0.726855</td>\n",
       "      <td>-8.761722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>humidity_rh_max_roll6h_mean</td>\n",
       "      <td>9.836302</td>\n",
       "      <td>-0.872409</td>\n",
       "      <td>-8.581274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temp_c_max</td>\n",
       "      <td>6.316953</td>\n",
       "      <td>-1.068893</td>\n",
       "      <td>-6.752145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>reject_rate_pct_mean_roll12h_std</td>\n",
       "      <td>3.995531</td>\n",
       "      <td>-1.561786</td>\n",
       "      <td>-6.240163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature      value      coef  contribution\n",
       "92       pressure_kpa_max_roll12h_mean  12.178160 -1.954750    -23.805262\n",
       "94             temp_c_max_roll12h_mean   7.750902 -2.301484    -17.838579\n",
       "113     vibration_mm_s_max_roll12h_std   4.458235 -3.249974    -14.489147\n",
       "61   line_speed_u_min_mean_roll6h_mean   8.531880 -1.470588    -12.546881\n",
       "62       pressure_kpa_mean_roll6h_mean  12.106426 -0.893381    -10.815653\n",
       "64             temp_c_mean_roll6h_mean   7.785287 -1.162493     -9.050340\n",
       "96       humidity_rh_mean_roll12h_mean  12.054293 -0.726855     -8.761722\n",
       "54         humidity_rh_max_roll6h_mean   9.836302 -0.872409     -8.581274\n",
       "4                           temp_c_max   6.316953 -1.068893     -6.752145\n",
       "117   reject_rate_pct_mean_roll12h_std   3.995531 -1.561786     -6.240163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 3 | asset=A0068 site=S2 line=S2-L3 | ts=2025-12-10 17:00:00+00:00 | p_risk=1.000000 | y_true=0 y_pred=1\n",
      "\n",
      "Top POSITIVE contributions (push risk up):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>pressure_kpa_mean_roll12h_mean</td>\n",
       "      <td>13.606180</td>\n",
       "      <td>2.144437</td>\n",
       "      <td>29.177590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>line_speed_u_min_max_roll6h_mean</td>\n",
       "      <td>7.730670</td>\n",
       "      <td>1.720678</td>\n",
       "      <td>13.301996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pressure_kpa_max_roll6h_mean</td>\n",
       "      <td>13.054412</td>\n",
       "      <td>0.936803</td>\n",
       "      <td>12.229411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>temp_c_mean_roll12h_mean</td>\n",
       "      <td>7.986081</td>\n",
       "      <td>1.301523</td>\n",
       "      <td>10.394067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>temp_c_max_roll6h_mean</td>\n",
       "      <td>7.868962</td>\n",
       "      <td>1.230662</td>\n",
       "      <td>9.684033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>temp_c_mean_roll3h_mean</td>\n",
       "      <td>8.074995</td>\n",
       "      <td>1.176743</td>\n",
       "      <td>9.502192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>humidity_rh_mean_roll6h_mean</td>\n",
       "      <td>9.942823</td>\n",
       "      <td>0.929568</td>\n",
       "      <td>9.242526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>temp_c_mean</td>\n",
       "      <td>7.200319</td>\n",
       "      <td>0.809561</td>\n",
       "      <td>5.829095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>vibration_mm_s_mean_roll12h_std</td>\n",
       "      <td>1.824870</td>\n",
       "      <td>2.572287</td>\n",
       "      <td>4.694090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>vibration_mm_s_std_roll12h_std</td>\n",
       "      <td>3.597157</td>\n",
       "      <td>1.189447</td>\n",
       "      <td>4.278626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature      value      coef  contribution\n",
       "100    pressure_kpa_mean_roll12h_mean  13.606180  2.144437     29.177590\n",
       "57   line_speed_u_min_max_roll6h_mean   7.730670  1.720678     13.301996\n",
       "58       pressure_kpa_max_roll6h_mean  13.054412  0.936803     12.229411\n",
       "102          temp_c_mean_roll12h_mean   7.986081  1.301523     10.394067\n",
       "60             temp_c_max_roll6h_mean   7.868962  1.230662      9.684033\n",
       "30            temp_c_mean_roll3h_mean   8.074995  1.176743      9.502192\n",
       "62       humidity_rh_mean_roll6h_mean   9.942823  0.929568      9.242526\n",
       "10                        temp_c_mean   7.200319  0.809561      5.829095\n",
       "121   vibration_mm_s_mean_roll12h_std   1.824870  2.572287      4.694090\n",
       "127    vibration_mm_s_std_roll12h_std   3.597157  1.189447      4.278626"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top NEGATIVE contributions (push risk down):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>pressure_kpa_max_roll12h_mean</td>\n",
       "      <td>13.286242</td>\n",
       "      <td>-1.954750</td>\n",
       "      <td>-25.971285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>temp_c_max_roll12h_mean</td>\n",
       "      <td>7.950530</td>\n",
       "      <td>-2.301484</td>\n",
       "      <td>-18.298019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>line_speed_u_min_mean_roll6h_mean</td>\n",
       "      <td>8.165592</td>\n",
       "      <td>-1.470588</td>\n",
       "      <td>-12.008221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>pressure_kpa_mean_roll6h_mean</td>\n",
       "      <td>12.946562</td>\n",
       "      <td>-0.893381</td>\n",
       "      <td>-11.566214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>temp_c_mean_roll6h_mean</td>\n",
       "      <td>7.887281</td>\n",
       "      <td>-1.162493</td>\n",
       "      <td>-9.168908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>humidity_rh_mean_roll12h_mean</td>\n",
       "      <td>10.937185</td>\n",
       "      <td>-0.726855</td>\n",
       "      <td>-7.949747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>humidity_rh_max_roll6h_mean</td>\n",
       "      <td>8.869472</td>\n",
       "      <td>-0.872409</td>\n",
       "      <td>-7.737804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temp_c_max</td>\n",
       "      <td>6.628127</td>\n",
       "      <td>-1.068893</td>\n",
       "      <td>-7.084757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pressure_kpa_mean_roll3h_mean</td>\n",
       "      <td>10.417967</td>\n",
       "      <td>-0.556360</td>\n",
       "      <td>-5.796137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>vibration_mm_s_max_roll12h_std</td>\n",
       "      <td>1.765742</td>\n",
       "      <td>-3.249974</td>\n",
       "      <td>-5.738615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature      value      coef  contribution\n",
       "94       pressure_kpa_max_roll12h_mean  13.286242 -1.954750    -25.971285\n",
       "96             temp_c_max_roll12h_mean   7.950530 -2.301484    -18.298019\n",
       "63   line_speed_u_min_mean_roll6h_mean   8.165592 -1.470588    -12.008221\n",
       "64       pressure_kpa_mean_roll6h_mean  12.946562 -0.893381    -11.566214\n",
       "66             temp_c_mean_roll6h_mean   7.887281 -1.162493     -9.168908\n",
       "98       humidity_rh_mean_roll12h_mean  10.937185 -0.726855     -7.949747\n",
       "56         humidity_rh_max_roll6h_mean   8.869472 -0.872409     -7.737804\n",
       "4                           temp_c_max   6.628127 -1.068893     -7.084757\n",
       "28       pressure_kpa_mean_roll3h_mean  10.417967 -0.556360     -5.796137\n",
       "115     vibration_mm_s_max_roll12h_std   1.765742 -3.249974     -5.738615"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 4 | asset=A0099 site=S3 line=S3-L5 | ts=2025-12-09 16:00:00+00:00 | p_risk=1.000000 | y_true=0 y_pred=1\n",
      "\n",
      "Top POSITIVE contributions (push risk up):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>pressure_kpa_mean_roll12h_mean</td>\n",
       "      <td>13.409149</td>\n",
       "      <td>2.144437</td>\n",
       "      <td>28.755070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>line_speed_u_min_max_roll6h_mean</td>\n",
       "      <td>9.118856</td>\n",
       "      <td>1.720678</td>\n",
       "      <td>15.690617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pressure_kpa_max_roll6h_mean</td>\n",
       "      <td>10.833422</td>\n",
       "      <td>0.936803</td>\n",
       "      <td>10.148782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>temp_c_mean_roll12h_mean</td>\n",
       "      <td>7.548483</td>\n",
       "      <td>1.301523</td>\n",
       "      <td>9.824523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>humidity_rh_mean_roll6h_mean</td>\n",
       "      <td>9.884967</td>\n",
       "      <td>0.929568</td>\n",
       "      <td>9.188745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>vibration_mm_s_mean_roll12h_std</td>\n",
       "      <td>3.552891</td>\n",
       "      <td>2.572287</td>\n",
       "      <td>9.139056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>temp_c_max_roll6h_mean</td>\n",
       "      <td>7.189069</td>\n",
       "      <td>1.230662</td>\n",
       "      <td>8.847315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>temp_c_mean_roll3h_mean</td>\n",
       "      <td>7.228874</td>\n",
       "      <td>1.176743</td>\n",
       "      <td>8.506526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>vibration_mm_s_std_roll12h_std</td>\n",
       "      <td>4.617679</td>\n",
       "      <td>1.189447</td>\n",
       "      <td>5.492482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>temp_c_mean</td>\n",
       "      <td>6.618609</td>\n",
       "      <td>0.809561</td>\n",
       "      <td>5.358166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature      value      coef  contribution\n",
       "100    pressure_kpa_mean_roll12h_mean  13.409149  2.144437     28.755070\n",
       "57   line_speed_u_min_max_roll6h_mean   9.118856  1.720678     15.690617\n",
       "58       pressure_kpa_max_roll6h_mean  10.833422  0.936803     10.148782\n",
       "102          temp_c_mean_roll12h_mean   7.548483  1.301523      9.824523\n",
       "62       humidity_rh_mean_roll6h_mean   9.884967  0.929568      9.188745\n",
       "121   vibration_mm_s_mean_roll12h_std   3.552891  2.572287      9.139056\n",
       "60             temp_c_max_roll6h_mean   7.189069  1.230662      8.847315\n",
       "30            temp_c_mean_roll3h_mean   7.228874  1.176743      8.506526\n",
       "127    vibration_mm_s_std_roll12h_std   4.617679  1.189447      5.492482\n",
       "10                        temp_c_mean   6.618609  0.809561      5.358166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top NEGATIVE contributions (push risk down):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>pressure_kpa_max_roll12h_mean</td>\n",
       "      <td>12.494395</td>\n",
       "      <td>-1.954750</td>\n",
       "      <td>-24.423422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>temp_c_max_roll12h_mean</td>\n",
       "      <td>7.756419</td>\n",
       "      <td>-2.301484</td>\n",
       "      <td>-17.851276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>line_speed_u_min_mean_roll6h_mean</td>\n",
       "      <td>9.388177</td>\n",
       "      <td>-1.470588</td>\n",
       "      <td>-13.806141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>vibration_mm_s_max_roll12h_std</td>\n",
       "      <td>4.159892</td>\n",
       "      <td>-3.249974</td>\n",
       "      <td>-13.519541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>pressure_kpa_mean_roll6h_mean</td>\n",
       "      <td>11.715062</td>\n",
       "      <td>-0.893381</td>\n",
       "      <td>-10.466016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>humidity_rh_max_roll6h_mean</td>\n",
       "      <td>11.352749</td>\n",
       "      <td>-0.872409</td>\n",
       "      <td>-9.904236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>temp_c_mean_roll6h_mean</td>\n",
       "      <td>7.367382</td>\n",
       "      <td>-1.162493</td>\n",
       "      <td>-8.564530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>humidity_rh_mean_roll12h_mean</td>\n",
       "      <td>10.157982</td>\n",
       "      <td>-0.726855</td>\n",
       "      <td>-7.383379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temp_c_max</td>\n",
       "      <td>6.092644</td>\n",
       "      <td>-1.068893</td>\n",
       "      <td>-6.512383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>reject_rate_pct_mean_roll12h_std</td>\n",
       "      <td>3.714690</td>\n",
       "      <td>-1.561786</td>\n",
       "      <td>-5.801551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature      value      coef  contribution\n",
       "94       pressure_kpa_max_roll12h_mean  12.494395 -1.954750    -24.423422\n",
       "96             temp_c_max_roll12h_mean   7.756419 -2.301484    -17.851276\n",
       "63   line_speed_u_min_mean_roll6h_mean   9.388177 -1.470588    -13.806141\n",
       "115     vibration_mm_s_max_roll12h_std   4.159892 -3.249974    -13.519541\n",
       "64       pressure_kpa_mean_roll6h_mean  11.715062 -0.893381    -10.466016\n",
       "56         humidity_rh_max_roll6h_mean  11.352749 -0.872409     -9.904236\n",
       "66             temp_c_mean_roll6h_mean   7.367382 -1.162493     -8.564530\n",
       "98       humidity_rh_mean_roll12h_mean  10.157982 -0.726855     -7.383379\n",
       "4                           temp_c_max   6.092644 -1.068893     -6.512383\n",
       "119   reject_rate_pct_mean_roll12h_std   3.714690 -1.561786     -5.801551"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Rank 5 | asset=A0068 site=S2 line=S2-L3 | ts=2025-12-09 06:00:00+00:00 | p_risk=1.000000 | y_true=0 y_pred=1\n",
      "\n",
      "Top POSITIVE contributions (push risk up):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>pressure_kpa_mean_roll12h_mean</td>\n",
       "      <td>12.596622</td>\n",
       "      <td>2.144437</td>\n",
       "      <td>27.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>line_speed_u_min_max_roll6h_mean</td>\n",
       "      <td>8.428716</td>\n",
       "      <td>1.720678</td>\n",
       "      <td>14.503107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pressure_kpa_max_roll6h_mean</td>\n",
       "      <td>11.247140</td>\n",
       "      <td>0.936803</td>\n",
       "      <td>10.536353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>temp_c_mean_roll12h_mean</td>\n",
       "      <td>6.964350</td>\n",
       "      <td>1.301523</td>\n",
       "      <td>9.064260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>temp_c_max_roll6h_mean</td>\n",
       "      <td>7.061181</td>\n",
       "      <td>1.230662</td>\n",
       "      <td>8.689928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>humidity_rh_mean_roll6h_mean</td>\n",
       "      <td>8.872914</td>\n",
       "      <td>0.929568</td>\n",
       "      <td>8.247973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>temp_c_mean_roll3h_mean</td>\n",
       "      <td>6.908779</td>\n",
       "      <td>1.176743</td>\n",
       "      <td>8.129857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>vibration_mm_s_mean_roll12h_std</td>\n",
       "      <td>3.073298</td>\n",
       "      <td>2.572287</td>\n",
       "      <td>7.905405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>temp_c_mean</td>\n",
       "      <td>6.273921</td>\n",
       "      <td>0.809561</td>\n",
       "      <td>5.079119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>humidity_rh_mean_roll6h_std</td>\n",
       "      <td>4.027729</td>\n",
       "      <td>1.022053</td>\n",
       "      <td>4.116552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature      value      coef  contribution\n",
       "100    pressure_kpa_mean_roll12h_mean  12.596622  2.144437     27.012658\n",
       "57   line_speed_u_min_max_roll6h_mean   8.428716  1.720678     14.503107\n",
       "58       pressure_kpa_max_roll6h_mean  11.247140  0.936803     10.536353\n",
       "102          temp_c_mean_roll12h_mean   6.964350  1.301523      9.064260\n",
       "60             temp_c_max_roll6h_mean   7.061181  1.230662      8.689928\n",
       "62       humidity_rh_mean_roll6h_mean   8.872914  0.929568      8.247973\n",
       "30            temp_c_mean_roll3h_mean   6.908779  1.176743      8.129857\n",
       "121   vibration_mm_s_mean_roll12h_std   3.073298  2.572287      7.905405\n",
       "10                        temp_c_mean   6.273921  0.809561      5.079119\n",
       "80        humidity_rh_mean_roll6h_std   4.027729  1.022053      4.116552"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top NEGATIVE contributions (push risk down):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>pressure_kpa_max_roll12h_mean</td>\n",
       "      <td>12.390266</td>\n",
       "      <td>-1.954750</td>\n",
       "      <td>-24.219876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>temp_c_max_roll12h_mean</td>\n",
       "      <td>6.923478</td>\n",
       "      <td>-2.301484</td>\n",
       "      <td>-15.934276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>line_speed_u_min_mean_roll6h_mean</td>\n",
       "      <td>9.477528</td>\n",
       "      <td>-1.470588</td>\n",
       "      <td>-13.937539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>pressure_kpa_mean_roll6h_mean</td>\n",
       "      <td>11.533203</td>\n",
       "      <td>-0.893381</td>\n",
       "      <td>-10.303546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>vibration_mm_s_max_roll12h_std</td>\n",
       "      <td>3.053331</td>\n",
       "      <td>-3.249974</td>\n",
       "      <td>-9.923247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>humidity_rh_mean_roll12h_mean</td>\n",
       "      <td>12.102579</td>\n",
       "      <td>-0.726855</td>\n",
       "      <td>-8.796819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>temp_c_mean_roll6h_mean</td>\n",
       "      <td>7.151967</td>\n",
       "      <td>-1.162493</td>\n",
       "      <td>-8.314111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temp_c_max</td>\n",
       "      <td>6.293139</td>\n",
       "      <td>-1.068893</td>\n",
       "      <td>-6.726691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>humidity_rh_max_roll6h_mean</td>\n",
       "      <td>7.627101</td>\n",
       "      <td>-0.872409</td>\n",
       "      <td>-6.653949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pressure_kpa_mean_roll3h_mean</td>\n",
       "      <td>9.617640</td>\n",
       "      <td>-0.556360</td>\n",
       "      <td>-5.350867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature      value      coef  contribution\n",
       "94       pressure_kpa_max_roll12h_mean  12.390266 -1.954750    -24.219876\n",
       "96             temp_c_max_roll12h_mean   6.923478 -2.301484    -15.934276\n",
       "63   line_speed_u_min_mean_roll6h_mean   9.477528 -1.470588    -13.937539\n",
       "64       pressure_kpa_mean_roll6h_mean  11.533203 -0.893381    -10.303546\n",
       "115     vibration_mm_s_max_roll12h_std   3.053331 -3.249974     -9.923247\n",
       "98       humidity_rh_mean_roll12h_mean  12.102579 -0.726855     -8.796819\n",
       "66             temp_c_mean_roll6h_mean   7.151967 -1.162493     -8.314111\n",
       "4                           temp_c_max   6.293139 -1.068893     -6.726691\n",
       "56         humidity_rh_max_roll6h_mean   7.627101 -0.872409     -6.653949\n",
       "28       pressure_kpa_mean_roll3h_mean   9.617640 -0.556360     -5.350867"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done. Next: Cell 11 can build an asset-level risk rollup (daily/weekly) for the dashboard.\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 10 — Interpretability: global coefficients + per-row feature contributions (traceable)\n",
    "#============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Paths (same OUT_DIR)\n",
    "# -----------------------------\n",
    "X_test_path   = OUT_DIR / \"X_test.npz\"\n",
    "model_path    = OUT_DIR / \"baseline_logreg_saga.joblib\"\n",
    "feat_path     = OUT_DIR / \"feature_names.csv\"\n",
    "pred_path     = OUT_DIR / \"predictions_test_asset_hour.parquet\"\n",
    "\n",
    "assert X_test_path.exists(), f\"Missing {X_test_path}\"\n",
    "assert model_path.exists(),  f\"Missing {model_path}\"\n",
    "assert feat_path.exists(),   f\"Missing {feat_path}\"\n",
    "assert pred_path.exists(),   f\"Missing {pred_path}\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load artifacts\n",
    "# -----------------------------\n",
    "X_test_tx = sp.load_npz(X_test_path).tocsr()\n",
    "clf = joblib.load(model_path)\n",
    "\n",
    "feature_names = pd.read_csv(feat_path)[\"feature_name\"].astype(str).tolist()\n",
    "pred_df = pd.read_parquet(pred_path)\n",
    "\n",
    "n_X = X_test_tx.shape[1]\n",
    "n_feat = len(feature_names)\n",
    "n_model = int(getattr(clf, \"n_features_in_\", n_X))\n",
    "\n",
    "if not (n_X == n_feat == n_model):\n",
    "    raise ValueError(\n",
    "        \"Artifact mismatch detected in Cell 10.\\n\"\n",
    "        f\"  X_test features: {n_X}\\n\"\n",
    "        f\"  feature_names  : {n_feat}\\n\"\n",
    "        f\"  model expects  : {n_model}\\n\\n\"\n",
    "        \"Fix: re-run Cells 6 → 7 → 9 so matrices/model/predictions are aligned.\"\n",
    "    )\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(f\"  X_test_tx: {X_test_tx.shape} | sparse: {sp.issparse(X_test_tx)}\")\n",
    "print(f\"  # feature_names: {len(feature_names)}\")\n",
    "print(f\"  predictions table: {pred_df.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Global interpretability: coefficient table\n",
    "# -----------------------------\n",
    "coef = clf.coef_.ravel()  # shape (n_features,)\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coef\": coef.astype(float),\n",
    "    \"abs_coef\": np.abs(coef.astype(float))\n",
    "}).sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "coef_out = OUT_DIR / \"logreg_coefficients.csv\"\n",
    "coef_df.to_csv(coef_out, index=False)\n",
    "\n",
    "print(\"\\nSaved global coefficient table:\")\n",
    "print(\" \", coef_out)\n",
    "\n",
    "print(\"\\nTop 25 coefficients by absolute magnitude:\")\n",
    "display(coef_df.head(25))\n",
    "\n",
    "print(\"\\nMost positive (pushes risk UP):\")\n",
    "display(coef_df.sort_values(\"coef\", ascending=False).head(15))\n",
    "\n",
    "print(\"\\nMost negative (pushes risk DOWN):\")\n",
    "display(coef_df.sort_values(\"coef\", ascending=True).head(15))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Per-row contributions (linear model on transformed features)\n",
    "#    contribution_j = x_ij * coef_j\n",
    "# -----------------------------\n",
    "def explain_row_sparse(X_csr, coef_vec, feat_names, row_idx, top_k=12):\n",
    "    \"\"\"\n",
    "    Returns a dataframe of top positive/negative feature contributions for one sparse row.\n",
    "    \"\"\"\n",
    "    row = X_csr.getrow(row_idx)\n",
    "    # contributions for nonzero features only (fast)\n",
    "    idx = row.indices\n",
    "    data = row.data\n",
    "    contrib = data * coef_vec[idx]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": [feat_names[i] for i in idx],\n",
    "        \"value\": data.astype(float),\n",
    "        \"coef\": coef_vec[idx].astype(float),\n",
    "        \"contribution\": contrib.astype(float),\n",
    "    })\n",
    "\n",
    "    df_pos = df.sort_values(\"contribution\", ascending=False).head(top_k)\n",
    "    df_neg = df.sort_values(\"contribution\", ascending=True).head(top_k)\n",
    "\n",
    "    return df_pos, df_neg\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Tie predictions back to matrix rows\n",
    "#     IMPORTANT: predictions_test_asset_hour.parquet is aligned with X_test ordering\n",
    "#     because Cell 9 used ids_test + y_test + proba in-order.\n",
    "# -----------------------------\n",
    "top_n = 15\n",
    "pred_top = pred_df.sort_values(\"p_risk\", ascending=False).head(top_n).copy()\n",
    "\n",
    "# row indices in X_test correspond to pred_df row order\n",
    "# We'll recover those by taking the integer position within pred_df.\n",
    "# Build a mapping: index position -> row in X_test\n",
    "# (ensure pred_df has default RangeIndex-like behavior)\n",
    "pred_df_reset = pred_df.reset_index(drop=True)\n",
    "top_positions = pred_top.index.to_list()\n",
    "# If pred_top inherited a non-default index, re-derive via merge on risk_rank\n",
    "if not all(isinstance(i, (int, np.integer)) for i in top_positions):\n",
    "    pred_top = pred_top.merge(\n",
    "        pred_df_reset.reset_index().rename(columns={\"index\": \"row_pos\"}),\n",
    "        on=[\"asset_id\", \"site_id\", \"ts_hour_utc\", \"p_risk\", \"y_true\", \"y_pred\", \"risk_rank\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    top_positions = pred_top[\"row_pos\"].tolist()\n",
    "\n",
    "print(f\"\\nExplaining top {top_n} highest-risk test rows...\")\n",
    "\n",
    "explanations = []\n",
    "for rank_i, row_pos in enumerate(top_positions, start=1):\n",
    "    row_pos = int(row_pos)\n",
    "    df_pos, df_neg = explain_row_sparse(X_test_tx, coef, feature_names, row_pos, top_k=10)\n",
    "\n",
    "    meta = pred_df_reset.iloc[row_pos].to_dict()\n",
    "    explanations.append({\n",
    "        \"rank\": rank_i,\n",
    "        \"row_pos\": row_pos,\n",
    "        \"asset_id\": meta.get(\"asset_id\"),\n",
    "        \"site_id\": meta.get(\"site_id\"),\n",
    "        \"line_id\": meta.get(\"line_id\"),\n",
    "        \"ts_hour_utc\": str(meta.get(\"ts_hour_utc\")),\n",
    "        \"p_risk\": float(meta.get(\"p_risk\")),\n",
    "        \"y_true\": int(meta.get(\"y_true\")),\n",
    "        \"y_pred\": int(meta.get(\"y_pred\")),\n",
    "        \"top_positive\": df_pos,\n",
    "        \"top_negative\": df_neg,\n",
    "    })\n",
    "\n",
    "# Display a compact summary + show contributions for the first few\n",
    "summary_rows = []\n",
    "for e in explanations:\n",
    "    summary_rows.append({\n",
    "        \"rank\": e[\"rank\"],\n",
    "        \"asset_id\": e[\"asset_id\"],\n",
    "        \"site_id\": e[\"site_id\"],\n",
    "        \"line_id\": e[\"line_id\"],\n",
    "        \"ts_hour_utc\": e[\"ts_hour_utc\"],\n",
    "        \"p_risk\": e[\"p_risk\"],\n",
    "        \"y_true\": e[\"y_true\"],\n",
    "        \"y_pred\": e[\"y_pred\"],\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_out = OUT_DIR / \"top_risk_rows_summary.csv\"\n",
    "summary_df.to_csv(summary_out, index=False)\n",
    "\n",
    "print(\"\\nSaved top-risk summary:\")\n",
    "print(\" \", summary_out)\n",
    "display(summary_df)\n",
    "\n",
    "# Show detailed explanations for first 5\n",
    "for e in explanations[:5]:\n",
    "    print(\"\\n\" + \"-\"*90)\n",
    "    print(f\"Rank {e['rank']} | asset={e['asset_id']} site={e['site_id']} line={e['line_id']} \"\n",
    "          f\"| ts={e['ts_hour_utc']} | p_risk={e['p_risk']:.6f} | y_true={e['y_true']} y_pred={e['y_pred']}\")\n",
    "    print(\"\\nTop POSITIVE contributions (push risk up):\")\n",
    "    display(e[\"top_positive\"])\n",
    "    print(\"\\nTop NEGATIVE contributions (push risk down):\")\n",
    "    display(e[\"top_negative\"])\n",
    "\n",
    "print(\"\\nDone. Next: Cell 11 can build an asset-level risk rollup (daily/weekly) for the dashboard.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57276128-790a-4b6d-8851-dddaf867b126",
   "metadata": {},
   "source": [
    "### What Cell 10 Just Did\n",
    "This cell added **interpretability** on top of the baseline model in two complementary ways:\n",
    "\n",
    "1) **Global interpretability (model-wide drivers)**\n",
    "- Pulled the trained Logistic Regression coefficients (`coef_`) and aligned them to the transformed feature names (post one-hot / scaling).\n",
    "- Ranked features by **absolute coefficient magnitude** to show the strongest overall drivers.\n",
    "- Split views into:\n",
    "  - features pushing toward **target=1** (positive coefficients)\n",
    "  - features pushing toward **target=0** (negative coefficients)\n",
    "- Saved a **coefficients table** so the “top drivers” can be referenced later in the write-up and exported artifacts.\n",
    "\n",
    "2) **Local interpretability (row-level “why” for a specific prediction)**\n",
    "- For selected rows (often high-risk hours), computed **per-feature contributions** in transformed space:\n",
    "  - `contribution_i = x_i * coef_i`\n",
    "- Produced a per-row list of the **top contributing features** (positive and/or absolute contribution) so each prediction is explainable as:\n",
    "  - **what hour / which asset / what score / why the model thinks so**\n",
    "- Ensured the interpretation stays **traceable** by joining back to ID columns (asset_id + ts_hour_utc) and saving outputs that can be audited.\n",
    "\n",
    "Net result: you now have both the **big-picture drivers** and the **case-by-case explanations** needed for operational reporting and “top assets/day: when + why” style summaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f833fee4-7e45-42a3-959d-9ce8a0d5f8f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded predictions: (8093, 11)\n",
      "p_risk range: 5.6451629149023574e-08 -> 1.0\n",
      "Test positive rate: 0.016063264549610774\n",
      "\n",
      "Daily rollups:\n",
      "  asset_daily: (413, 10)\n",
      "  line_daily : (77, 9)\n",
      "  site_daily : (16, 8)\n",
      "\n",
      "Top offenders (by mean risk):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>n_hours</th>\n",
       "      <th>risk_mean</th>\n",
       "      <th>risk_p95</th>\n",
       "      <th>risk_max</th>\n",
       "      <th>incident_rate</th>\n",
       "      <th>incidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>A0069</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.797687</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>A0037</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.755502</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L4</td>\n",
       "      <td>A0105</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.744462</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>A0112</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.733131</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L4</td>\n",
       "      <td>A0091</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.717993</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>A0073</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.674554</td>\n",
       "      <td>0.997285</td>\n",
       "      <td>0.999811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>A0099</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.661867</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>A0066</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.656012</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>A0007</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.653826</td>\n",
       "      <td>0.998171</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>A0068</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.637114</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>A0113</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.636639</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>A0053</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.629610</td>\n",
       "      <td>0.997856</td>\n",
       "      <td>0.999161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L4</td>\n",
       "      <td>A0046</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.628177</td>\n",
       "      <td>0.997980</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L4</td>\n",
       "      <td>A0072</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.607116</td>\n",
       "      <td>0.999790</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L1</td>\n",
       "      <td>A0093</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.593813</td>\n",
       "      <td>0.999021</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    site_id line_id asset_id  n_hours  risk_mean  risk_p95  risk_max  \\\n",
       "49       S2   S2-L3    A0069     67.0   0.797687  0.999946  1.000000   \n",
       "18       S1   S1-L3    A0037     67.0   0.755502  0.999921  0.999994   \n",
       "56       S2   S2-L4    A0105     67.0   0.744462  0.999707  0.999972   \n",
       "7        S1   S1-L1    A0112     67.0   0.733131  0.999969  0.999999   \n",
       "28       S1   S1-L4    A0091     67.0   0.717993  0.999963  0.999997   \n",
       "21       S1   S1-L3    A0073     67.0   0.674554  0.997285  0.999811   \n",
       "86       S3   S3-L5    A0099     67.0   0.661867  0.999990  1.000000   \n",
       "34       S1   S1-L5    A0066     67.0   0.656012  0.999989  0.999998   \n",
       "15       S1   S1-L3    A0007     67.0   0.653826  0.998171  0.999942   \n",
       "48       S2   S2-L3    A0068     67.0   0.637114  0.999993  1.000000   \n",
       "36       S1   S1-L5    A0113     67.0   0.636639  0.999659  0.999988   \n",
       "19       S1   S1-L3    A0053     67.0   0.629610  0.997856  0.999161   \n",
       "111      S4   S4-L4    A0046     67.0   0.628177  0.997980  0.999993   \n",
       "55       S2   S2-L4    A0072     67.0   0.607116  0.999790  0.999918   \n",
       "92       S4   S4-L1    A0093     67.0   0.593813  0.999021  0.999968   \n",
       "\n",
       "     incident_rate  incidents  \n",
       "49        0.000000        0.0  \n",
       "18        0.089552        6.0  \n",
       "56        0.089552        6.0  \n",
       "7         0.000000        0.0  \n",
       "28        0.000000        0.0  \n",
       "21        0.000000        0.0  \n",
       "86        0.000000        0.0  \n",
       "34        0.000000        0.0  \n",
       "15        0.000000        0.0  \n",
       "48        0.089552        6.0  \n",
       "36        0.000000        0.0  \n",
       "19        0.000000        0.0  \n",
       "111       0.000000        0.0  \n",
       "55        0.000000        0.0  \n",
       "92        0.000000        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>n_hours</th>\n",
       "      <th>risk_mean</th>\n",
       "      <th>risk_p95</th>\n",
       "      <th>risk_max</th>\n",
       "      <th>incident_rate</th>\n",
       "      <th>incidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L4</td>\n",
       "      <td>471.0</td>\n",
       "      <td>0.430262</td>\n",
       "      <td>0.998671</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.401083</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017804</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.380485</td>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L2</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.375833</td>\n",
       "      <td>0.995616</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>471.0</td>\n",
       "      <td>0.361757</td>\n",
       "      <td>0.998636</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.348960</td>\n",
       "      <td>0.997576</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.026706</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L4</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.307140</td>\n",
       "      <td>0.987601</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L4</td>\n",
       "      <td>405.0</td>\n",
       "      <td>0.285098</td>\n",
       "      <td>0.993935</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.279758</td>\n",
       "      <td>0.989227</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L1</td>\n",
       "      <td>405.0</td>\n",
       "      <td>0.261819</td>\n",
       "      <td>0.990886</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id line_id  n_hours  risk_mean  risk_p95  risk_max  incident_rate  \\\n",
       "8       S2   S2-L4    471.0   0.430262  0.998671  0.999972       0.012739   \n",
       "7       S2   S2-L3    337.0   0.401083  0.999911  1.000000       0.017804   \n",
       "10      S3   S3-L1    201.0   0.380485  0.998778  0.999996       0.000000   \n",
       "11      S3   S3-L2    201.0   0.375833  0.995616  0.999589       0.029851   \n",
       "4       S1   S1-L5    471.0   0.361757  0.998636  0.999998       0.000000   \n",
       "2       S1   S1-L3    674.0   0.348960  0.997576  0.999994       0.026706   \n",
       "13      S3   S3-L4    202.0   0.307140  0.987601  0.999915       0.000000   \n",
       "18      S4   S4-L4    405.0   0.285098  0.993935  0.999993       0.014815   \n",
       "5       S2   S2-L1    135.0   0.279758  0.989227  0.999632       0.007407   \n",
       "15      S4   S4-L1    405.0   0.261819  0.990886  0.999968       0.000000   \n",
       "\n",
       "    incidents  \n",
       "8         6.0  \n",
       "7         6.0  \n",
       "10        0.0  \n",
       "11        6.0  \n",
       "4         0.0  \n",
       "2        18.0  \n",
       "13        0.0  \n",
       "18        6.0  \n",
       "5         1.0  \n",
       "15        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>n_hours</th>\n",
       "      <th>risk_mean</th>\n",
       "      <th>risk_p95</th>\n",
       "      <th>risk_max</th>\n",
       "      <th>incident_rate</th>\n",
       "      <th>incidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>0.322194</td>\n",
       "      <td>0.996395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1</td>\n",
       "      <td>2563.0</td>\n",
       "      <td>0.263269</td>\n",
       "      <td>0.995608</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S3</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>0.237356</td>\n",
       "      <td>0.986676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S4</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>0.229382</td>\n",
       "      <td>0.987760</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.024344</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site_id  n_hours  risk_mean  risk_p95  risk_max  incident_rate  incidents\n",
       "1      S2   1748.0   0.322194  0.996395  1.000000       0.007437       13.0\n",
       "0      S1   2563.0   0.263269  0.995608  0.999999       0.018728       48.0\n",
       "2      S3   1687.0   0.237356  0.986676  1.000000       0.010670       18.0\n",
       "3      S4   2095.0   0.229382  0.987760  0.999998       0.024344       51.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved rollup artifacts:\n",
      "  asset_daily:\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/asset_daily.parquet\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/asset_daily.csv\n",
      "  line_daily:\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/line_daily.parquet\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/line_daily.csv\n",
      "  site_daily:\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/site_daily.parquet\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/site_daily.csv\n",
      "  asset_summary:\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/asset_summary.parquet\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/asset_summary.csv\n",
      "  line_summary:\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/line_summary.parquet\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/line_summary.csv\n",
      "  site_summary:\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/site_summary.parquet\n",
      "    /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/site_summary.csv\n",
      "\n",
      "Sanity check — worst assets by risk_p95 (test horizon):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>n_hours</th>\n",
       "      <th>risk_mean</th>\n",
       "      <th>risk_p95</th>\n",
       "      <th>risk_max</th>\n",
       "      <th>incident_rate</th>\n",
       "      <th>incidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>A0068</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.637114</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>A0099</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.661867</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>A0066</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.656012</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>A0112</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.733131</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L4</td>\n",
       "      <td>A0091</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.717993</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>A0069</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.797687</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>A0037</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.755502</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>A0056</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.589032</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>A0010</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.481047</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L4</td>\n",
       "      <td>A0072</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.607116</td>\n",
       "      <td>0.999790</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>A0064</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.368647</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L4</td>\n",
       "      <td>A0105</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.744462</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>A0113</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.636639</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L4</td>\n",
       "      <td>A0039</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.499896</td>\n",
       "      <td>0.999505</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L4</td>\n",
       "      <td>A0102</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.555336</td>\n",
       "      <td>0.999367</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    site_id line_id asset_id  n_hours  risk_mean  risk_p95  risk_max  \\\n",
       "48       S2   S2-L3    A0068     67.0   0.637114  0.999993  1.000000   \n",
       "86       S3   S3-L5    A0099     67.0   0.661867  0.999990  1.000000   \n",
       "34       S1   S1-L5    A0066     67.0   0.656012  0.999989  0.999998   \n",
       "7        S1   S1-L1    A0112     67.0   0.733131  0.999969  0.999999   \n",
       "28       S1   S1-L4    A0091     67.0   0.717993  0.999963  0.999997   \n",
       "49       S2   S2-L3    A0069     67.0   0.797687  0.999946  1.000000   \n",
       "18       S1   S1-L3    A0037     67.0   0.755502  0.999921  0.999994   \n",
       "65       S3   S3-L1    A0056     67.0   0.589032  0.999893  0.999996   \n",
       "45       S2   S2-L3    A0010     67.0   0.481047  0.999883  0.999960   \n",
       "55       S2   S2-L4    A0072     67.0   0.607116  0.999790  0.999918   \n",
       "101      S4   S4-L2    A0064     67.0   0.368647  0.999720  0.999960   \n",
       "56       S2   S2-L4    A0105     67.0   0.744462  0.999707  0.999972   \n",
       "36       S1   S1-L5    A0113     67.0   0.636639  0.999659  0.999988   \n",
       "110      S4   S4-L4    A0039     67.0   0.499896  0.999505  0.999970   \n",
       "114      S4   S4-L4    A0102     67.0   0.555336  0.999367  0.999853   \n",
       "\n",
       "     incident_rate  incidents  \n",
       "48        0.089552        6.0  \n",
       "86        0.000000        0.0  \n",
       "34        0.000000        0.0  \n",
       "7         0.000000        0.0  \n",
       "28        0.000000        0.0  \n",
       "49        0.000000        0.0  \n",
       "18        0.089552        6.0  \n",
       "65        0.000000        0.0  \n",
       "45        0.000000        0.0  \n",
       "55        0.000000        0.0  \n",
       "101       0.000000        0.0  \n",
       "56        0.089552        6.0  \n",
       "36        0.000000        0.0  \n",
       "110       0.000000        0.0  \n",
       "114       0.000000        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done. Next: Cell 12 can build a dashboard-ready 'risk index' score (0–100) per asset/day.\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 11 — Dashboard rollups: risk by day/site/line/asset + top offenders\n",
    "#============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pred_path = OUT_DIR / \"predictions_test_asset_hour.parquet\"\n",
    "assert pred_path.exists(), f\"Missing {pred_path}\"\n",
    "\n",
    "pred = pd.read_parquet(pred_path).copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Parse/clean required columns\n",
    "# -----------------------------\n",
    "required = [\"asset_id\", \"site_id\", \"line_id\", \"ts_hour_utc\", \"p_risk\", \"y_true\"]\n",
    "missing = [c for c in required if c not in pred.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"predictions file missing columns: {missing}\")\n",
    "\n",
    "pred[\"ts_hour_utc\"] = pd.to_datetime(pred[\"ts_hour_utc\"], utc=True, errors=\"coerce\")\n",
    "if pred[\"ts_hour_utc\"].isna().any():\n",
    "    raise ValueError(\"ts_hour_utc has NaT after parsing; check Cell 9 output.\")\n",
    "\n",
    "pred[\"p_risk\"] = pd.to_numeric(pred[\"p_risk\"], errors=\"coerce\")\n",
    "pred[\"y_true\"] = pred[\"y_true\"].astype(\"int8\")\n",
    "\n",
    "pred[\"date_utc\"] = pred[\"ts_hour_utc\"].dt.date.astype(\"string\")\n",
    "pred[\"hour_utc\"] = pred[\"ts_hour_utc\"].dt.hour.astype(\"int8\")\n",
    "\n",
    "print(\"Loaded predictions:\", pred.shape)\n",
    "print(\"p_risk range:\", float(pred[\"p_risk\"].min()), \"->\", float(pred[\"p_risk\"].max()))\n",
    "print(\"Test positive rate:\", float(pred[\"y_true\"].mean()))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Helper aggregations\n",
    "# -----------------------------\n",
    "def agg_block(df):\n",
    "    return pd.Series({\n",
    "        \"n_hours\": len(df),\n",
    "        \"risk_mean\": float(df[\"p_risk\"].mean()),\n",
    "        \"risk_p95\": float(df[\"p_risk\"].quantile(0.95)),\n",
    "        \"risk_max\": float(df[\"p_risk\"].max()),\n",
    "        \"incident_rate\": float(df[\"y_true\"].mean()),\n",
    "        \"incidents\": int(df[\"y_true\"].sum()),\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Daily rollups (site/line/asset)\n",
    "# -----------------------------\n",
    "asset_daily = (\n",
    "    pred.groupby([\"date_utc\", \"site_id\", \"line_id\", \"asset_id\"], as_index=False)\n",
    "        .apply(agg_block)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "line_daily = (\n",
    "    pred.groupby([\"date_utc\", \"site_id\", \"line_id\"], as_index=False)\n",
    "        .apply(agg_block)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "site_daily = (\n",
    "    pred.groupby([\"date_utc\", \"site_id\"], as_index=False)\n",
    "        .apply(agg_block)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nDaily rollups:\")\n",
    "print(\"  asset_daily:\", asset_daily.shape)\n",
    "print(\"  line_daily :\", line_daily.shape)\n",
    "print(\"  site_daily :\", site_daily.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) “Top offenders” summary over entire test horizon\n",
    "# -----------------------------\n",
    "asset_summary = (\n",
    "    pred.groupby([\"site_id\", \"line_id\", \"asset_id\"], as_index=False)\n",
    "        .apply(agg_block)\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values([\"risk_mean\", \"risk_p95\", \"incidents\"], ascending=[False, False, False])\n",
    ")\n",
    "\n",
    "line_summary = (\n",
    "    pred.groupby([\"site_id\", \"line_id\"], as_index=False)\n",
    "        .apply(agg_block)\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values([\"risk_mean\", \"risk_p95\", \"incidents\"], ascending=[False, False, False])\n",
    ")\n",
    "\n",
    "site_summary = (\n",
    "    pred.groupby([\"site_id\"], as_index=False)\n",
    "        .apply(agg_block)\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values([\"risk_mean\", \"risk_p95\", \"incidents\"], ascending=[False, False, False])\n",
    ")\n",
    "\n",
    "print(\"\\nTop offenders (by mean risk):\")\n",
    "display(asset_summary.head(15))\n",
    "display(line_summary.head(10))\n",
    "display(site_summary.head(10))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Save artifacts (CSV + Parquet)\n",
    "# -----------------------------\n",
    "out_files = {}\n",
    "\n",
    "for name, df in [\n",
    "    (\"asset_daily\", asset_daily),\n",
    "    (\"line_daily\", line_daily),\n",
    "    (\"site_daily\", site_daily),\n",
    "    (\"asset_summary\", asset_summary),\n",
    "    (\"line_summary\", line_summary),\n",
    "    (\"site_summary\", site_summary),\n",
    "]:\n",
    "    pqt = OUT_DIR / f\"{name}.parquet\"\n",
    "    csv = OUT_DIR / f\"{name}.csv\"\n",
    "    df.to_parquet(pqt, index=False)\n",
    "    df.to_csv(csv, index=False)\n",
    "    out_files[name] = (pqt, csv)\n",
    "\n",
    "print(\"\\nSaved rollup artifacts:\")\n",
    "for name, (pqt, csv) in out_files.items():\n",
    "    print(f\"  {name}:\")\n",
    "    print(f\"    {pqt}\")\n",
    "    print(f\"    {csv}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Quick sanity visuals (table only; charts later in dashboard notebook)\n",
    "# -----------------------------\n",
    "print(\"\\nSanity check — worst assets by risk_p95 (test horizon):\")\n",
    "display(asset_summary.sort_values(\"risk_p95\", ascending=False).head(15))\n",
    "\n",
    "print(\"\\nDone. Next: Cell 12 can build a dashboard-ready 'risk index' score (0–100) per asset/day.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171fbbe3-fe05-4de7-b34d-006fa0552d1f",
   "metadata": {},
   "source": [
    "### What Cell 11 Just Did\n",
    "This cell built the **operational rollups** you’d want for a dashboard—turning row-level (asset-hour) scores into **actionable summaries** by time and manufacturing context.\n",
    "\n",
    "1) **Converted scores into dashboard-ready aggregates**\n",
    "- Started from the scored/prediction table (asset-hour level) and grouped results into summaries like:\n",
    "  - **by day** (how risk changes over time)\n",
    "  - **by site** (which plants are driving risk)\n",
    "  - **by line** (which lines are consistently risky)\n",
    "  - **by asset** (repeat offenders across hours/days)\n",
    "\n",
    "2) **Computed “top offenders” lists**\n",
    "- Identified the highest-risk entities using sensible ranking logic (typically by one of):\n",
    "  - **max score** (worst single hour)\n",
    "  - **mean score** (consistently elevated)\n",
    "  - **count above threshold** (how often it trips alerts)\n",
    "- Produced “Top N” tables for quick triage (e.g., top risky assets, top risky lines).\n",
    "\n",
    "3) **Made outputs reproducible and exportable**\n",
    "- Saved rollup tables (CSV/Parquet) so they can be:\n",
    "  - embedded into a report,\n",
    "  - plotted in later cells,\n",
    "  - or wired into a lightweight dashboard without re-running heavy steps.\n",
    "\n",
    "Net result: you now have a clean **risk-by-day/site/line/asset** view plus **top offenders**, which is the backbone for a “where to look first” operational summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ce127d0-5a0c-45ba-9696-6c560c476709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded artifacts:\n",
      "  preprocess: preprocess.joblib\n",
      "  model     : baseline_logreg_saga.joblib\n",
      "\n",
      "Top 20 features by |coef|:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-3.627807</td>\n",
       "      <td>3.627807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>line_id_S2-L3</td>\n",
       "      <td>3.277419</td>\n",
       "      <td>3.277419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vibration_mm_s_max_roll12h_std</td>\n",
       "      <td>-3.249974</td>\n",
       "      <td>3.249974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>3.030807</td>\n",
       "      <td>3.030807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>2.860782</td>\n",
       "      <td>2.860782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>line_id_S3-L2</td>\n",
       "      <td>-2.741310</td>\n",
       "      <td>2.741310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vibration_mm_s_mean_roll12h_std</td>\n",
       "      <td>2.572287</td>\n",
       "      <td>2.572287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>line_id_S3-L5</td>\n",
       "      <td>2.352172</td>\n",
       "      <td>2.352172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>temp_c_max_roll12h_mean</td>\n",
       "      <td>-2.301484</td>\n",
       "      <td>2.301484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-2.227523</td>\n",
       "      <td>2.227523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>line_id_S4-L4</td>\n",
       "      <td>2.219993</td>\n",
       "      <td>2.219993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pressure_kpa_mean_roll12h_mean</td>\n",
       "      <td>2.144437</td>\n",
       "      <td>2.144437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>asset_type_capper</td>\n",
       "      <td>2.086919</td>\n",
       "      <td>2.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-2.055362</td>\n",
       "      <td>2.055362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pressure_kpa_max_roll12h_mean</td>\n",
       "      <td>-1.954750</td>\n",
       "      <td>1.954750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>line_speed_u_min_max_roll6h_mean</td>\n",
       "      <td>1.720678</td>\n",
       "      <td>1.720678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>asset_type_case_packer</td>\n",
       "      <td>1.597252</td>\n",
       "      <td>1.597252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>line_id_S2-L4</td>\n",
       "      <td>1.578042</td>\n",
       "      <td>1.578042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>line_id_S4-L1</td>\n",
       "      <td>1.577696</td>\n",
       "      <td>1.577696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>reject_rate_pct_mean_roll12h_std</td>\n",
       "      <td>-1.561786</td>\n",
       "      <td>1.561786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             feature      coef  abs_coef\n",
       "0                      line_id_S2-L5 -3.627807  3.627807\n",
       "1                      line_id_S2-L3  3.277419  3.277419\n",
       "2     vibration_mm_s_max_roll12h_std -3.249974  3.249974\n",
       "3                asset_type_cartoner  3.030807  3.030807\n",
       "4                      line_id_S4-L5  2.860782  2.860782\n",
       "5                      line_id_S3-L2 -2.741310  2.741310\n",
       "6    vibration_mm_s_mean_roll12h_std  2.572287  2.572287\n",
       "7                      line_id_S3-L5  2.352172  2.352172\n",
       "8            temp_c_max_roll12h_mean -2.301484  2.301484\n",
       "9                      line_id_S1-L2 -2.227523  2.227523\n",
       "10                     line_id_S4-L4  2.219993  2.219993\n",
       "11    pressure_kpa_mean_roll12h_mean  2.144437  2.144437\n",
       "12                 asset_type_capper  2.086919  2.086919\n",
       "13            asset_type_print_apply -2.055362  2.055362\n",
       "14     pressure_kpa_max_roll12h_mean -1.954750  1.954750\n",
       "15  line_speed_u_min_max_roll6h_mean  1.720678  1.720678\n",
       "16            asset_type_case_packer  1.597252  1.597252\n",
       "17                     line_id_S2-L4  1.578042  1.578042\n",
       "18                     line_id_S4-L1  1.577696  1.577696\n",
       "19  reject_rate_pct_mean_roll12h_std -1.561786  1.561786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 pushing toward target=1 (largest +coef):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>line_id_S2-L3</td>\n",
       "      <td>3.277419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>3.030807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>2.860782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vibration_mm_s_mean_roll12h_std</td>\n",
       "      <td>2.572287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>line_id_S3-L5</td>\n",
       "      <td>2.352172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>line_id_S4-L4</td>\n",
       "      <td>2.219993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pressure_kpa_mean_roll12h_mean</td>\n",
       "      <td>2.144437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>asset_type_capper</td>\n",
       "      <td>2.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>line_speed_u_min_max_roll6h_mean</td>\n",
       "      <td>1.720678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>asset_type_case_packer</td>\n",
       "      <td>1.597252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>line_id_S2-L4</td>\n",
       "      <td>1.578042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>line_id_S4-L1</td>\n",
       "      <td>1.577696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>line_speed_u_min_mean_roll12h_std</td>\n",
       "      <td>1.366542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>temp_c_mean_roll12h_mean</td>\n",
       "      <td>1.301523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>temp_c_max_roll6h_mean</td>\n",
       "      <td>1.230662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature      coef\n",
       "1                       line_id_S2-L3  3.277419\n",
       "3                 asset_type_cartoner  3.030807\n",
       "4                       line_id_S4-L5  2.860782\n",
       "6     vibration_mm_s_mean_roll12h_std  2.572287\n",
       "7                       line_id_S3-L5  2.352172\n",
       "10                      line_id_S4-L4  2.219993\n",
       "11     pressure_kpa_mean_roll12h_mean  2.144437\n",
       "12                  asset_type_capper  2.086919\n",
       "15   line_speed_u_min_max_roll6h_mean  1.720678\n",
       "16             asset_type_case_packer  1.597252\n",
       "17                      line_id_S2-L4  1.578042\n",
       "18                      line_id_S4-L1  1.577696\n",
       "23  line_speed_u_min_mean_roll12h_std  1.366542\n",
       "24           temp_c_mean_roll12h_mean  1.301523\n",
       "26             temp_c_max_roll6h_mean  1.230662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 pushing toward target=0 (most -coef):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-3.627807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vibration_mm_s_max_roll12h_std</td>\n",
       "      <td>-3.249974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>line_id_S3-L2</td>\n",
       "      <td>-2.741310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>temp_c_max_roll12h_mean</td>\n",
       "      <td>-2.301484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-2.227523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-2.055362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pressure_kpa_max_roll12h_mean</td>\n",
       "      <td>-1.954750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>reject_rate_pct_mean_roll12h_std</td>\n",
       "      <td>-1.561786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>temp_c_max_roll12h_std</td>\n",
       "      <td>-1.509104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>line_speed_u_min_mean_roll6h_mean</td>\n",
       "      <td>-1.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>line_speed_u_min_max_roll12h_std</td>\n",
       "      <td>-1.409706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>asset_type_labeler</td>\n",
       "      <td>-1.268630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>line_id_S3-L1</td>\n",
       "      <td>-1.173880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>temp_c_mean_roll6h_mean</td>\n",
       "      <td>-1.162493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>temp_c_max</td>\n",
       "      <td>-1.068893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature      coef\n",
       "0                       line_id_S2-L5 -3.627807\n",
       "2      vibration_mm_s_max_roll12h_std -3.249974\n",
       "5                       line_id_S3-L2 -2.741310\n",
       "8             temp_c_max_roll12h_mean -2.301484\n",
       "9                       line_id_S1-L2 -2.227523\n",
       "13             asset_type_print_apply -2.055362\n",
       "14      pressure_kpa_max_roll12h_mean -1.954750\n",
       "19   reject_rate_pct_mean_roll12h_std -1.561786\n",
       "20             temp_c_max_roll12h_std -1.509104\n",
       "21  line_speed_u_min_mean_roll6h_mean -1.470588\n",
       "22   line_speed_u_min_max_roll12h_std -1.409706\n",
       "25                 asset_type_labeler -1.268630\n",
       "30                      line_id_S3-L1 -1.173880\n",
       "31            temp_c_mean_roll6h_mean -1.162493\n",
       "34                         temp_c_max -1.068893"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/baseline_logreg_coefficients.csv\n",
      "\n",
      "Note: leaky metrics JSON not found: baseline_logreg_metrics.json\n",
      "Note: no-leak metrics JSON not found: baseline_logreg_noleak_metrics.json\n",
      "\n",
      "Baseline comparison (leaky vs no-leak):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>leaky_baseline</th>\n",
       "      <th>no_leak_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roc_auc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pr_auc</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric leaky_baseline no_leak_baseline\n",
       "0   accuracy           None             None\n",
       "1  precision           None             None\n",
       "2     recall           None             None\n",
       "3         f1           None             None\n",
       "4    roc_auc           None             None\n",
       "5     pr_auc           None             None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/baseline_comparison_leak_vs_noleak.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 12 — Interpret baseline: coefficients + comparison (leaky vs no-leak) from saved artifacts\n",
    "#============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Locate artifacts in OUT_DIR (be flexible with filenames)\n",
    "# -----------------------------\n",
    "# Preferred no-leak artifacts\n",
    "pre_nl_path_candidates = [\n",
    "    OUT_DIR / \"preprocess_noleak.joblib\",\n",
    "    OUT_DIR / \"preprocess.joblib\",  # fallback if you only saved one preprocessor\n",
    "]\n",
    "clf_nl_path_candidates = [\n",
    "    OUT_DIR / \"baseline_logreg_noleak.joblib\",\n",
    "    OUT_DIR / \"baseline_logreg_saga.joblib\",  # fallback (current baseline)\n",
    "    OUT_DIR / \"baseline_logreg.joblib\",\n",
    "]\n",
    "\n",
    "# Feature name candidates\n",
    "feat_nl_candidates = [\n",
    "    OUT_DIR / \"feature_names_noleak.csv\",\n",
    "    OUT_DIR / \"feature_names.csv\",\n",
    "]\n",
    "\n",
    "# Metrics JSON candidates\n",
    "leaky_metrics_path  = OUT_DIR / \"baseline_logreg_metrics.json\"\n",
    "noleak_metrics_path = OUT_DIR / \"baseline_logreg_noleak_metrics.json\"\n",
    "\n",
    "def first_existing(paths):\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "pre_nl_path = first_existing(pre_nl_path_candidates)\n",
    "clf_nl_path = first_existing(clf_nl_path_candidates)\n",
    "feat_path   = first_existing(feat_nl_candidates)\n",
    "\n",
    "if pre_nl_path is None:\n",
    "    raise FileNotFoundError(f\"No preprocessor found in OUT_DIR. Tried: {[str(p) for p in pre_nl_path_candidates]}\")\n",
    "if clf_nl_path is None:\n",
    "    raise FileNotFoundError(f\"No baseline model found in OUT_DIR. Tried: {[str(p) for p in clf_nl_path_candidates]}\")\n",
    "\n",
    "preprocess_noleak = joblib.load(pre_nl_path)\n",
    "clf_noleak = joblib.load(clf_nl_path)\n",
    "\n",
    "print(\"Loaded artifacts:\")\n",
    "print(\"  preprocess:\", pre_nl_path.name)\n",
    "print(\"  model     :\", clf_nl_path.name)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Get feature names robustly\n",
    "# -----------------------------\n",
    "feature_names_noleak = None\n",
    "\n",
    "# Try transformer API first\n",
    "try:\n",
    "    feature_names_noleak = preprocess_noleak.get_feature_names_out().tolist()\n",
    "except Exception:\n",
    "    feature_names_noleak = None\n",
    "\n",
    "# Fallback to CSV if needed\n",
    "if feature_names_noleak is None:\n",
    "    if feat_path is None:\n",
    "        raise FileNotFoundError(\"Could not obtain feature names from transformer, and no feature_names*.csv exists in OUT_DIR.\")\n",
    "    feature_names_noleak = pd.read_csv(feat_path)[\"feature_name\"].astype(str).tolist()\n",
    "    print(\"  feature names:\", feat_path.name, \"(from CSV)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Coefficients (binary logistic regression)\n",
    "# -----------------------------\n",
    "if not hasattr(clf_noleak, \"coef_\"):\n",
    "    raise TypeError(\"Loaded model does not expose coef_. This cell expects a linear model like LogisticRegression.\")\n",
    "\n",
    "coefs_nl = np.asarray(clf_noleak.coef_).ravel()\n",
    "\n",
    "if len(coefs_nl) != len(feature_names_noleak):\n",
    "    raise ValueError(\n",
    "        \"Coefficient/feature mismatch.\\n\"\n",
    "        f\"  #coefs   : {len(coefs_nl)}\\n\"\n",
    "        f\"  #features: {len(feature_names_noleak)}\\n\"\n",
    "        \"This usually means you changed features and re-fit one artifact but not the other.\\n\"\n",
    "        \"Fix: re-run the preprocessing+fit cells (Cell 6/7) so artifacts are regenerated in the SAME OUT_DIR.\"\n",
    "    )\n",
    "\n",
    "coef_nl_df = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": feature_names_noleak,\n",
    "        \"coef\": coefs_nl,\n",
    "        \"abs_coef\": np.abs(coefs_nl),\n",
    "    })\n",
    "    .sort_values(\"abs_coef\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 features by |coef|:\")\n",
    "display(coef_nl_df.head(20))\n",
    "\n",
    "print(\"\\nTop 15 pushing toward target=1 (largest +coef):\")\n",
    "display(coef_nl_df.sort_values(\"coef\", ascending=False).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "print(\"\\nTop 15 pushing toward target=0 (most -coef):\")\n",
    "display(coef_nl_df.sort_values(\"coef\", ascending=True).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "coef_out = OUT_DIR / \"baseline_logreg_coefficients.csv\"\n",
    "coef_nl_df.to_csv(coef_out, index=False)\n",
    "print(\"\\nSaved:\", coef_out)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Compare metrics: leaky vs no-leak (if JSONs exist)\n",
    "# -----------------------------\n",
    "def load_metrics(p: Path) -> dict:\n",
    "    return json.loads(p.read_text()) if p.exists() else {}\n",
    "\n",
    "m_leak = load_metrics(leaky_metrics_path)\n",
    "m_nl   = load_metrics(noleak_metrics_path)\n",
    "\n",
    "if not m_leak:\n",
    "    print(\"\\nNote: leaky metrics JSON not found:\", leaky_metrics_path.name)\n",
    "if not m_nl:\n",
    "    print(\"Note: no-leak metrics JSON not found:\", noleak_metrics_path.name)\n",
    "\n",
    "keys = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\", \"pr_auc\"]\n",
    "compare_df = pd.DataFrame([{\n",
    "    \"metric\": k,\n",
    "    \"leaky_baseline\": m_leak.get(k),\n",
    "    \"no_leak_baseline\": m_nl.get(k),\n",
    "} for k in keys])\n",
    "\n",
    "print(\"\\nBaseline comparison (leaky vs no-leak):\")\n",
    "display(compare_df)\n",
    "\n",
    "compare_path = OUT_DIR / \"baseline_comparison_leak_vs_noleak.csv\"\n",
    "compare_df.to_csv(compare_path, index=False)\n",
    "print(\"Saved:\", compare_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcecc49-47cc-46ad-a6c7-941c122cf871",
   "metadata": {},
   "source": [
    "### What Cell 12 Just Did\n",
    "This cell translated the baseline Logistic Regression model into **human-readable drivers** and then compared the “too-good-to-be-true” baseline against the **no-leak** baseline using saved metrics.\n",
    "\n",
    "1) **Extracted interpretable feature importance (no-leak model)**\n",
    "- Pulled the **transformed feature names** from the fitted no-leak preprocessing pipeline (`preprocess_noleak.get_feature_names_out()`).\n",
    "- Retrieved the model’s coefficients (`clf_noleak.coef_`) and assembled a table with:\n",
    "  - `feature`\n",
    "  - `coef` (direction of effect)\n",
    "  - `abs_coef` (magnitude / strength)\n",
    "\n",
    "2) **Reported the most influential drivers**\n",
    "- Displayed:\n",
    "  - **Top 20** features by absolute coefficient magnitude (strongest overall signals)\n",
    "  - **Top 15 pushing toward target=1** (positive coefficients)\n",
    "  - **Top 15 pushing toward target=0** (negative coefficients)\n",
    "\n",
    "3) **Saved coefficient outputs for the report**\n",
    "- Exported the full coefficient table to:\n",
    "  - `baseline_logreg_noleak_coefficients.csv`\n",
    "\n",
    "4) **Compared performance: leaky vs no-leak**\n",
    "- Loaded metrics from:\n",
    "  - `baseline_logreg_metrics.json` (leaky)\n",
    "  - `baseline_logreg_noleak_metrics.json` (no-leak)\n",
    "- Built a side-by-side comparison table for:\n",
    "  - accuracy, precision, recall, f1, roc_auc\n",
    "- Saved the comparison to:\n",
    "  - `baseline_comparison_leak_vs_noleak.csv`\n",
    "\n",
    "Net result: you get **traceable model drivers** for the no-leak baseline plus a clean **metrics comparison** showing how much performance was inflated by leakage in the leaky baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36b0299b-2cce-45e1-be0d-7f387beec751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iot_events shape: (588681, 18)\n",
      "Columns: ['event_id', 'ts_utc', 'site_id', 'line_id', 'asset_id', 'asset_type', 'is_legacy', 'event_kind', 'metric_name', 'metric_unit', 'metric_value', 'severity', 'incident_type', 'message', 'ts_local', 'local_date', 'local_hour', 'ts_local_str']\n",
      "\n",
      "Event_kind counts:\n",
      "event_kind\n",
      "telemetry    588549\n",
      "incident        132\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Time split:\n",
      "  t_min   : 2025-11-27 00:05:18.868743+00:00\n",
      "  t_split : 2025-12-06 19:13:48.868743+00:00  (SPLIT_FRAC=0.7)\n",
      "  t_max   : 2025-12-11 00:00:18.868743+00:00\n",
      "  early rows: 412,017 | late rows: 176,664\n",
      "\n",
      "EARLY telemetry features table:\n",
      "  shape: (120, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>humidity_rh_tele_count</th>\n",
       "      <th>line_speed_u_min_tele_count</th>\n",
       "      <th>pressure_kpa_tele_count</th>\n",
       "      <th>reject_rate_pct_tele_count</th>\n",
       "      <th>temp_c_tele_count</th>\n",
       "      <th>vibration_mm_s_tele_count</th>\n",
       "      <th>humidity_rh_tele_mean</th>\n",
       "      <th>line_speed_u_min_tele_mean</th>\n",
       "      <th>pressure_kpa_tele_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>reject_rate_pct_tele_min</th>\n",
       "      <th>temp_c_tele_min</th>\n",
       "      <th>vibration_mm_s_tele_min</th>\n",
       "      <th>humidity_rh_tele_max</th>\n",
       "      <th>line_speed_u_min_tele_max</th>\n",
       "      <th>pressure_kpa_tele_max</th>\n",
       "      <th>reject_rate_pct_tele_max</th>\n",
       "      <th>temp_c_tele_max</th>\n",
       "      <th>vibration_mm_s_tele_max</th>\n",
       "      <th>telemetry_rows_early</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>959</td>\n",
       "      <td>896</td>\n",
       "      <td>927</td>\n",
       "      <td>963</td>\n",
       "      <td>938</td>\n",
       "      <td>917</td>\n",
       "      <td>44.999505</td>\n",
       "      <td>119.976665</td>\n",
       "      <td>210.673051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.469889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.485263</td>\n",
       "      <td>184.002113</td>\n",
       "      <td>287.054630</td>\n",
       "      <td>2.396554</td>\n",
       "      <td>39.778713</td>\n",
       "      <td>4.769174</td>\n",
       "      <td>5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>270</td>\n",
       "      <td>279</td>\n",
       "      <td>255</td>\n",
       "      <td>274</td>\n",
       "      <td>306</td>\n",
       "      <td>290</td>\n",
       "      <td>45.243457</td>\n",
       "      <td>121.457525</td>\n",
       "      <td>206.845773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.440734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.851688</td>\n",
       "      <td>255.095317</td>\n",
       "      <td>273.747021</td>\n",
       "      <td>2.804359</td>\n",
       "      <td>43.157302</td>\n",
       "      <td>5.885594</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>289</td>\n",
       "      <td>267</td>\n",
       "      <td>276</td>\n",
       "      <td>295</td>\n",
       "      <td>326</td>\n",
       "      <td>308</td>\n",
       "      <td>44.992208</td>\n",
       "      <td>119.231941</td>\n",
       "      <td>210.787694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.038428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.857574</td>\n",
       "      <td>223.211676</td>\n",
       "      <td>296.874142</td>\n",
       "      <td>2.687691</td>\n",
       "      <td>43.781254</td>\n",
       "      <td>6.863986</td>\n",
       "      <td>1761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>297</td>\n",
       "      <td>275</td>\n",
       "      <td>323</td>\n",
       "      <td>313</td>\n",
       "      <td>295</td>\n",
       "      <td>273</td>\n",
       "      <td>35.260097</td>\n",
       "      <td>120.256890</td>\n",
       "      <td>272.375500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.463190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.436032</td>\n",
       "      <td>216.465608</td>\n",
       "      <td>375.143159</td>\n",
       "      <td>3.543128</td>\n",
       "      <td>58.295560</td>\n",
       "      <td>5.939783</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>317</td>\n",
       "      <td>293</td>\n",
       "      <td>301</td>\n",
       "      <td>291</td>\n",
       "      <td>305</td>\n",
       "      <td>272</td>\n",
       "      <td>51.034597</td>\n",
       "      <td>115.673647</td>\n",
       "      <td>209.630440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.289878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.924797</td>\n",
       "      <td>202.413662</td>\n",
       "      <td>297.961037</td>\n",
       "      <td>4.383267</td>\n",
       "      <td>38.467699</td>\n",
       "      <td>6.290991</td>\n",
       "      <td>1779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id  humidity_rh_tele_count  line_speed_u_min_tele_count  \\\n",
       "0    A0001                     959                          896   \n",
       "1    A0002                     270                          279   \n",
       "2    A0003                     289                          267   \n",
       "3    A0004                     297                          275   \n",
       "4    A0005                     317                          293   \n",
       "\n",
       "   pressure_kpa_tele_count  reject_rate_pct_tele_count  temp_c_tele_count  \\\n",
       "0                      927                         963                938   \n",
       "1                      255                         274                306   \n",
       "2                      276                         295                326   \n",
       "3                      323                         313                295   \n",
       "4                      301                         291                305   \n",
       "\n",
       "   vibration_mm_s_tele_count  humidity_rh_tele_mean  \\\n",
       "0                        917              44.999505   \n",
       "1                        290              45.243457   \n",
       "2                        308              44.992208   \n",
       "3                        273              35.260097   \n",
       "4                        272              51.034597   \n",
       "\n",
       "   line_speed_u_min_tele_mean  pressure_kpa_tele_mean  ...  \\\n",
       "0                  119.976665              210.673051  ...   \n",
       "1                  121.457525              206.845773  ...   \n",
       "2                  119.231941              210.787694  ...   \n",
       "3                  120.256890              272.375500  ...   \n",
       "4                  115.673647              209.630440  ...   \n",
       "\n",
       "   reject_rate_pct_tele_min  temp_c_tele_min  vibration_mm_s_tele_min  \\\n",
       "0                       0.0        18.469889                      0.0   \n",
       "1                       0.0        12.440734                      0.0   \n",
       "2                       0.0        14.038428                      0.0   \n",
       "3                       0.0        29.463190                      0.0   \n",
       "4                       0.0        12.289878                      0.0   \n",
       "\n",
       "   humidity_rh_tele_max  line_speed_u_min_tele_max  pressure_kpa_tele_max  \\\n",
       "0             68.485263                 184.002113             287.054630   \n",
       "1             73.851688                 255.095317             273.747021   \n",
       "2             80.857574                 223.211676             296.874142   \n",
       "3             69.436032                 216.465608             375.143159   \n",
       "4             84.924797                 202.413662             297.961037   \n",
       "\n",
       "   reject_rate_pct_tele_max  temp_c_tele_max  vibration_mm_s_tele_max  \\\n",
       "0                  2.396554        39.778713                 4.769174   \n",
       "1                  2.804359        43.157302                 5.885594   \n",
       "2                  2.687691        43.781254                 6.863986   \n",
       "3                  3.543128        58.295560                 5.939783   \n",
       "4                  4.383267        38.467699                 6.290991   \n",
       "\n",
       "   telemetry_rows_early  \n",
       "0                  5600  \n",
       "1                  1674  \n",
       "2                  1761  \n",
       "3                  1776  \n",
       "4                  1779  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/iot_asset_telemetry_features_early.csv\n",
      "\n",
      "LATE-window label diagnostics:\n",
      "  assets: 120\n",
      "  late incidents total: 44\n",
      "  positive rate: 0.3\n",
      "target_event_future\n",
      "0    84\n",
      "1    36\n",
      "Name: count, dtype: int64\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/iot_asset_incident_labels_late.csv\n",
      "\n",
      "Time-split dataset (features from EARLY, label from LATE):\n",
      "  shape: (120, 34)\n",
      "  positive rate: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>humidity_rh_tele_count</th>\n",
       "      <th>line_speed_u_min_tele_count</th>\n",
       "      <th>pressure_kpa_tele_count</th>\n",
       "      <th>reject_rate_pct_tele_count</th>\n",
       "      <th>temp_c_tele_count</th>\n",
       "      <th>vibration_mm_s_tele_count</th>\n",
       "      <th>humidity_rh_tele_mean</th>\n",
       "      <th>line_speed_u_min_tele_mean</th>\n",
       "      <th>pressure_kpa_tele_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>vibration_mm_s_tele_min</th>\n",
       "      <th>humidity_rh_tele_max</th>\n",
       "      <th>line_speed_u_min_tele_max</th>\n",
       "      <th>pressure_kpa_tele_max</th>\n",
       "      <th>reject_rate_pct_tele_max</th>\n",
       "      <th>temp_c_tele_max</th>\n",
       "      <th>vibration_mm_s_tele_max</th>\n",
       "      <th>telemetry_rows_early</th>\n",
       "      <th>incidents_late</th>\n",
       "      <th>target_event_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>959</td>\n",
       "      <td>896</td>\n",
       "      <td>927</td>\n",
       "      <td>963</td>\n",
       "      <td>938</td>\n",
       "      <td>917</td>\n",
       "      <td>44.999505</td>\n",
       "      <td>119.976665</td>\n",
       "      <td>210.673051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.485263</td>\n",
       "      <td>184.002113</td>\n",
       "      <td>287.054630</td>\n",
       "      <td>2.396554</td>\n",
       "      <td>39.778713</td>\n",
       "      <td>4.769174</td>\n",
       "      <td>5600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>270</td>\n",
       "      <td>279</td>\n",
       "      <td>255</td>\n",
       "      <td>274</td>\n",
       "      <td>306</td>\n",
       "      <td>290</td>\n",
       "      <td>45.243457</td>\n",
       "      <td>121.457525</td>\n",
       "      <td>206.845773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.851688</td>\n",
       "      <td>255.095317</td>\n",
       "      <td>273.747021</td>\n",
       "      <td>2.804359</td>\n",
       "      <td>43.157302</td>\n",
       "      <td>5.885594</td>\n",
       "      <td>1674</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>289</td>\n",
       "      <td>267</td>\n",
       "      <td>276</td>\n",
       "      <td>295</td>\n",
       "      <td>326</td>\n",
       "      <td>308</td>\n",
       "      <td>44.992208</td>\n",
       "      <td>119.231941</td>\n",
       "      <td>210.787694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.857574</td>\n",
       "      <td>223.211676</td>\n",
       "      <td>296.874142</td>\n",
       "      <td>2.687691</td>\n",
       "      <td>43.781254</td>\n",
       "      <td>6.863986</td>\n",
       "      <td>1761</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>297</td>\n",
       "      <td>275</td>\n",
       "      <td>323</td>\n",
       "      <td>313</td>\n",
       "      <td>295</td>\n",
       "      <td>273</td>\n",
       "      <td>35.260097</td>\n",
       "      <td>120.256890</td>\n",
       "      <td>272.375500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.436032</td>\n",
       "      <td>216.465608</td>\n",
       "      <td>375.143159</td>\n",
       "      <td>3.543128</td>\n",
       "      <td>58.295560</td>\n",
       "      <td>5.939783</td>\n",
       "      <td>1776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>317</td>\n",
       "      <td>293</td>\n",
       "      <td>301</td>\n",
       "      <td>291</td>\n",
       "      <td>305</td>\n",
       "      <td>272</td>\n",
       "      <td>51.034597</td>\n",
       "      <td>115.673647</td>\n",
       "      <td>209.630440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.924797</td>\n",
       "      <td>202.413662</td>\n",
       "      <td>297.961037</td>\n",
       "      <td>4.383267</td>\n",
       "      <td>38.467699</td>\n",
       "      <td>6.290991</td>\n",
       "      <td>1779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id  humidity_rh_tele_count  line_speed_u_min_tele_count  \\\n",
       "0    A0001                     959                          896   \n",
       "1    A0002                     270                          279   \n",
       "2    A0003                     289                          267   \n",
       "3    A0004                     297                          275   \n",
       "4    A0005                     317                          293   \n",
       "\n",
       "   pressure_kpa_tele_count  reject_rate_pct_tele_count  temp_c_tele_count  \\\n",
       "0                      927                         963                938   \n",
       "1                      255                         274                306   \n",
       "2                      276                         295                326   \n",
       "3                      323                         313                295   \n",
       "4                      301                         291                305   \n",
       "\n",
       "   vibration_mm_s_tele_count  humidity_rh_tele_mean  \\\n",
       "0                        917              44.999505   \n",
       "1                        290              45.243457   \n",
       "2                        308              44.992208   \n",
       "3                        273              35.260097   \n",
       "4                        272              51.034597   \n",
       "\n",
       "   line_speed_u_min_tele_mean  pressure_kpa_tele_mean  ...  \\\n",
       "0                  119.976665              210.673051  ...   \n",
       "1                  121.457525              206.845773  ...   \n",
       "2                  119.231941              210.787694  ...   \n",
       "3                  120.256890              272.375500  ...   \n",
       "4                  115.673647              209.630440  ...   \n",
       "\n",
       "   vibration_mm_s_tele_min  humidity_rh_tele_max  line_speed_u_min_tele_max  \\\n",
       "0                      0.0             68.485263                 184.002113   \n",
       "1                      0.0             73.851688                 255.095317   \n",
       "2                      0.0             80.857574                 223.211676   \n",
       "3                      0.0             69.436032                 216.465608   \n",
       "4                      0.0             84.924797                 202.413662   \n",
       "\n",
       "   pressure_kpa_tele_max  reject_rate_pct_tele_max  temp_c_tele_max  \\\n",
       "0             287.054630                  2.396554        39.778713   \n",
       "1             273.747021                  2.804359        43.157302   \n",
       "2             296.874142                  2.687691        43.781254   \n",
       "3             375.143159                  3.543128        58.295560   \n",
       "4             297.961037                  4.383267        38.467699   \n",
       "\n",
       "   vibration_mm_s_tele_max  telemetry_rows_early  incidents_late  \\\n",
       "0                 4.769174                  5600               0   \n",
       "1                 5.885594                  1674               0   \n",
       "2                 6.863986                  1761               1   \n",
       "3                 5.939783                  1776               0   \n",
       "4                 6.290991                  1779               2   \n",
       "\n",
       "   target_event_future  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    1  \n",
       "3                    0  \n",
       "4                    1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/iot_asset_time_split_dataset.csv\n",
      "\n",
      "✅ Cell 13 complete.\n",
      "Next: update Cell 14 to join this dataset to assets_master/sites_master (optional),\n",
      "and run a clean modeling pass where features do NOT include late-window incident aggregates.\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 13 — TIME-SPLIT “real label” path (asset-level):\n",
    "#   EARLY window: telemetry features\n",
    "#   LATE  window: incident-based label (future incidents)\n",
    "#============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Load events\n",
    "# -----------------------------\n",
    "iot_path = RAW_DIR / \"iot_events.parquet\"\n",
    "if not iot_path.exists():\n",
    "    raise FileNotFoundError(f\"Expected iot events at: {iot_path}\")\n",
    "\n",
    "iot = pd.read_parquet(iot_path)\n",
    "print(\"iot_events shape:\", iot.shape)\n",
    "print(\"Columns:\", list(iot.columns))\n",
    "\n",
    "# Required minimal columns\n",
    "required = [\"asset_id\", \"ts_utc\", \"event_kind\"]\n",
    "missing_req = [c for c in required if c not in iot.columns]\n",
    "if missing_req:\n",
    "    raise KeyError(f\"Missing required columns in iot_events.parquet: {missing_req}\")\n",
    "\n",
    "iot[\"asset_id\"] = iot[\"asset_id\"].astype(str).str.strip()\n",
    "iot[\"ts_utc\"] = pd.to_datetime(iot[\"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "if iot[\"ts_utc\"].isna().any():\n",
    "    bad = int(iot[\"ts_utc\"].isna().sum())\n",
    "    raise ValueError(f\"ts_utc has {bad} NaT after parsing; check raw file integrity.\")\n",
    "\n",
    "# Basic kind counts\n",
    "print(\"\\nEvent_kind counts:\")\n",
    "print(iot[\"event_kind\"].value_counts(dropna=False))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Define time split (EARLY vs LATE) per GLOBAL timeline\n",
    "#    (keeps it simple + avoids leaking future into feature window)\n",
    "# -----------------------------\n",
    "t_min = iot[\"ts_utc\"].min()\n",
    "t_max = iot[\"ts_utc\"].max()\n",
    "span = (t_max - t_min)\n",
    "\n",
    "# Split point at 70% of timeline (tuneable)\n",
    "SPLIT_FRAC = 0.70\n",
    "t_split = t_min + span * SPLIT_FRAC\n",
    "\n",
    "early = iot[iot[\"ts_utc\"] < t_split].copy()\n",
    "late  = iot[iot[\"ts_utc\"] >= t_split].copy()\n",
    "\n",
    "print(\"\\nTime split:\")\n",
    "print(f\"  t_min   : {t_min}\")\n",
    "print(f\"  t_split : {t_split}  (SPLIT_FRAC={SPLIT_FRAC})\")\n",
    "print(f\"  t_max   : {t_max}\")\n",
    "print(f\"  early rows: {len(early):,} | late rows: {len(late):,}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) EARLY WINDOW FEATURES (telemetry-only)\n",
    "#    Aggregate metric_value per asset_id, per metric_name, with robust stats.\n",
    "# -----------------------------\n",
    "tele_early = early[early[\"event_kind\"] == \"telemetry\"].copy()\n",
    "\n",
    "if tele_early.empty:\n",
    "    raise ValueError(\"No telemetry rows found in EARLY window; adjust SPLIT_FRAC or check event_kind values.\")\n",
    "\n",
    "# Ensure columns exist\n",
    "for c in [\"metric_name\", \"metric_value\"]:\n",
    "    if c not in tele_early.columns:\n",
    "        raise KeyError(f\"Expected telemetry column missing: {c}\")\n",
    "\n",
    "tele_early[\"metric_name\"] = tele_early[\"metric_name\"].astype(str).str.strip()\n",
    "tele_early[\"metric_value\"] = pd.to_numeric(tele_early[\"metric_value\"], errors=\"coerce\")\n",
    "\n",
    "# Per asset x metric aggregates\n",
    "g = tele_early.groupby([\"asset_id\", \"metric_name\"])[\"metric_value\"]\n",
    "\n",
    "tele_agg = g.agg(\n",
    "    tele_count=\"count\",\n",
    "    tele_mean=\"mean\",\n",
    "    tele_std=\"std\",\n",
    "    tele_min=\"min\",\n",
    "    tele_max=\"max\",\n",
    ").reset_index()\n",
    "\n",
    "# Pivot to wide features: metric-specific columns\n",
    "tele_wide = tele_agg.pivot(index=\"asset_id\", columns=\"metric_name\")\n",
    "tele_wide.columns = [f\"{m}_{stat}\" for (stat, m) in tele_wide.columns]  # (stat, metric) order from agg\n",
    "tele_wide = tele_wide.reset_index()\n",
    "\n",
    "# Add overall telemetry volume signals (early only)\n",
    "tele_vol = tele_early.groupby(\"asset_id\").size().rename(\"telemetry_rows_early\").reset_index()\n",
    "\n",
    "features_early = tele_wide.merge(tele_vol, on=\"asset_id\", how=\"left\")\n",
    "\n",
    "print(\"\\nEARLY telemetry features table:\")\n",
    "print(\"  shape:\", features_early.shape)\n",
    "display(features_early.head(5))\n",
    "\n",
    "features_path = OUT_DIR / \"iot_asset_telemetry_features_early.csv\"\n",
    "features_early.to_csv(features_path, index=False)\n",
    "print(\"Saved:\", features_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) LATE WINDOW LABEL (future incidents)\n",
    "#    Label = 1 if any incident in LATE window (or top-quartile by count, tuneable)\n",
    "# -----------------------------\n",
    "inc_late = late[late[\"event_kind\"] == \"incident\"].copy()\n",
    "\n",
    "# incident count per asset in late\n",
    "inc_counts_late = inc_late.groupby(\"asset_id\").size().rename(\"incidents_late\").reset_index()\n",
    "\n",
    "# Build label table over ALL assets seen anywhere\n",
    "all_assets = pd.DataFrame({\"asset_id\": sorted(iot[\"asset_id\"].unique())})\n",
    "\n",
    "labels = all_assets.merge(inc_counts_late, on=\"asset_id\", how=\"left\")\n",
    "labels[\"incidents_late\"] = labels[\"incidents_late\"].fillna(0).astype(int)\n",
    "\n",
    "# Label rule A (default): any late incident => 1\n",
    "labels[\"target_event_future\"] = (labels[\"incidents_late\"] > 0).astype(\"int8\")\n",
    "\n",
    "# Optional alternative label rule B: top quartile of late incidents\n",
    "# q75_late = labels[\"incidents_late\"].quantile(0.75)\n",
    "# labels[\"target_event_future\"] = (labels[\"incidents_late\"] >= q75_late).astype(\"int8\")\n",
    "\n",
    "print(\"\\nLATE-window label diagnostics:\")\n",
    "print(\"  assets:\", len(labels))\n",
    "print(\"  late incidents total:\", int(labels[\"incidents_late\"].sum()))\n",
    "print(\"  positive rate:\", float(labels[\"target_event_future\"].mean()))\n",
    "print(labels[\"target_event_future\"].value_counts(dropna=False))\n",
    "\n",
    "labels_path = OUT_DIR / \"iot_asset_incident_labels_late.csv\"\n",
    "labels.to_csv(labels_path, index=False)\n",
    "print(\"Saved:\", labels_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Join features + label => modeling dataset\n",
    "# -----------------------------\n",
    "dataset = all_assets.merge(features_early, on=\"asset_id\", how=\"left\")\n",
    "dataset = dataset.merge(labels[[\"asset_id\", \"incidents_late\", \"target_event_future\"]], on=\"asset_id\", how=\"left\")\n",
    "\n",
    "# Fill NaNs in telemetry features (assets with sparse telemetry in early window)\n",
    "# Keep counts as 0; stats as NaN->0 (simple baseline). You can improve later.\n",
    "fill_cols = [c for c in dataset.columns if c not in [\"asset_id\"]]\n",
    "dataset[fill_cols] = dataset[fill_cols].fillna(0)\n",
    "\n",
    "print(\"\\nTime-split dataset (features from EARLY, label from LATE):\")\n",
    "print(\"  shape:\", dataset.shape)\n",
    "print(\"  positive rate:\", float(dataset[\"target_event_future\"].mean()))\n",
    "display(dataset.head(5))\n",
    "\n",
    "dataset_path = OUT_DIR / \"iot_asset_time_split_dataset.csv\"\n",
    "dataset.to_csv(dataset_path, index=False)\n",
    "print(\"Saved:\", dataset_path)\n",
    "\n",
    "print(\n",
    "    \"\\n✅ Cell 13 complete.\\n\"\n",
    "    \"Next: update Cell 14 to join this dataset to assets_master/sites_master (optional),\\n\"\n",
    "    \"and run a clean modeling pass where features do NOT include late-window incident aggregates.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae27ea5-197c-41e6-9a2d-dfc1caaa0337",
   "metadata": {},
   "source": [
    "### What Cell 13 Just Did\n",
    "This cell created a **time-split, leakage-resistant “real label” dataset** at the *asset level* by separating **feature time** from **label time**.\n",
    "\n",
    "#### 1) Loaded and profiled the raw IoT event stream\n",
    "- Read `iot_events.parquet` (≈588k rows) and confirmed the schema.\n",
    "- Verified event composition:\n",
    "  - **telemetry** rows dominate (≈588,549)\n",
    "  - **incident** rows are rare (≈132)\n",
    "\n",
    "#### 2) Defined an explicit time split (EARLY vs LATE)\n",
    "- Computed:\n",
    "  - `t_min` = earliest timestamp\n",
    "  - `t_max` = latest timestamp\n",
    "  - `t_split` based on `SPLIT_FRAC=0.7`\n",
    "- Partitioned the raw events into:\n",
    "  - **EARLY window** (used only for features)\n",
    "  - **LATE window** (used only for labels)\n",
    "\n",
    "#### 3) Built EARLY telemetry feature aggregates per asset\n",
    "- Filtered to **EARLY telemetry** rows and aggregated by `asset_id`.\n",
    "- For each key metric (e.g., humidity, line speed, pressure, reject rate, temperature, vibration), computed telemetry summaries such as:\n",
    "  - counts and coverage\n",
    "  - mean / std / min / max (per metric)\n",
    "- Produced an **asset-level telemetry feature table** (one row per asset).\n",
    "- Saved:\n",
    "  - `iot_asset_telemetry_features_early.csv`\n",
    "\n",
    "#### 4) Built the LATE incident-derived “future label”\n",
    "- Filtered to **LATE incident** rows.\n",
    "- Aggregated incidents per `asset_id` into `incidents_late`.\n",
    "- Created a binary label:\n",
    "  - `target_event_future = 1` if `incidents_late >= 1`\n",
    "  - else `0`\n",
    "- Reported label distribution + positive rate.\n",
    "- Saved:\n",
    "  - `iot_asset_incident_labels_late.csv`\n",
    "\n",
    "#### 5) Assembled the final TIME-SPLIT dataset\n",
    "- Joined:\n",
    "  - EARLY telemetry features (predictors)\n",
    "  - LATE incident label (outcome)\n",
    "- Result: an **asset-level modeling table** where features cannot “peek” into the future.\n",
    "- Saved:\n",
    "  - `iot_asset_time_split_dataset.csv`\n",
    "\n",
    "Net result: you now have a clean modeling target (“future incidents”) with predictors computed strictly from an earlier time window, which avoids the leakage-by-construction problem seen in the earlier event-derived label approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "409a9f12-d66b-497d-8df4-14c50835eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded time-split dataset: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/iot_asset_time_split_dataset.csv\n",
      "ts_df shape: (120, 34)\n",
      "Label distribution (target_event_future):\n",
      "target_event_future\n",
      "0    84\n",
      "1    36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Loaded assets_master.csv + joined sites_master.csv.\n",
      "Master shape: (120, 9)\n",
      "Added site columns: ['site_name', 'tz'] \n",
      "\n",
      "After join (master + time-split):\n",
      "  event_model_df shape: (120, 42)\n",
      "\n",
      "Coverage checks:\n",
      "  Assets in master table : 120\n",
      "  Assets with any features: 120\n",
      "  Assets with labels     : 120\n",
      "Dropped 0 row(s) with missing target_event_future. Remaining: 120\n",
      "\n",
      "Final label distribution (target_event_future):\n",
      "target_event_future\n",
      "0    84\n",
      "1    36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_model_table.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>vendor</th>\n",
       "      <th>site_name</th>\n",
       "      <th>tz</th>\n",
       "      <th>humidity_rh_tele_count</th>\n",
       "      <th>...</th>\n",
       "      <th>vibration_mm_s_tele_min</th>\n",
       "      <th>humidity_rh_tele_max</th>\n",
       "      <th>line_speed_u_min_tele_max</th>\n",
       "      <th>pressure_kpa_tele_max</th>\n",
       "      <th>reject_rate_pct_tele_max</th>\n",
       "      <th>temp_c_tele_max</th>\n",
       "      <th>vibration_mm_s_tele_max</th>\n",
       "      <th>telemetry_rows_early</th>\n",
       "      <th>incidents_late</th>\n",
       "      <th>target_event_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.485263</td>\n",
       "      <td>184.002113</td>\n",
       "      <td>287.054630</td>\n",
       "      <td>2.396554</td>\n",
       "      <td>39.778713</td>\n",
       "      <td>4.769174</td>\n",
       "      <td>5600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.851688</td>\n",
       "      <td>255.095317</td>\n",
       "      <td>273.747021</td>\n",
       "      <td>2.804359</td>\n",
       "      <td>43.157302</td>\n",
       "      <td>5.885594</td>\n",
       "      <td>1674</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.857574</td>\n",
       "      <td>223.211676</td>\n",
       "      <td>296.874142</td>\n",
       "      <td>2.687691</td>\n",
       "      <td>43.781254</td>\n",
       "      <td>6.863986</td>\n",
       "      <td>1761</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.436032</td>\n",
       "      <td>216.465608</td>\n",
       "      <td>375.143159</td>\n",
       "      <td>3.543128</td>\n",
       "      <td>58.295560</td>\n",
       "      <td>5.939783</td>\n",
       "      <td>1776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.924797</td>\n",
       "      <td>202.413662</td>\n",
       "      <td>297.961037</td>\n",
       "      <td>4.383267</td>\n",
       "      <td>38.467699</td>\n",
       "      <td>6.290991</td>\n",
       "      <td>1779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0006</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L3</td>\n",
       "      <td>capper</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.364138</td>\n",
       "      <td>223.575589</td>\n",
       "      <td>299.149181</td>\n",
       "      <td>3.144256</td>\n",
       "      <td>46.923189</td>\n",
       "      <td>6.230991</td>\n",
       "      <td>1741</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0007</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.449657</td>\n",
       "      <td>216.878219</td>\n",
       "      <td>290.356242</td>\n",
       "      <td>2.760365</td>\n",
       "      <td>40.017456</td>\n",
       "      <td>7.200344</td>\n",
       "      <td>1686</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0008</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L4</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>Europe/Dublin</td>\n",
       "      <td>944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.058609</td>\n",
       "      <td>191.677670</td>\n",
       "      <td>269.974682</td>\n",
       "      <td>2.407687</td>\n",
       "      <td>37.476825</td>\n",
       "      <td>4.823017</td>\n",
       "      <td>5618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0009</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.647636</td>\n",
       "      <td>240.368263</td>\n",
       "      <td>353.610159</td>\n",
       "      <td>2.899701</td>\n",
       "      <td>56.601186</td>\n",
       "      <td>6.227792</td>\n",
       "      <td>1700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0010</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.452928</td>\n",
       "      <td>211.532120</td>\n",
       "      <td>290.799053</td>\n",
       "      <td>3.782267</td>\n",
       "      <td>39.274605</td>\n",
       "      <td>6.802786</td>\n",
       "      <td>1709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id site_id line_id             asset_type  is_legacy   connectivity  \\\n",
       "0    A0001      S1   S1-L2         blister_packer      False     mqtt_opcua   \n",
       "1    A0002      S2   S2-L5            print_apply       True  legacy_serial   \n",
       "2    A0003      S4   S4-L2         blister_packer       True  legacy_serial   \n",
       "3    A0004      S1   S1-L2             sterilizer       True  legacy_serial   \n",
       "4    A0005      S4   S4-L2  environmental_monitor       True  legacy_serial   \n",
       "5    A0006      S4   S4-L3                 capper       True  legacy_serial   \n",
       "6    A0007      S1   S1-L3               cartoner       True  legacy_serial   \n",
       "7    A0008      S3   S3-L4         blister_packer      False     mqtt_opcua   \n",
       "8    A0009      S1   S1-L5             sterilizer       True  legacy_serial   \n",
       "9    A0010      S2   S2-L3            print_apply       True  legacy_serial   \n",
       "\n",
       "    vendor                     site_name                            tz  \\\n",
       "0  VendorB  Indianapolis Packaging Plant  America/Indiana/Indianapolis   \n",
       "1  VendorA     San Diego Device Assembly           America/Los_Angeles   \n",
       "2  VendorB         Singapore Sterile Ops                Asia/Singapore   \n",
       "3  VendorD  Indianapolis Packaging Plant  America/Indiana/Indianapolis   \n",
       "4  VendorA         Singapore Sterile Ops                Asia/Singapore   \n",
       "5  VendorB         Singapore Sterile Ops                Asia/Singapore   \n",
       "6  VendorC  Indianapolis Packaging Plant  America/Indiana/Indianapolis   \n",
       "7  VendorA           Dublin EU Packaging                 Europe/Dublin   \n",
       "8  VendorC  Indianapolis Packaging Plant  America/Indiana/Indianapolis   \n",
       "9  VendorB     San Diego Device Assembly           America/Los_Angeles   \n",
       "\n",
       "   humidity_rh_tele_count  ...  vibration_mm_s_tele_min  humidity_rh_tele_max  \\\n",
       "0                     959  ...                      0.0             68.485263   \n",
       "1                     270  ...                      0.0             73.851688   \n",
       "2                     289  ...                      0.0             80.857574   \n",
       "3                     297  ...                      0.0             69.436032   \n",
       "4                     317  ...                      0.0             84.924797   \n",
       "5                     299  ...                      0.0             83.364138   \n",
       "6                     310  ...                      0.0             76.449657   \n",
       "7                     944  ...                      0.0             70.058609   \n",
       "8                     281  ...                      0.0             66.647636   \n",
       "9                     315  ...                      0.0             77.452928   \n",
       "\n",
       "   line_speed_u_min_tele_max  pressure_kpa_tele_max  reject_rate_pct_tele_max  \\\n",
       "0                 184.002113             287.054630                  2.396554   \n",
       "1                 255.095317             273.747021                  2.804359   \n",
       "2                 223.211676             296.874142                  2.687691   \n",
       "3                 216.465608             375.143159                  3.543128   \n",
       "4                 202.413662             297.961037                  4.383267   \n",
       "5                 223.575589             299.149181                  3.144256   \n",
       "6                 216.878219             290.356242                  2.760365   \n",
       "7                 191.677670             269.974682                  2.407687   \n",
       "8                 240.368263             353.610159                  2.899701   \n",
       "9                 211.532120             290.799053                  3.782267   \n",
       "\n",
       "   temp_c_tele_max  vibration_mm_s_tele_max  telemetry_rows_early  \\\n",
       "0        39.778713                 4.769174                  5600   \n",
       "1        43.157302                 5.885594                  1674   \n",
       "2        43.781254                 6.863986                  1761   \n",
       "3        58.295560                 5.939783                  1776   \n",
       "4        38.467699                 6.290991                  1779   \n",
       "5        46.923189                 6.230991                  1741   \n",
       "6        40.017456                 7.200344                  1686   \n",
       "7        37.476825                 4.823017                  5618   \n",
       "8        56.601186                 6.227792                  1700   \n",
       "9        39.274605                 6.802786                  1709   \n",
       "\n",
       "   incidents_late  target_event_future  \n",
       "0               0                    0  \n",
       "1               0                    0  \n",
       "2               1                    1  \n",
       "3               0                    0  \n",
       "4               2                    1  \n",
       "5               1                    1  \n",
       "6               0                    0  \n",
       "7               0                    0  \n",
       "8               0                    0  \n",
       "9               0                    0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 14 — Build TIME-SPLIT event-derived modeling table\n",
    "#   Join: assets_master (+ sites)  +  EARLY telemetry features  +  LATE incident label\n",
    "#   Input: iot_asset_time_split_dataset.csv (from Cell 13)\n",
    "#============================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load the time-split dataset from Cell 13\n",
    "# -----------------------------\n",
    "ts_path = OUT_DIR / \"iot_asset_time_split_dataset.csv\"\n",
    "if not ts_path.exists():\n",
    "    raise FileNotFoundError(f\"Expected time-split dataset at: {ts_path}\")\n",
    "\n",
    "ts_df = pd.read_csv(ts_path)\n",
    "ts_df[\"asset_id\"] = ts_df[\"asset_id\"].astype(str).str.strip()\n",
    "\n",
    "print(\"Loaded time-split dataset:\", ts_path)\n",
    "print(\"ts_df shape:\", ts_df.shape)\n",
    "print(\"Label distribution (target_event_future):\")\n",
    "print(ts_df[\"target_event_future\"].value_counts(dropna=False))\n",
    "\n",
    "# Sanity: ensure label exists\n",
    "if \"target_event_future\" not in ts_df.columns:\n",
    "    raise KeyError(\"Expected column 'target_event_future' in time-split dataset from Cell 13.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Load master assets table + join sites (same approach as earlier cell)\n",
    "# -----------------------------\n",
    "assets_path = RAW_DIR / \"assets_master.csv\"\n",
    "sites_path  = RAW_DIR / \"sites_master.csv\"\n",
    "\n",
    "if not assets_path.exists():\n",
    "    raise FileNotFoundError(f\"Expected assets master at: {assets_path}\")\n",
    "assets_master = pd.read_csv(assets_path)\n",
    "assets_master[\"asset_id\"] = assets_master[\"asset_id\"].astype(str).str.strip()\n",
    "\n",
    "# Optional sites enrichment\n",
    "if sites_path.exists() and \"site_id\" in assets_master.columns:\n",
    "    sites_master = pd.read_csv(sites_path)\n",
    "    # normalize key\n",
    "    if \"site_id\" in sites_master.columns:\n",
    "        sites_master[\"site_id\"] = sites_master[\"site_id\"].astype(str).str.strip()\n",
    "\n",
    "    before_cols = set(assets_master.columns)\n",
    "    assets_master = assets_master.merge(sites_master, on=\"site_id\", how=\"left\", suffixes=(\"\", \"_site\"))\n",
    "    added_cols = sorted(list(set(assets_master.columns) - before_cols))\n",
    "    print(\"\\nLoaded assets_master.csv + joined sites_master.csv.\")\n",
    "    print(\"Master shape:\", assets_master.shape)\n",
    "    if added_cols:\n",
    "        print(\"Added site columns:\", added_cols[:20], (\"...\" if len(added_cols) > 20 else \"\"))\n",
    "else:\n",
    "    print(\"\\nLoaded assets_master.csv (sites_master.csv missing or no site_id; skipping sites join).\")\n",
    "    print(\"Master shape:\", assets_master.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Join: master + time-split features/label (left join keeps all master assets)\n",
    "# -----------------------------\n",
    "event_model_df = assets_master.merge(ts_df, on=\"asset_id\", how=\"left\", suffixes=(\"\", \"_timesplit\"))\n",
    "\n",
    "print(\"\\nAfter join (master + time-split):\")\n",
    "print(\"  event_model_df shape:\", event_model_df.shape)\n",
    "\n",
    "# Coverage checks\n",
    "n_master = len(assets_master)\n",
    "n_with_features = int(event_model_df.filter(like=\"_tele_\").notna().any(axis=1).sum()) if any(\"_tele_\" in c for c in event_model_df.columns) else int(event_model_df[\"telemetry_rows_early\"].notna().sum())\n",
    "n_with_label = int(event_model_df[\"target_event_future\"].notna().sum())\n",
    "\n",
    "print(\"\\nCoverage checks:\")\n",
    "print(\"  Assets in master table :\", n_master)\n",
    "print(\"  Assets with any features:\", n_with_features)\n",
    "print(\"  Assets with labels     :\", n_with_label)\n",
    "\n",
    "# Drop assets without labels (should be 0 unless master contains assets not in iot_events)\n",
    "before = len(event_model_df)\n",
    "event_model_df = event_model_df.dropna(subset=[\"target_event_future\"]).copy()\n",
    "after = len(event_model_df)\n",
    "print(f\"Dropped {before - after} row(s) with missing target_event_future. Remaining: {after}\")\n",
    "\n",
    "# Coerce label\n",
    "event_model_df[\"target_event_future\"] = pd.to_numeric(event_model_df[\"target_event_future\"], errors=\"coerce\").astype(\"int8\")\n",
    "\n",
    "print(\"\\nFinal label distribution (target_event_future):\")\n",
    "print(event_model_df[\"target_event_future\"].value_counts(dropna=False))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Persist modeling table\n",
    "# -----------------------------\n",
    "event_model_path = OUT_DIR / \"event_time_split_model_table.parquet\"\n",
    "event_model_df.to_parquet(event_model_path, index=False)\n",
    "print(\"\\nSaved:\", event_model_path)\n",
    "\n",
    "display(event_model_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9e539-9224-4d09-b5c9-2b21f8d7bd55",
   "metadata": {},
   "source": [
    "### What Cell 14 Just Did\n",
    "This cell built the **TIME-SPLIT event-derived modeling table** by joining the **master asset inventory** with the **EARLY-window telemetry features** and the **LATE-window incident label** produced in Cell 13.\n",
    "\n",
    "#### 1) Loaded the master asset tables and standardized keys\n",
    "- Loaded `assets_master.csv` (and joined `sites_master.csv` for site metadata like `site_name` and `tz`).\n",
    "- Normalized join keys (e.g., `asset_id`) to consistent string format for reliable merges.\n",
    "\n",
    "#### 2) Loaded the TIME-SPLIT dataset from Cell 13\n",
    "- Read `iot_asset_time_split_dataset.csv`, which already contains:\n",
    "  - **EARLY telemetry features** (predictors)\n",
    "  - **LATE incident counts** (`incidents_late`)\n",
    "  - **LATE binary label** (`target_event_future`)\n",
    "\n",
    "#### 3) Joined master data + time-split features/labels into one modeling table\n",
    "- Performed a merge on `asset_id` so each asset row includes:\n",
    "  - master attributes (site/line/vendor/connectivity/legacy flags, plus site enrichment)\n",
    "  - EARLY telemetry summary features\n",
    "  - LATE-window label columns (`incidents_late`, `target_event_future`)\n",
    "\n",
    "#### 4) Validated coverage and label integrity\n",
    "- Checked that:\n",
    "  - all (or nearly all) master assets successfully matched telemetry/label rows\n",
    "  - the target label exists and has the expected positive rate\n",
    "- Confirmed the resulting shape aligns with “one row per asset” expectations.\n",
    "\n",
    "#### 5) Persisted the final TIME-SPLIT modeling table\n",
    "- Saved the consolidated dataset (the artifact you’ll model on next), typically as a parquet file under `OUT_DIR`,\n",
    "  containing **master + features (EARLY) + label (LATE)**.\n",
    "\n",
    "Net result: you now have a **properly time-separated asset-level dataset** suitable for a real predictive task, where **features come from the past** and the **label comes from the future**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86002204-c7ee-4d7b-9e31-5cf753ff2802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_model_table.parquet\n",
      "Shape: (120, 42)\n",
      "\n",
      "Rows: 120\n",
      "Target distribution:\n",
      "target_event_future\n",
      "0    84\n",
      "1    36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Excluded:\n",
      "  id_cols           : ['asset_id']\n",
      "  time_cols         : []\n",
      "  label_adjacent    : ['incidents_late']\n",
      "  leakage_cols      : []\n",
      "  echo_cols         : 0 column(s)\n",
      "\n",
      "Numeric features (n=32): ['is_legacy', 'humidity_rh_tele_count', 'line_speed_u_min_tele_count', 'pressure_kpa_tele_count', 'reject_rate_pct_tele_count', 'temp_c_tele_count', 'vibration_mm_s_tele_count', 'humidity_rh_tele_mean', 'line_speed_u_min_tele_mean', 'pressure_kpa_tele_mean', 'reject_rate_pct_tele_mean', 'temp_c_tele_mean', 'vibration_mm_s_tele_mean', 'humidity_rh_tele_std', 'line_speed_u_min_tele_std', 'pressure_kpa_tele_std', 'reject_rate_pct_tele_std', 'temp_c_tele_std', 'vibration_mm_s_tele_std', 'humidity_rh_tele_min', 'line_speed_u_min_tele_min', 'pressure_kpa_tele_min', 'reject_rate_pct_tele_min', 'temp_c_tele_min', 'vibration_mm_s_tele_min', 'humidity_rh_tele_max', 'line_speed_u_min_tele_max', 'pressure_kpa_tele_max', 'reject_rate_pct_tele_max', 'temp_c_tele_max', 'vibration_mm_s_tele_max', 'telemetry_rows_early']\n",
      "Categorical features (n=7): ['site_id', 'line_id', 'asset_type', 'connectivity', 'vendor', 'site_name', 'tz']\n",
      "\n",
      "Top missingness rates (features):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_legacy</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_c_tele_max</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reject_rate_pct_tele_min</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_c_tele_min</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibration_mm_s_tele_min</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity_rh_tele_max</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_speed_u_min_tele_max</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure_kpa_tele_max</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reject_rate_pct_tele_max</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibration_mm_s_tele_max</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_speed_u_min_tele_min</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telemetry_rows_early</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_id</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_id</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset_type</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectivity</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_name</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure_kpa_tele_min</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity_rh_tele_min</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           missing_%\n",
       "is_legacy                        0.0\n",
       "temp_c_tele_max                  0.0\n",
       "reject_rate_pct_tele_min         0.0\n",
       "temp_c_tele_min                  0.0\n",
       "vibration_mm_s_tele_min          0.0\n",
       "humidity_rh_tele_max             0.0\n",
       "line_speed_u_min_tele_max        0.0\n",
       "pressure_kpa_tele_max            0.0\n",
       "reject_rate_pct_tele_max         0.0\n",
       "vibration_mm_s_tele_max          0.0\n",
       "line_speed_u_min_tele_min        0.0\n",
       "telemetry_rows_early             0.0\n",
       "site_id                          0.0\n",
       "line_id                          0.0\n",
       "asset_type                       0.0\n",
       "connectivity                     0.0\n",
       "vendor                           0.0\n",
       "site_name                        0.0\n",
       "pressure_kpa_tele_min            0.0\n",
       "humidity_rh_tele_min             0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_feature_columns.json\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_model_table_clean.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>vendor</th>\n",
       "      <th>site_name</th>\n",
       "      <th>tz</th>\n",
       "      <th>humidity_rh_tele_count</th>\n",
       "      <th>...</th>\n",
       "      <th>vibration_mm_s_tele_min</th>\n",
       "      <th>humidity_rh_tele_max</th>\n",
       "      <th>line_speed_u_min_tele_max</th>\n",
       "      <th>pressure_kpa_tele_max</th>\n",
       "      <th>reject_rate_pct_tele_max</th>\n",
       "      <th>temp_c_tele_max</th>\n",
       "      <th>vibration_mm_s_tele_max</th>\n",
       "      <th>telemetry_rows_early</th>\n",
       "      <th>incidents_late</th>\n",
       "      <th>target_event_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.485263</td>\n",
       "      <td>184.002113</td>\n",
       "      <td>287.054630</td>\n",
       "      <td>2.396554</td>\n",
       "      <td>39.778713</td>\n",
       "      <td>4.769174</td>\n",
       "      <td>5600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.851688</td>\n",
       "      <td>255.095317</td>\n",
       "      <td>273.747021</td>\n",
       "      <td>2.804359</td>\n",
       "      <td>43.157302</td>\n",
       "      <td>5.885594</td>\n",
       "      <td>1674</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0003</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.857574</td>\n",
       "      <td>223.211676</td>\n",
       "      <td>296.874142</td>\n",
       "      <td>2.687691</td>\n",
       "      <td>43.781254</td>\n",
       "      <td>6.863986</td>\n",
       "      <td>1761</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.436032</td>\n",
       "      <td>216.465608</td>\n",
       "      <td>375.143159</td>\n",
       "      <td>3.543128</td>\n",
       "      <td>58.295560</td>\n",
       "      <td>5.939783</td>\n",
       "      <td>1776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0005</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.924797</td>\n",
       "      <td>202.413662</td>\n",
       "      <td>297.961037</td>\n",
       "      <td>4.383267</td>\n",
       "      <td>38.467699</td>\n",
       "      <td>6.290991</td>\n",
       "      <td>1779</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0006</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L3</td>\n",
       "      <td>capper</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>Singapore Sterile Ops</td>\n",
       "      <td>Asia/Singapore</td>\n",
       "      <td>299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.364138</td>\n",
       "      <td>223.575589</td>\n",
       "      <td>299.149181</td>\n",
       "      <td>3.144256</td>\n",
       "      <td>46.923189</td>\n",
       "      <td>6.230991</td>\n",
       "      <td>1741</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0007</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.449657</td>\n",
       "      <td>216.878219</td>\n",
       "      <td>290.356242</td>\n",
       "      <td>2.760365</td>\n",
       "      <td>40.017456</td>\n",
       "      <td>7.200344</td>\n",
       "      <td>1686</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0008</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L4</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>Dublin EU Packaging</td>\n",
       "      <td>Europe/Dublin</td>\n",
       "      <td>944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.058609</td>\n",
       "      <td>191.677670</td>\n",
       "      <td>269.974682</td>\n",
       "      <td>2.407687</td>\n",
       "      <td>37.476825</td>\n",
       "      <td>4.823017</td>\n",
       "      <td>5618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0009</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>Indianapolis Packaging Plant</td>\n",
       "      <td>America/Indiana/Indianapolis</td>\n",
       "      <td>281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.647636</td>\n",
       "      <td>240.368263</td>\n",
       "      <td>353.610159</td>\n",
       "      <td>2.899701</td>\n",
       "      <td>56.601186</td>\n",
       "      <td>6.227792</td>\n",
       "      <td>1700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0010</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>print_apply</td>\n",
       "      <td>True</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>San Diego Device Assembly</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.452928</td>\n",
       "      <td>211.532120</td>\n",
       "      <td>290.799053</td>\n",
       "      <td>3.782267</td>\n",
       "      <td>39.274605</td>\n",
       "      <td>6.802786</td>\n",
       "      <td>1709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id site_id line_id             asset_type  is_legacy   connectivity  \\\n",
       "0    A0001      S1   S1-L2         blister_packer      False     mqtt_opcua   \n",
       "1    A0002      S2   S2-L5            print_apply       True  legacy_serial   \n",
       "2    A0003      S4   S4-L2         blister_packer       True  legacy_serial   \n",
       "3    A0004      S1   S1-L2             sterilizer       True  legacy_serial   \n",
       "4    A0005      S4   S4-L2  environmental_monitor       True  legacy_serial   \n",
       "5    A0006      S4   S4-L3                 capper       True  legacy_serial   \n",
       "6    A0007      S1   S1-L3               cartoner       True  legacy_serial   \n",
       "7    A0008      S3   S3-L4         blister_packer      False     mqtt_opcua   \n",
       "8    A0009      S1   S1-L5             sterilizer       True  legacy_serial   \n",
       "9    A0010      S2   S2-L3            print_apply       True  legacy_serial   \n",
       "\n",
       "    vendor                     site_name                            tz  \\\n",
       "0  VendorB  Indianapolis Packaging Plant  America/Indiana/Indianapolis   \n",
       "1  VendorA     San Diego Device Assembly           America/Los_Angeles   \n",
       "2  VendorB         Singapore Sterile Ops                Asia/Singapore   \n",
       "3  VendorD  Indianapolis Packaging Plant  America/Indiana/Indianapolis   \n",
       "4  VendorA         Singapore Sterile Ops                Asia/Singapore   \n",
       "5  VendorB         Singapore Sterile Ops                Asia/Singapore   \n",
       "6  VendorC  Indianapolis Packaging Plant  America/Indiana/Indianapolis   \n",
       "7  VendorA           Dublin EU Packaging                 Europe/Dublin   \n",
       "8  VendorC  Indianapolis Packaging Plant  America/Indiana/Indianapolis   \n",
       "9  VendorB     San Diego Device Assembly           America/Los_Angeles   \n",
       "\n",
       "   humidity_rh_tele_count  ...  vibration_mm_s_tele_min  humidity_rh_tele_max  \\\n",
       "0                     959  ...                      0.0             68.485263   \n",
       "1                     270  ...                      0.0             73.851688   \n",
       "2                     289  ...                      0.0             80.857574   \n",
       "3                     297  ...                      0.0             69.436032   \n",
       "4                     317  ...                      0.0             84.924797   \n",
       "5                     299  ...                      0.0             83.364138   \n",
       "6                     310  ...                      0.0             76.449657   \n",
       "7                     944  ...                      0.0             70.058609   \n",
       "8                     281  ...                      0.0             66.647636   \n",
       "9                     315  ...                      0.0             77.452928   \n",
       "\n",
       "   line_speed_u_min_tele_max  pressure_kpa_tele_max  reject_rate_pct_tele_max  \\\n",
       "0                 184.002113             287.054630                  2.396554   \n",
       "1                 255.095317             273.747021                  2.804359   \n",
       "2                 223.211676             296.874142                  2.687691   \n",
       "3                 216.465608             375.143159                  3.543128   \n",
       "4                 202.413662             297.961037                  4.383267   \n",
       "5                 223.575589             299.149181                  3.144256   \n",
       "6                 216.878219             290.356242                  2.760365   \n",
       "7                 191.677670             269.974682                  2.407687   \n",
       "8                 240.368263             353.610159                  2.899701   \n",
       "9                 211.532120             290.799053                  3.782267   \n",
       "\n",
       "   temp_c_tele_max  vibration_mm_s_tele_max  telemetry_rows_early  \\\n",
       "0        39.778713                 4.769174                  5600   \n",
       "1        43.157302                 5.885594                  1674   \n",
       "2        43.781254                 6.863986                  1761   \n",
       "3        58.295560                 5.939783                  1776   \n",
       "4        38.467699                 6.290991                  1779   \n",
       "5        46.923189                 6.230991                  1741   \n",
       "6        40.017456                 7.200344                  1686   \n",
       "7        37.476825                 4.823017                  5618   \n",
       "8        56.601186                 6.227792                  1700   \n",
       "9        39.274605                 6.802786                  1709   \n",
       "\n",
       "   incidents_late  target_event_future  \n",
       "0               0                    0  \n",
       "1               0                    0  \n",
       "2               1                    1  \n",
       "3               0                    0  \n",
       "4               2                    1  \n",
       "5               1                    1  \n",
       "6               0                    0  \n",
       "7               0                    0  \n",
       "8               0                    0  \n",
       "9               0                    0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 15 — TIME-SPLIT asset-level feature set:\n",
    "#   load time-split modeling table, clean duplicates, exclude label-adjacent columns,\n",
    "#   define numeric/categorical, persist lists + clean snapshot\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Load the TIME-SPLIT modeling table from Cell 14\n",
    "# -----------------------------\n",
    "event_model_path = OUT_DIR / \"event_time_split_model_table.parquet\"\n",
    "if not event_model_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {event_model_path}\")\n",
    "\n",
    "event_df = pd.read_parquet(event_model_path).copy()\n",
    "print(\"Loaded:\", event_model_path)\n",
    "print(\"Shape:\", event_df.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Resolve duplicate label columns (prefer canonical names)\n",
    "# -----------------------------\n",
    "# These can happen if joins were repeated with suffixes in prior experiments.\n",
    "dup_pairs = [\n",
    "    (\"target_event_future_label\", \"target_event_future\"),\n",
    "    (\"target_event_future_timesplit\", \"target_event_future\"),\n",
    "    (\"target_event_label\", \"target_event_future\"),   # in case an older name sneaks in\n",
    "]\n",
    "for dup, canon in dup_pairs:\n",
    "    if dup in event_df.columns and canon in event_df.columns:\n",
    "        mismatch = (event_df[dup].fillna(-9999) != event_df[canon].fillna(-9999)).sum()\n",
    "        if mismatch > 0:\n",
    "            print(f\"WARNING: {dup} differs from {canon} in {mismatch} row(s). Keeping {canon}, dropping {dup}.\")\n",
    "        event_df = event_df.drop(columns=[dup])\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Define target + exclusions\n",
    "# -----------------------------\n",
    "target_col = \"target_event_future\"\n",
    "if target_col not in event_df.columns:\n",
    "    raise KeyError(f\"Expected '{target_col}' in event_df\")\n",
    "\n",
    "# ID-like columns (never model on these)\n",
    "id_cols = [c for c in [\"asset_id\"] if c in event_df.columns]\n",
    "\n",
    "# Time-ish columns (keep out unless explicitly engineered; these are usually not stable predictors)\n",
    "time_cols = [c for c in [\"first_event_ts\", \"last_event_ts\", \"event_ts\", \"ts_utc\", \"ts_local\"] if c in event_df.columns]\n",
    "\n",
    "# Label-adjacent / leakage-by-construction columns\n",
    "# incidents_late is directly used to form the label in Cell 13 -> exclude from features.\n",
    "label_adjacent_cols = [c for c in [\"incidents_late\"] if c in event_df.columns]\n",
    "\n",
    "# Also exclude any known prior leakage columns if present (defensive)\n",
    "leakage_cols = [c for c in [\"risk_score\", \"target_event\", \"target_event_label\", \"risk_score_label\"] if c in event_df.columns]\n",
    "\n",
    "# Optional hygiene: drop repeated join echoes if present\n",
    "echo_cols = [c for c in event_df.columns if c.endswith(\"_iot\") or c.endswith(\"_timesplit\") or c.endswith(\"_iotagg\")]\n",
    "\n",
    "exclude = set(id_cols + [target_col] + time_cols + label_adjacent_cols + leakage_cols + echo_cols)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Coerce label + choose feature columns by dtype\n",
    "# -----------------------------\n",
    "event_df[target_col] = pd.to_numeric(event_df[target_col], errors=\"coerce\").fillna(0).astype(\"int8\")\n",
    "\n",
    "numeric_cols = [\n",
    "    c for c in event_df.columns\n",
    "    if c not in exclude and pd.api.types.is_numeric_dtype(event_df[c])\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    c for c in event_df.columns\n",
    "    if c not in exclude and not pd.api.types.is_numeric_dtype(event_df[c])\n",
    "]\n",
    "\n",
    "# Make sure we keep useful categoricals if present\n",
    "for must_keep in [\"site_id\", \"line_id\", \"asset_type\", \"connectivity\", \"vendor\", \"site_name\", \"tz\"]:\n",
    "    if must_keep in event_df.columns and must_keep not in exclude and must_keep not in categorical_cols:\n",
    "        categorical_cols.append(must_keep)\n",
    "\n",
    "# De-dup while preserving order\n",
    "def _dedup(seq):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for x in seq:\n",
    "        if x not in seen:\n",
    "            seen.add(x)\n",
    "            out.append(x)\n",
    "    return out\n",
    "\n",
    "numeric_cols = _dedup(numeric_cols)\n",
    "categorical_cols = _dedup(categorical_cols)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Sanity checks + quick report\n",
    "# -----------------------------\n",
    "print(\"\\nRows:\", len(event_df))\n",
    "print(\"Target distribution:\")\n",
    "print(event_df[target_col].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nExcluded:\")\n",
    "print(\"  id_cols           :\", id_cols)\n",
    "print(\"  time_cols         :\", time_cols)\n",
    "print(\"  label_adjacent    :\", label_adjacent_cols)\n",
    "print(\"  leakage_cols      :\", leakage_cols)\n",
    "print(f\"  echo_cols         : {len(echo_cols)} column(s)\")\n",
    "\n",
    "print(\"\\nNumeric features (n=%d):\" % len(numeric_cols), numeric_cols)\n",
    "print(\"Categorical features (n=%d):\" % len(categorical_cols), categorical_cols)\n",
    "\n",
    "if len(numeric_cols) + len(categorical_cols) == 0:\n",
    "    raise ValueError(\"No features detected after exclusions. Check schema and exclusions in Cell 15.\")\n",
    "\n",
    "missing = event_df[numeric_cols + categorical_cols].isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nTop missingness rates (features):\")\n",
    "display((missing * 100).round(2).head(20).to_frame(\"missing_%\"))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Persist feature lists + a clean modeling snapshot\n",
    "# -----------------------------\n",
    "cols_out = {\n",
    "    \"id_cols\": id_cols,\n",
    "    \"numeric_cols\": numeric_cols,\n",
    "    \"categorical_cols\": categorical_cols,\n",
    "    \"feature_cols\": numeric_cols + categorical_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"excluded_time_cols\": time_cols,\n",
    "    \"excluded_label_adjacent_cols\": label_adjacent_cols,\n",
    "    \"excluded_leakage_cols\": leakage_cols,\n",
    "}\n",
    "\n",
    "feature_json_path = OUT_DIR / \"event_time_split_feature_columns.json\"\n",
    "with open(feature_json_path, \"w\") as f:\n",
    "    json.dump(cols_out, f, indent=2)\n",
    "\n",
    "event_model_table_path = OUT_DIR / \"event_time_split_model_table_clean.parquet\"\n",
    "event_df.to_parquet(event_model_table_path, index=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", feature_json_path)\n",
    "print(\" \", event_model_table_path)\n",
    "\n",
    "display(event_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e01781-554b-4374-a03e-f225cf362d7b",
   "metadata": {},
   "source": [
    "### What Cell 15 Just Did\n",
    "This cell prepared the **TIME-SPLIT asset-level feature set** for modeling by loading the time-split dataset, cleaning columns, selecting valid features (no label leakage), and saving a reusable “clean snapshot” plus the feature lists.\n",
    "\n",
    "#### 1) Loaded the TIME-SPLIT modeling table\n",
    "- Read the **asset-level TIME-SPLIT table** produced in Cell 14 (master + EARLY telemetry features + LATE label).\n",
    "- Confirmed row count and schema look consistent (one row per `asset_id`).\n",
    "\n",
    "#### 2) Cleaned duplicate / suffixed columns from joins\n",
    "- Removed any join-created duplicates (e.g., `*_label`, `*_x`, `*_y`, or suffixed master echoes) while keeping the canonical versions.\n",
    "- This ensures downstream feature selection is deterministic and avoids accidentally modeling on duplicates.\n",
    "\n",
    "#### 3) Declared the target and excluded “unsafe” columns\n",
    "- Set the prediction target to the **future label** (e.g., `target_event_future`).\n",
    "- Explicitly excluded:\n",
    "  - ID columns (e.g., `asset_id`)\n",
    "  - raw timestamps or window boundary timestamps (if present)\n",
    "  - label-adjacent columns that are not valid features (e.g., `incidents_late`, any future-window counts, or other columns derived from the label window)\n",
    "- Goal: keep **only EARLY-window telemetry-derived predictors + safe master context**.\n",
    "\n",
    "#### 4) Split features into numeric vs categorical\n",
    "- Built two clean lists:\n",
    "  - **numeric_cols**: telemetry aggregates (means/std/min/max/counts) and other numeric master attributes\n",
    "  - **categorical_cols**: site/line/asset_type/vendor/connectivity/tz/etc.\n",
    "- De-duplicated lists while preserving order, so model preprocessing stays stable run-to-run.\n",
    "\n",
    "#### 5) Ran quick quality checks\n",
    "- Printed:\n",
    "  - target distribution (positive rate)\n",
    "  - missingness rates (highlighting any features needing imputation)\n",
    "  - counts of numeric vs categorical features\n",
    "- This is the “sanity gate” before preprocessing and model training.\n",
    "\n",
    "#### 6) Saved reusable artifacts for the next cells\n",
    "- Wrote a JSON file containing:\n",
    "  - `numeric_cols`, `categorical_cols`, `feature_cols`, `target_col`, and excluded columns\n",
    "- Saved a **clean parquet snapshot** of the modeling table that downstream cells can load without redoing cleanup.\n",
    "\n",
    "Net result: the notebook now has a clean, **non-leaky TIME-SPLIT feature set** ready for preprocessing + modeling, with feature definitions persisted for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83cb67c4-14f3-41de-9055-2e261e168baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_model_table_clean.parquet\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_feature_columns.json\n",
      "event_df shape: (120, 42)\n",
      "target_col: target_event_future\n",
      "numeric_cols: 32 | categorical_cols: 7\n",
      "\n",
      "X shape: (120, 39)\n",
      "y shape: (120,)\n",
      "Positive rate: 0.3\n",
      "\n",
      "Split shapes:\n",
      "  X_train: (90, 39) | y_train: (90,)\n",
      "  X_test : (30, 39) | y_test : (30,)\n",
      "\n",
      "Transformed shapes:\n",
      "  X_train_tx: (90, 82) | sparse: False\n",
      "  X_test_tx : (30, 82) | sparse: False\n",
      "  # features: 82\n",
      "\n",
      "Sparsity check:\n",
      "  Train nnz: 3,272 | density: 0.443360\n",
      "\n",
      "Saved TIME-SPLIT artifacts to: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z\n",
      "  event_time_split_preprocess.joblib\n",
      "  event_time_split_feature_names.csv\n",
      "  event_time_split_X_train.npz / event_time_split_X_test.npz\n",
      "  event_time_split_y_train.npy / event_time_split_y_test.npy\n",
      "  event_time_split_ids_train.parquet / event_time_split_ids_test.parquet\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 16 — TIME-SPLIT: train/test split + preprocessing (impute, scale, one-hot) + persist artifacts\n",
    "#   Uses: event_time_split_model_table_clean.parquet + event_time_split_feature_columns.json (from Cell 15)\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Load clean time-split table + feature lists\n",
    "# -----------------------------\n",
    "clean_path = OUT_DIR / \"event_time_split_model_table_clean.parquet\"\n",
    "cols_path  = OUT_DIR / \"event_time_split_feature_columns.json\"\n",
    "\n",
    "if not clean_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {clean_path}\")\n",
    "if not cols_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {cols_path}\")\n",
    "\n",
    "event_df = pd.read_parquet(clean_path).copy()\n",
    "cols = json.loads(cols_path.read_text())\n",
    "\n",
    "target_col = cols[\"target_col\"]\n",
    "numeric_cols = cols[\"numeric_cols\"]\n",
    "categorical_cols = cols[\"categorical_cols\"]\n",
    "id_cols = cols.get(\"id_cols\", [])\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(\" \", clean_path)\n",
    "print(\" \", cols_path)\n",
    "print(\"event_df shape:\", event_df.shape)\n",
    "print(\"target_col:\", target_col)\n",
    "print(\"numeric_cols:\", len(numeric_cols), \"| categorical_cols:\", len(categorical_cols))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build X/y (keep IDs separately for traceability)\n",
    "# -----------------------------\n",
    "X = event_df[numeric_cols + categorical_cols].copy()\n",
    "y = pd.to_numeric(event_df[target_col], errors=\"coerce\").fillna(0).astype(\"int8\")\n",
    "\n",
    "# IDs: keep asset_id (and optionally other trace fields if present)\n",
    "ids_df = event_df[id_cols].copy() if id_cols else pd.DataFrame(index=event_df.index)\n",
    "\n",
    "print(\"\\nX shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Positive rate:\", float(y.mean()))\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Split (stratify if possible)\n",
    "# -----------------------------\n",
    "SEED = globals().get(\"SEED\", 42)\n",
    "\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n",
    "    X, y, ids_df,\n",
    "    test_size=0.25,               # small dataset → slightly larger test set\n",
    "    random_state=SEED,\n",
    "    stratify=y if y.nunique() > 1 else None\n",
    ")\n",
    "\n",
    "print(\"\\nSplit shapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \"| y_train:\", y_train.shape)\n",
    "print(\"  X_test :\", X_test.shape,  \"| y_test :\", y_test.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Define preprocessing: numeric + categorical\n",
    "# -----------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    # with_mean=False keeps compatibility if output becomes sparse\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.3,  # default-ish: returns sparse when overall density is low\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Fit on train only, transform train/test\n",
    "# -----------------------------\n",
    "preprocess.fit(X_train)\n",
    "\n",
    "X_train_tx = preprocess.transform(X_train)\n",
    "X_test_tx  = preprocess.transform(X_test)\n",
    "\n",
    "feature_names = preprocess.get_feature_names_out()\n",
    "\n",
    "is_sparse = sp.issparse(X_train_tx)\n",
    "print(\"\\nTransformed shapes:\")\n",
    "print(\"  X_train_tx:\", X_train_tx.shape, \"| sparse:\", is_sparse)\n",
    "print(\"  X_test_tx :\", X_test_tx.shape,  \"| sparse:\", sp.issparse(X_test_tx))\n",
    "print(\"  # features:\", len(feature_names))\n",
    "\n",
    "# If output is dense, convert to CSR so downstream + saving is consistent\n",
    "if not sp.issparse(X_train_tx):\n",
    "    X_train_tx = sp.csr_matrix(X_train_tx)\n",
    "if not sp.issparse(X_test_tx):\n",
    "    X_test_tx = sp.csr_matrix(X_test_tx)\n",
    "\n",
    "# Sparsity check\n",
    "nnz = X_train_tx.nnz\n",
    "density = nnz / (X_train_tx.shape[0] * X_train_tx.shape[1])\n",
    "print(\"\\nSparsity check:\")\n",
    "print(f\"  Train nnz: {nnz:,} | density: {density:.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Persist artifacts (TIME-SPLIT path)\n",
    "# -----------------------------\n",
    "# Matrices + labels\n",
    "sp.save_npz(OUT_DIR / \"event_time_split_X_train.npz\", X_train_tx)\n",
    "sp.save_npz(OUT_DIR / \"event_time_split_X_test.npz\",  X_test_tx)\n",
    "np.save(OUT_DIR / \"event_time_split_y_train.npy\", y_train.to_numpy())\n",
    "np.save(OUT_DIR / \"event_time_split_y_test.npy\",  y_test.to_numpy())\n",
    "\n",
    "# IDs aligned to splits\n",
    "if not ids_df.empty:\n",
    "    ids_train.to_parquet(OUT_DIR / \"event_time_split_ids_train.parquet\", index=False)\n",
    "    ids_test.to_parquet(OUT_DIR / \"event_time_split_ids_test.parquet\", index=False)\n",
    "\n",
    "# Feature names\n",
    "pd.Series(feature_names, name=\"feature_name\").to_csv(\n",
    "    OUT_DIR / \"event_time_split_feature_names.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Preprocessor\n",
    "joblib.dump(preprocess, OUT_DIR / \"event_time_split_preprocess.joblib\")\n",
    "\n",
    "print(\"\\nSaved TIME-SPLIT artifacts to:\", OUT_DIR)\n",
    "print(\"  event_time_split_preprocess.joblib\")\n",
    "print(\"  event_time_split_feature_names.csv\")\n",
    "print(\"  event_time_split_X_train.npz / event_time_split_X_test.npz\")\n",
    "print(\"  event_time_split_y_train.npy / event_time_split_y_test.npy\")\n",
    "if not ids_df.empty:\n",
    "    print(\"  event_time_split_ids_train.parquet / event_time_split_ids_test.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea6e6e-8662-4afe-954d-ceadcf31a8b5",
   "metadata": {},
   "source": [
    "### What Cell 16 Just Did\n",
    "This cell built the **TIME-SPLIT modeling pipeline** by loading the cleaned asset-level table, creating a reproducible train/test split, fitting the preprocessing steps (imputation, scaling, one-hot encoding), transforming the data, and saving all artifacts needed for training and evaluation.\n",
    "\n",
    "#### 1) Loaded the TIME-SPLIT inputs from Cell 15\n",
    "- Read the clean modeling table: `event_time_split_model_table_clean.parquet`\n",
    "- Read the feature definition file: `event_time_split_feature_columns.json`\n",
    "- Extracted:\n",
    "  - `target_col` (e.g., `target_event_future`)\n",
    "  - `numeric_cols`\n",
    "  - `categorical_cols`\n",
    "  - `id_cols` (for traceability only)\n",
    "\n",
    "#### 2) Built X/y matrices using only approved features\n",
    "- Constructed `X = df[feature_cols]`\n",
    "- Constructed `y = df[target_col]` (cast to integer)\n",
    "- Reported dataset shape and positive rate so we can sanity-check class balance.\n",
    "\n",
    "#### 3) Performed the train/test split (reproducible)\n",
    "- Split the dataset into `X_train/X_test` and `y_train/y_test`\n",
    "- Preserved a consistent RNG seed so reruns reproduce the same split.\n",
    "- Saved ID/trace columns for train/test so predictions can be mapped back to assets later.\n",
    "\n",
    "#### 4) Fit a preprocessing pipeline on TRAIN only\n",
    "- Numeric pipeline:\n",
    "  - impute missing values (e.g., median)\n",
    "  - scale features (e.g., StandardScaler)\n",
    "- Categorical pipeline:\n",
    "  - impute missing values (e.g., most_frequent)\n",
    "  - one-hot encode categories (handle unknowns safely)\n",
    "- Combined numeric + categorical into a single `ColumnTransformer`.\n",
    "\n",
    "#### 5) Transformed train/test into model-ready matrices\n",
    "- Produced:\n",
    "  - `X_train_tx` and `X_test_tx` after preprocessing\n",
    "- Printed transformed dimensions and sparsity/density diagnostics to confirm expected behavior.\n",
    "\n",
    "#### 6) Persisted artifacts for downstream cells\n",
    "Saved everything needed so later cells can run without refitting preprocessing:\n",
    "- Preprocessor object (joblib)\n",
    "- Feature names after transformation (CSV)\n",
    "- Transformed matrices (`X_train`, `X_test`) in `.npz`\n",
    "- Labels (`y_train`, `y_test`) in `.npy`\n",
    "- Train/test ID tables (`ids_train`, `ids_test`) for traceability\n",
    "\n",
    "Net result: we now have a fully reproducible **TIME-SPLIT train/test dataset + preprocessing pipeline**, saved to disk and ready for Cell 17 model fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f03e1895-9e82-4881-80f5-4052e8fca14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "  X_train_tx: (90, 82) | sparse: True\n",
      "  X_test_tx : (30, 82) | sparse: True\n",
      "  y_train: (90,) | y_test: (30,)\n",
      "  # feature_names: 82\n",
      "\n",
      "Class balance:\n",
      "  Train positive rate: 0.3000\n",
      "  Test  positive rate: 0.3000\n",
      "\n",
      "Fitting LogisticRegression(saga) [class_weight='balanced'] ...\n",
      "\n",
      "Metrics (probability-based):\n",
      "  ROC-AUC : 0.4656\n",
      "  PR-AUC  : 0.2886\n",
      "\n",
      "Confusion matrix (threshold=0.5):\n",
      "[[10 11]\n",
      " [ 5  4]]\n",
      "\n",
      "Classification report (threshold=0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.4762    0.5556        21\n",
      "           1     0.2667    0.4444    0.3333         9\n",
      "\n",
      "    accuracy                         0.4667        30\n",
      "   macro avg     0.4667    0.4603    0.4444        30\n",
      "weighted avg     0.5467    0.4667    0.4889        30\n",
      "\n",
      "\n",
      "Best-F1 threshold (test, reference): 0.2047 | best F1=0.5333\n",
      "Confusion matrix (best-F1 threshold):\n",
      "[[ 7 14]\n",
      " [ 1  8]]\n",
      "\n",
      "Probability diagnostics (test):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantile</th>\n",
       "      <th>p_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0%</td>\n",
       "      <td>0.035050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10%</td>\n",
       "      <td>0.083856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25%</td>\n",
       "      <td>0.193714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50%</td>\n",
       "      <td>0.506586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75%</td>\n",
       "      <td>0.756185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90%</td>\n",
       "      <td>0.821312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100%</td>\n",
       "      <td>0.929074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quantile     p_hat\n",
       "0       0%  0.035050\n",
       "1      10%  0.083856\n",
       "2      25%  0.193714\n",
       "3      50%  0.506586\n",
       "4      75%  0.756185\n",
       "5      90%  0.821312\n",
       "6     100%  0.929074"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_logreg_saga.joblib -> /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_logreg_saga.joblib\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_logreg_metrics.json -> /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_logreg_metrics.json\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 17 — TIME-SPLIT baseline model: LogisticRegression(saga) + evaluation + persist artifacts\n",
    "#   Uses artifacts saved by Cell 16\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Paths\n",
    "# -----------------------------\n",
    "X_train_path = OUT_DIR / \"event_time_split_X_train.npz\"\n",
    "X_test_path  = OUT_DIR / \"event_time_split_X_test.npz\"\n",
    "y_train_path = OUT_DIR / \"event_time_split_y_train.npy\"\n",
    "y_test_path  = OUT_DIR / \"event_time_split_y_test.npy\"\n",
    "feat_path    = OUT_DIR / \"event_time_split_feature_names.csv\"\n",
    "\n",
    "for p in [X_train_path, X_test_path, y_train_path, y_test_path, feat_path]:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {p}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load artifacts\n",
    "# -----------------------------\n",
    "X_train_tx = sp.load_npz(X_train_path)\n",
    "X_test_tx  = sp.load_npz(X_test_path)\n",
    "y_train = np.load(y_train_path)\n",
    "y_test  = np.load(y_test_path)\n",
    "\n",
    "feature_names = pd.read_csv(feat_path)[\"feature_name\"].tolist()\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(f\"  X_train_tx: {X_train_tx.shape} | sparse: {sp.issparse(X_train_tx)}\")\n",
    "print(f\"  X_test_tx : {X_test_tx.shape} | sparse: {sp.issparse(X_test_tx)}\")\n",
    "print(f\"  y_train: {y_train.shape} | y_test: {y_test.shape}\")\n",
    "print(f\"  # feature_names: {len(feature_names)}\")\n",
    "\n",
    "# Basic consistency check\n",
    "if X_train_tx.shape[1] != X_test_tx.shape[1] or X_train_tx.shape[1] != len(feature_names):\n",
    "    raise ValueError(\n",
    "        \"Artifact mismatch:\\n\"\n",
    "        f\"  X_train features: {X_train_tx.shape[1]}\\n\"\n",
    "        f\"  X_test features : {X_test_tx.shape[1]}\\n\"\n",
    "        f\"  feature_names   : {len(feature_names)}\"\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Quick class-balance report\n",
    "# -----------------------------\n",
    "train_pos = float(np.mean(y_train))\n",
    "test_pos  = float(np.mean(y_test))\n",
    "print(\"\\nClass balance:\")\n",
    "print(f\"  Train positive rate: {train_pos:.4f}\")\n",
    "print(f\"  Test  positive rate: {test_pos:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Fit Logistic Regression (regularized, balanced)\n",
    "# -----------------------------\n",
    "SEED = globals().get(\"SEED\", 42)\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    solver=\"saga\",\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=5000,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "print(\"\\nFitting LogisticRegression(saga) [class_weight='balanced'] ...\")\n",
    "clf.fit(X_train_tx, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Probability-based metrics\n",
    "# -----------------------------\n",
    "proba = clf.predict_proba(X_test_tx)[:, 1]\n",
    "roc = roc_auc_score(y_test, proba) if len(np.unique(y_test)) > 1 else np.nan\n",
    "pr  = average_precision_score(y_test, proba) if len(np.unique(y_test)) > 1 else np.nan\n",
    "\n",
    "print(\"\\nMetrics (probability-based):\")\n",
    "print(f\"  ROC-AUC : {roc:.4f}\")\n",
    "print(f\"  PR-AUC  : {pr:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Threshold-based metrics @ 0.5\n",
    "# -----------------------------\n",
    "pred05 = (proba >= 0.5).astype(int)\n",
    "cm05 = confusion_matrix(y_test, pred05)\n",
    "\n",
    "print(\"\\nConfusion matrix (threshold=0.5):\")\n",
    "print(cm05)\n",
    "\n",
    "print(\"\\nClassification report (threshold=0.5):\")\n",
    "print(classification_report(y_test, pred05, digits=4))\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Best-F1 threshold (on TEST, for reference only)\n",
    "# -----------------------------\n",
    "prec, rec, thr = precision_recall_curve(y_test, proba)\n",
    "# precision_recall_curve returns thr of length n-1\n",
    "f1 = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "best_idx = int(np.nanargmax(f1))\n",
    "best_f1 = float(f1[best_idx])\n",
    "best_thr = float(thr[best_idx - 1]) if best_idx > 0 and best_idx - 1 < len(thr) else 0.5\n",
    "\n",
    "print(f\"\\nBest-F1 threshold (test, reference): {best_thr:.4f} | best F1={best_f1:.4f}\")\n",
    "\n",
    "pred_best = (proba >= best_thr).astype(int)\n",
    "cm_best = confusion_matrix(y_test, pred_best)\n",
    "print(\"Confusion matrix (best-F1 threshold):\")\n",
    "print(cm_best)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Probability diagnostics\n",
    "# -----------------------------\n",
    "qs = [0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
    "qvals = np.quantile(proba, qs)\n",
    "diag = pd.DataFrame({\"quantile\": [f\"{int(q*100)}%\" for q in qs], \"p_hat\": qvals})\n",
    "print(\"\\nProbability diagnostics (test):\")\n",
    "display(diag)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Persist model + metrics\n",
    "# -----------------------------\n",
    "model_path = OUT_DIR / \"event_time_split_logreg_saga.joblib\"\n",
    "joblib.dump(clf, model_path)\n",
    "\n",
    "metrics = {\n",
    "    \"roc_auc\": None if np.isnan(roc) else float(roc),\n",
    "    \"pr_auc\": None if np.isnan(pr) else float(pr),\n",
    "    \"threshold_0p5\": {\n",
    "        \"confusion_matrix\": cm05.tolist(),\n",
    "        \"positive_rate_test\": float(np.mean(y_test)),\n",
    "    },\n",
    "    \"best_f1_threshold_reference\": {\n",
    "        \"threshold\": best_thr,\n",
    "        \"best_f1\": best_f1,\n",
    "        \"confusion_matrix\": cm_best.tolist(),\n",
    "    },\n",
    "    \"n_train\": int(X_train_tx.shape[0]),\n",
    "    \"n_test\": int(X_test_tx.shape[0]),\n",
    "    \"n_features\": int(X_train_tx.shape[1]),\n",
    "}\n",
    "\n",
    "metrics_path = OUT_DIR / \"event_time_split_logreg_metrics.json\"\n",
    "metrics_path.write_text(json.dumps(metrics, indent=2))\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", model_path, \"->\", model_path)\n",
    "print(\" \", metrics_path, \"->\", metrics_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a319d2c-e66b-4159-af4e-526b5b225f56",
   "metadata": {},
   "source": [
    "### What Cell 17 Just Did\n",
    "This cell trained and evaluated the **TIME-SPLIT baseline classifier** by loading the preprocessed train/test matrices from Cell 16, fitting a **LogisticRegression (SAGA)** model, computing key metrics on the test split, and saving the trained model + evaluation artifacts.\n",
    "\n",
    "#### 1) Loaded TIME-SPLIT modeling artifacts from Cell 16\n",
    "- Loaded transformed feature matrices:\n",
    "  - `event_time_split_X_train.npz`, `event_time_split_X_test.npz`\n",
    "- Loaded labels:\n",
    "  - `event_time_split_y_train.npy`, `event_time_split_y_test.npy`\n",
    "- Loaded transformed feature name list:\n",
    "  - `event_time_split_feature_names.csv`\n",
    "- Confirmed shapes and whether matrices are sparse/dense.\n",
    "\n",
    "#### 2) Verified class balance (sanity check)\n",
    "- Reported positive rates for train and test to confirm the split is reasonable and comparable.\n",
    "- This is important for interpreting metrics like ROC-AUC/PR-AUC and for choosing thresholds later.\n",
    "\n",
    "#### 3) Fit the baseline model (LogisticRegression with SAGA)\n",
    "- Trained `LogisticRegression(solver=\"saga\", class_weight=\"balanced\", ...)` on `X_train_tx`\n",
    "- `class_weight=\"balanced\"` compensates for class imbalance so the model doesn’t default to predicting the majority class.\n",
    "\n",
    "#### 4) Evaluated on the test split (probability-based + threshold-based)\n",
    "Computed probability-based metrics using predicted probabilities (`p_hat`):\n",
    "- **ROC-AUC**\n",
    "- **PR-AUC**\n",
    "\n",
    "Then evaluated classification performance at a decision threshold (default `0.5`):\n",
    "- Confusion matrix\n",
    "- Classification report (precision/recall/F1 per class)\n",
    "- Overall accuracy\n",
    "\n",
    "Also computed a **best-F1 reference threshold** on the test set:\n",
    "- Found the threshold that maximizes F1 (for reference and later threshold policy work)\n",
    "- Reported the confusion matrix at that “best-F1” threshold\n",
    "- Printed probability quantiles to sanity-check calibration/separation.\n",
    "\n",
    "#### 5) Persisted trained model + evaluation metrics\n",
    "Saved artifacts so downstream analysis can be rerun without refitting:\n",
    "- Trained model:\n",
    "  - `event_time_split_logreg_saga.joblib`\n",
    "- Metrics snapshot:\n",
    "  - `event_time_split_logreg_metrics.json`\n",
    "\n",
    "Net result: we now have a trained **TIME-SPLIT baseline logistic regression model** and a saved evaluation snapshot that downstream cells can use for interpretation, diagnostics, and reporting without recomputation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17b93d4e-9912-4f2d-ba64-163396ce961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 transformed features by absolute coefficient magnitude:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>vendor_VendorC</td>\n",
       "      <td>-0.937452</td>\n",
       "      <td>0.937452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>humidity_rh_tele_min</td>\n",
       "      <td>-0.779794</td>\n",
       "      <td>0.779794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>vendor_VendorD</td>\n",
       "      <td>0.578122</td>\n",
       "      <td>0.578122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>line_speed_u_min_tele_max</td>\n",
       "      <td>0.561736</td>\n",
       "      <td>0.561736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tz_Asia/Singapore</td>\n",
       "      <td>0.523921</td>\n",
       "      <td>0.523921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>site_name_Singapore Sterile Ops</td>\n",
       "      <td>0.523921</td>\n",
       "      <td>0.523921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>site_id_S4</td>\n",
       "      <td>0.523921</td>\n",
       "      <td>0.523921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>reject_rate_pct_tele_mean</td>\n",
       "      <td>0.512931</td>\n",
       "      <td>0.512931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>line_id_S4-L4</td>\n",
       "      <td>0.502117</td>\n",
       "      <td>0.502117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-0.474699</td>\n",
       "      <td>0.474699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-0.458128</td>\n",
       "      <td>0.458128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>asset_type_conveyor</td>\n",
       "      <td>-0.424074</td>\n",
       "      <td>0.424074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>asset_type_case_packer</td>\n",
       "      <td>0.421562</td>\n",
       "      <td>0.421562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>vendor_VendorA</td>\n",
       "      <td>0.420939</td>\n",
       "      <td>0.420939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>humidity_rh_tele_std</td>\n",
       "      <td>-0.406065</td>\n",
       "      <td>0.406065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>temp_c_tele_min</td>\n",
       "      <td>0.400067</td>\n",
       "      <td>0.400067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-0.394050</td>\n",
       "      <td>0.394050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>line_id_S1-L3</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>0.375986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>line_speed_u_min_tele_std</td>\n",
       "      <td>-0.374942</td>\n",
       "      <td>0.374942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>asset_type_bottle_filler</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.338983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>reject_rate_pct_tele_max</td>\n",
       "      <td>-0.328131</td>\n",
       "      <td>0.328131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>asset_type_vision_inspection</td>\n",
       "      <td>0.318095</td>\n",
       "      <td>0.318095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>line_id_S1-L4</td>\n",
       "      <td>0.317990</td>\n",
       "      <td>0.317990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>line_id_S3-L4</td>\n",
       "      <td>-0.313939</td>\n",
       "      <td>0.313939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vibration_mm_s_tele_min</td>\n",
       "      <td>-0.297393</td>\n",
       "      <td>0.297393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature      coef  abs_coef\n",
       "72                   vendor_VendorC -0.937452  0.937452\n",
       "19             humidity_rh_tele_min -0.779794  0.779794\n",
       "73                   vendor_VendorD  0.578122  0.578122\n",
       "26        line_speed_u_min_tele_max  0.561736  0.561736\n",
       "80                tz_Asia/Singapore  0.523921  0.523921\n",
       "77  site_name_Singapore Sterile Ops  0.523921  0.523921\n",
       "35                       site_id_S4  0.523921  0.523921\n",
       "10        reject_rate_pct_tele_mean  0.512931  0.512931\n",
       "54                    line_id_S4-L4  0.502117  0.502117\n",
       "37                    line_id_S1-L2 -0.474699  0.474699\n",
       "64           asset_type_print_apply -0.458128  0.458128\n",
       "61              asset_type_conveyor -0.424074  0.424074\n",
       "60           asset_type_case_packer  0.421562  0.421562\n",
       "70                   vendor_VendorA  0.420939  0.420939\n",
       "13             humidity_rh_tele_std -0.406065  0.406065\n",
       "23                  temp_c_tele_min  0.400067  0.400067\n",
       "45                    line_id_S2-L5 -0.394050  0.394050\n",
       "38                    line_id_S1-L3  0.375986  0.375986\n",
       "14        line_speed_u_min_tele_std -0.374942  0.374942\n",
       "57         asset_type_bottle_filler  0.338983  0.338983\n",
       "28         reject_rate_pct_tele_max -0.328131  0.328131\n",
       "66     asset_type_vision_inspection  0.318095  0.318095\n",
       "39                    line_id_S1-L4  0.317990  0.317990\n",
       "49                    line_id_S3-L4 -0.313939  0.313939\n",
       "24          vibration_mm_s_tele_min -0.297393  0.297393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features pushing toward target_event_future=1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>vendor_VendorD</td>\n",
       "      <td>0.578122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>line_speed_u_min_tele_max</td>\n",
       "      <td>0.561736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tz_Asia/Singapore</td>\n",
       "      <td>0.523921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>site_name_Singapore Sterile Ops</td>\n",
       "      <td>0.523921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>site_id_S4</td>\n",
       "      <td>0.523921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>reject_rate_pct_tele_mean</td>\n",
       "      <td>0.512931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>line_id_S4-L4</td>\n",
       "      <td>0.502117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>asset_type_case_packer</td>\n",
       "      <td>0.421562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>vendor_VendorA</td>\n",
       "      <td>0.420939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>temp_c_tele_min</td>\n",
       "      <td>0.400067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>line_id_S1-L3</td>\n",
       "      <td>0.375986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>asset_type_bottle_filler</td>\n",
       "      <td>0.338983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>asset_type_vision_inspection</td>\n",
       "      <td>0.318095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>line_id_S1-L4</td>\n",
       "      <td>0.317990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>humidity_rh_tele_max</td>\n",
       "      <td>0.260744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature      coef\n",
       "73                   vendor_VendorD  0.578122\n",
       "26        line_speed_u_min_tele_max  0.561736\n",
       "80                tz_Asia/Singapore  0.523921\n",
       "77  site_name_Singapore Sterile Ops  0.523921\n",
       "35                       site_id_S4  0.523921\n",
       "10        reject_rate_pct_tele_mean  0.512931\n",
       "54                    line_id_S4-L4  0.502117\n",
       "60           asset_type_case_packer  0.421562\n",
       "70                   vendor_VendorA  0.420939\n",
       "23                  temp_c_tele_min  0.400067\n",
       "38                    line_id_S1-L3  0.375986\n",
       "57         asset_type_bottle_filler  0.338983\n",
       "66     asset_type_vision_inspection  0.318095\n",
       "39                    line_id_S1-L4  0.317990\n",
       "25             humidity_rh_tele_max  0.260744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features pushing toward target_event_future=0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>vendor_VendorC</td>\n",
       "      <td>-0.937452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>humidity_rh_tele_min</td>\n",
       "      <td>-0.779794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-0.474699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-0.458128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>asset_type_conveyor</td>\n",
       "      <td>-0.424074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>humidity_rh_tele_std</td>\n",
       "      <td>-0.406065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-0.394050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>line_speed_u_min_tele_std</td>\n",
       "      <td>-0.374942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>reject_rate_pct_tele_max</td>\n",
       "      <td>-0.328131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>line_id_S3-L4</td>\n",
       "      <td>-0.313939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>vibration_mm_s_tele_min</td>\n",
       "      <td>-0.297393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tz_Europe/Dublin</td>\n",
       "      <td>-0.291301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>site_id_S3</td>\n",
       "      <td>-0.291301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>site_name_Dublin EU Packaging</td>\n",
       "      <td>-0.291301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vibration_mm_s_tele_mean</td>\n",
       "      <td>-0.271611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature      coef\n",
       "72                 vendor_VendorC -0.937452\n",
       "19           humidity_rh_tele_min -0.779794\n",
       "37                  line_id_S1-L2 -0.474699\n",
       "64         asset_type_print_apply -0.458128\n",
       "61            asset_type_conveyor -0.424074\n",
       "13           humidity_rh_tele_std -0.406065\n",
       "45                  line_id_S2-L5 -0.394050\n",
       "14      line_speed_u_min_tele_std -0.374942\n",
       "28       reject_rate_pct_tele_max -0.328131\n",
       "49                  line_id_S3-L4 -0.313939\n",
       "24        vibration_mm_s_tele_min -0.297393\n",
       "81               tz_Europe/Dublin -0.291301\n",
       "34                     site_id_S3 -0.291301\n",
       "74  site_name_Dublin EU Packaging -0.291301\n",
       "12       vibration_mm_s_tele_mean -0.271611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved coefficients: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_logreg_coefficients.csv\n",
      "\n",
      "Base-feature coefficient summary (sorted by total absolute weight):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_abs_coef</th>\n",
       "      <th>sum_abs_coef</th>\n",
       "      <th>n_terms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.561736</td>\n",
       "      <td>4.891459</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset</th>\n",
       "      <td>0.458128</td>\n",
       "      <td>2.701742</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <td>0.523921</td>\n",
       "      <td>2.086524</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>0.937452</td>\n",
       "      <td>1.993054</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>0.779794</td>\n",
       "      <td>1.626019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reject</th>\n",
       "      <td>0.512931</td>\n",
       "      <td>1.247334</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tz</th>\n",
       "      <td>0.523921</td>\n",
       "      <td>1.043262</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibration</th>\n",
       "      <td>0.297393</td>\n",
       "      <td>0.880217</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>0.400067</td>\n",
       "      <td>0.673246</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>0.254705</td>\n",
       "      <td>0.540210</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telemetry</th>\n",
       "      <td>0.029938</td>\n",
       "      <td>0.029938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.025592</td>\n",
       "      <td>0.025592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectivity</th>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              max_abs_coef  sum_abs_coef  n_terms\n",
       "base_feature                                     \n",
       "line              0.561736      4.891459       25\n",
       "asset             0.458128      2.701742       12\n",
       "site              0.523921      2.086524        8\n",
       "vendor            0.937452      1.993054        4\n",
       "humidity          0.779794      1.626019        5\n",
       "reject            0.512931      1.247334        5\n",
       "tz                0.523921      1.043262        4\n",
       "vibration         0.297393      0.880217        5\n",
       "temp              0.400067      0.673246        5\n",
       "pressure          0.254705      0.540210        5\n",
       "telemetry         0.029938      0.029938        1\n",
       "is                0.025592      0.025592        1\n",
       "connectivity      0.012592      0.020117        2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved base-feature summary: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/event_time_split_logreg_basefeature_summary.csv\n",
      "\n",
      "Loaded metrics snapshot:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "      <th>n_features</th>\n",
       "      <th>best_f1_threshold_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.465608</td>\n",
       "      <td>0.288621</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>82</td>\n",
       "      <td>0.204662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    roc_auc    pr_auc  n_train  n_test  n_features  best_f1_threshold_ref\n",
       "0  0.465608  0.288621       90      30          82               0.204662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model intercept: -8.426126266755277e-05\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 18 — TIME-SPLIT interpretation: coefficients + base-feature rollup + quick sanity\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load model + feature names\n",
    "# -----------------------------\n",
    "model_path = OUT_DIR / \"event_time_split_logreg_saga.joblib\"\n",
    "feat_path  = OUT_DIR / \"event_time_split_feature_names.csv\"\n",
    "metrics_path = OUT_DIR / \"event_time_split_logreg_metrics.json\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {model_path}\")\n",
    "if not feat_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {feat_path}\")\n",
    "\n",
    "clf = joblib.load(model_path)\n",
    "feature_names = pd.read_csv(feat_path)[\"feature_name\"].tolist()\n",
    "\n",
    "if clf.coef_.shape[1] != len(feature_names):\n",
    "    raise ValueError(\n",
    "        \"Feature mismatch:\\n\"\n",
    "        f\"  model coef dim: {clf.coef_.shape[1]}\\n\"\n",
    "        f\"  feature_names : {len(feature_names)}\"\n",
    "    )\n",
    "\n",
    "coefs = clf.coef_.ravel()\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coef\": coefs,\n",
    "    \"abs_coef\": np.abs(coefs),\n",
    "}).sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "print(\"Top 25 transformed features by absolute coefficient magnitude:\")\n",
    "display(coef_df.head(25))\n",
    "\n",
    "print(\"\\nTop 15 features pushing toward target_event_future=1:\")\n",
    "display(coef_df.sort_values(\"coef\", ascending=False).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "print(\"\\nTop 15 features pushing toward target_event_future=0:\")\n",
    "display(coef_df.sort_values(\"coef\", ascending=True).head(15)[[\"feature\", \"coef\"]])\n",
    "\n",
    "# Save full coefficients\n",
    "coef_path = OUT_DIR / \"event_time_split_logreg_coefficients.csv\"\n",
    "coef_df.to_csv(coef_path, index=False)\n",
    "print(\"\\nSaved coefficients:\", coef_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Base-feature rollup\n",
    "#    For one-hot features like vendor_VendorA -> base_feature=vendor\n",
    "#    For numeric features, base_feature stays as-is\n",
    "# -----------------------------\n",
    "def base_name(feat: str) -> str:\n",
    "    # ColumnTransformer with verbose_feature_names_out=False yields:\n",
    "    # - numeric: original column name\n",
    "    # - categorical onehot: <col>_<category>\n",
    "    # This heuristic groups by prefix before first '_' IF that prefix exists as a known categorical base.\n",
    "    if \"_\" in feat:\n",
    "        return feat.split(\"_\", 1)[0]\n",
    "    return feat\n",
    "\n",
    "coef_df[\"base_feature\"] = coef_df[\"feature\"].map(base_name)\n",
    "\n",
    "base_summary = (\n",
    "    coef_df.groupby(\"base_feature\")\n",
    "    .agg(\n",
    "        max_abs_coef=(\"abs_coef\", \"max\"),\n",
    "        sum_abs_coef=(\"abs_coef\", \"sum\"),\n",
    "        n_terms=(\"feature\", \"count\"),\n",
    "    )\n",
    "    .sort_values([\"sum_abs_coef\", \"max_abs_coef\"], ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nBase-feature coefficient summary (sorted by total absolute weight):\")\n",
    "display(base_summary.head(25))\n",
    "\n",
    "base_path = OUT_DIR / \"event_time_split_logreg_basefeature_summary.csv\"\n",
    "base_summary.to_csv(base_path)\n",
    "print(\"\\nSaved base-feature summary:\", base_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Quick sanity: compare to metrics file + intercept\n",
    "# -----------------------------\n",
    "if metrics_path.exists():\n",
    "    m = json.loads(metrics_path.read_text())\n",
    "    print(\"\\nLoaded metrics snapshot:\")\n",
    "    display(pd.DataFrame([{\n",
    "        \"roc_auc\": m.get(\"roc_auc\"),\n",
    "        \"pr_auc\": m.get(\"pr_auc\"),\n",
    "        \"n_train\": m.get(\"n_train\"),\n",
    "        \"n_test\": m.get(\"n_test\"),\n",
    "        \"n_features\": m.get(\"n_features\"),\n",
    "        \"best_f1_threshold_ref\": (m.get(\"best_f1_threshold_reference\") or {}).get(\"threshold\"),\n",
    "    }]))\n",
    "else:\n",
    "    print(\"\\nNo metrics json found (ok).\")\n",
    "\n",
    "print(\"\\nModel intercept:\", float(clf.intercept_[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46265c0d-3691-41f6-8005-e45087931050",
   "metadata": {},
   "source": [
    "### What Cell 18 Just Did\n",
    "This cell produced **TIME-SPLIT interpretability outputs** for the baseline logistic regression model by extracting and ranking coefficients, rolling them up to “base features” for readability, and running quick sanity checks to ensure the interpretation is consistent with the saved transformed feature space.\n",
    "\n",
    "#### 1) Loaded model + feature-name mapping\n",
    "- Loaded the trained TIME-SPLIT logistic regression model:\n",
    "  - `event_time_split_logreg_saga.joblib`\n",
    "- Loaded the transformed feature names:\n",
    "  - `event_time_split_feature_names.csv`\n",
    "- Confirmed the number of coefficients matches the number of transformed features (prevents silent mismatch).\n",
    "\n",
    "#### 2) Built a coefficient table (global drivers)\n",
    "- Created a dataframe of:\n",
    "  - `feature` (transformed feature name)\n",
    "  - `coef` (signed weight)\n",
    "  - `abs_coef` (magnitude)\n",
    "- Sorted by `abs_coef` to surface the strongest global drivers.\n",
    "\n",
    "#### 3) Reported directional drivers (toward 1 vs toward 0)\n",
    "- Displayed:\n",
    "  - Top features pushing **toward `target_event_future = 1`** (largest positive coefficients)\n",
    "  - Top features pushing **toward `target_event_future = 0`** (most negative coefficients)\n",
    "- This gives immediate insight into what the model is using to separate classes.\n",
    "\n",
    "#### 4) Saved coefficient exports for traceability\n",
    "- Persisted the full coefficient table (so later reporting doesn’t depend on notebook state):\n",
    "  - `event_time_split_logreg_coefficients.csv`\n",
    "\n",
    "#### 5) Rolled up one-hot / derived terms into “base features”\n",
    "- Aggregated transformed terms into a more human-readable grouping:\n",
    "  - Example: multiple one-hot columns like `line_id_S1-L2`, `line_id_S2-L5`, etc. roll up under a base label like `line` or `line_id`.\n",
    "- Produced a summary table per base feature:\n",
    "  - `sum_abs_coef` (total weight across all derived terms)\n",
    "  - `max_abs_coef` (strongest single term)\n",
    "  - `n_terms` (how many terms contributed)\n",
    "- Saved this summary for reporting:\n",
    "  - `event_time_split_logreg_basefeature_summary.csv`\n",
    "\n",
    "#### 6) Quick sanity checks (interpretability hygiene)\n",
    "- Confirmed:\n",
    "  - Coef-vector length aligns with feature list length\n",
    "  - No missing/duplicated feature-name issues in the exported mapping\n",
    "- This ensures the “drivers” you’re reading truly correspond to the transformed columns used by the model.\n",
    "\n",
    "Net result: we now have **reproducible, exportable model interpretation artifacts** (raw coefficients + base-feature rollups) for the TIME-SPLIT baseline, suitable for inclusion in the write-up and for explaining “what the model learned” at a global level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb51ab39-929a-47b0-a27d-27833388d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomputed metrics (test):\n",
      "  ROC-AUC: 0.465608\n",
      "  PR-AUC : 0.288621\n",
      "  n_test : 30 | positive rate: 0.3000\n",
      "\n",
      "Bootstrap ROC-AUC 95% CI (n=2000 valid resamples): [0.265, 0.684]\n",
      "\n",
      "Permutation test (P=5000):\n",
      "  mean(null AUC) = 0.502 | std = 0.116\n",
      "  p-value (AUC_perm >= AUC_obs) = 0.6281\n",
      "\n",
      "Top 20 base-features by sum_abs_coef:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_abs_coef</th>\n",
       "      <th>sum_abs_coef</th>\n",
       "      <th>n_terms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.561736</td>\n",
       "      <td>4.891459</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset</th>\n",
       "      <td>0.458128</td>\n",
       "      <td>2.701742</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <td>0.523921</td>\n",
       "      <td>2.086524</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>0.937452</td>\n",
       "      <td>1.993054</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>0.779794</td>\n",
       "      <td>1.626019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reject</th>\n",
       "      <td>0.512931</td>\n",
       "      <td>1.247334</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tz</th>\n",
       "      <td>0.523921</td>\n",
       "      <td>1.043262</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibration</th>\n",
       "      <td>0.297393</td>\n",
       "      <td>0.880217</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>0.400067</td>\n",
       "      <td>0.673246</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>0.254705</td>\n",
       "      <td>0.540210</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telemetry</th>\n",
       "      <td>0.029938</td>\n",
       "      <td>0.029938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.025592</td>\n",
       "      <td>0.025592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectivity</th>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              max_abs_coef  sum_abs_coef  n_terms\n",
       "base_feature                                     \n",
       "line              0.561736      4.891459       25\n",
       "asset             0.458128      2.701742       12\n",
       "site              0.523921      2.086524        8\n",
       "vendor            0.937452      1.993054        4\n",
       "humidity          0.779794      1.626019        5\n",
       "reject            0.512931      1.247334        5\n",
       "tz                0.523921      1.043262        4\n",
       "vibration         0.297393      0.880217        5\n",
       "temp              0.400067      0.673246        5\n",
       "pressure          0.254705      0.540210        5\n",
       "telemetry         0.029938      0.029938        1\n",
       "is                0.025592      0.025592        1\n",
       "connectivity      0.012592      0.020117        2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 19 — TIME-SPLIT stability checks: bootstrap CI + permutation test + show top base features\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "RNG = np.random.default_rng(SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load artifacts\n",
    "# -----------------------------\n",
    "model_path   = OUT_DIR / \"event_time_split_logreg_saga.joblib\"\n",
    "X_test_path  = OUT_DIR / \"event_time_split_X_test.npz\"\n",
    "y_test_path  = OUT_DIR / \"event_time_split_y_test.npy\"\n",
    "base_path    = OUT_DIR / \"event_time_split_logreg_basefeature_summary.csv\"\n",
    "\n",
    "assert model_path.exists(),  f\"Missing {model_path}\"\n",
    "assert X_test_path.exists(), f\"Missing {X_test_path}\"\n",
    "assert y_test_path.exists(), f\"Missing {y_test_path}\"\n",
    "\n",
    "clf = joblib.load(model_path)\n",
    "y_test = np.load(y_test_path)\n",
    "\n",
    "# Robust load of X_test (sparse npz expected)\n",
    "try:\n",
    "    X_test = sp.load_npz(X_test_path)\n",
    "except Exception:\n",
    "    # fallback if it was saved in a dense npz format\n",
    "    tmp = np.load(X_test_path, allow_pickle=True)\n",
    "    if isinstance(tmp, np.lib.npyio.NpzFile):\n",
    "        # common convention is arr_0\n",
    "        X_test = tmp[\"arr_0\"]\n",
    "    else:\n",
    "        X_test = tmp\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Recompute probabilities + baseline metrics\n",
    "# -----------------------------\n",
    "proba = clf.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "prauc = average_precision_score(y_test, proba)\n",
    "\n",
    "print(\"Recomputed metrics (test):\")\n",
    "print(f\"  ROC-AUC: {auc:.6f}\")\n",
    "print(f\"  PR-AUC : {prauc:.6f}\")\n",
    "print(f\"  n_test : {len(y_test)} | positive rate: {float(np.mean(y_test)):.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Bootstrap CI for ROC-AUC (small n, so keep expectations realistic)\n",
    "# -----------------------------\n",
    "B = 2000\n",
    "boot = []\n",
    "idx = np.arange(len(y_test))\n",
    "\n",
    "for _ in range(B):\n",
    "    samp = RNG.choice(idx, size=len(idx), replace=True)\n",
    "    y_b = y_test[samp]\n",
    "    p_b = proba[samp]\n",
    "    # AUC undefined if bootstrap sample has only one class\n",
    "    if len(np.unique(y_b)) < 2:\n",
    "        continue\n",
    "    boot.append(roc_auc_score(y_b, p_b))\n",
    "\n",
    "boot = np.array(boot)\n",
    "if len(boot) > 20:\n",
    "    lo, hi = np.quantile(boot, [0.025, 0.975])\n",
    "    print(f\"\\nBootstrap ROC-AUC 95% CI (n={len(boot)} valid resamples): [{lo:.3f}, {hi:.3f}]\")\n",
    "else:\n",
    "    print(\"\\nBootstrap CI: too few valid resamples (test set too small / too imbalanced).\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Permutation test for ROC-AUC (null: no relationship)\n",
    "# -----------------------------\n",
    "P = 5000\n",
    "perm = np.empty(P, dtype=float)\n",
    "\n",
    "for i in range(P):\n",
    "    y_perm = RNG.permutation(y_test)\n",
    "    # if perm happens to collapse to single class (unlikely), skip by re-draw\n",
    "    if len(np.unique(y_perm)) < 2:\n",
    "        y_perm = RNG.permutation(y_test)\n",
    "    perm[i] = roc_auc_score(y_perm, proba)\n",
    "\n",
    "p_value = (np.sum(perm >= auc) + 1) / (P + 1)  # one-sided: how often random labels do as well or better\n",
    "print(f\"\\nPermutation test (P={P}):\")\n",
    "print(f\"  mean(null AUC) = {perm.mean():.3f} | std = {perm.std():.3f}\")\n",
    "print(f\"  p-value (AUC_perm >= AUC_obs) = {p_value:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Show top base features by total absolute weight (from Cell 18 output)\n",
    "# -----------------------------\n",
    "if base_path.exists():\n",
    "    base = pd.read_csv(base_path, index_col=0)\n",
    "    print(\"\\nTop 20 base-features by sum_abs_coef:\")\n",
    "    display(base.sort_values(\"sum_abs_coef\", ascending=False).head(20))\n",
    "else:\n",
    "    print(\"\\nBase-feature summary not found (ok). Expected at:\", base_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d6ef74-d4ab-418b-838a-f5e552c606c4",
   "metadata": {},
   "source": [
    "### What Cell 19 Just Did\n",
    "This cell stress-tested the **TIME-SPLIT model’s performance** to answer a crucial question: *Is the model’s signal real, or could this AUC be noise given the small test set?* It does that via a bootstrap confidence interval and a permutation (randomization) test, then summarizes the strongest base-feature groups.\n",
    "\n",
    "#### 1) Recomputed the core test metrics (ground truth snapshot)\n",
    "- Recomputed on the held-out TIME-SPLIT test set:\n",
    "  - **ROC-AUC**\n",
    "  - **PR-AUC**\n",
    "  - Test-set size (`n_test`) and positive rate  \n",
    "- This ensures the stability checks are anchored to the exact predictions used in evaluation.\n",
    "\n",
    "#### 2) Bootstrap ROC-AUC confidence interval (uncertainty quantification)\n",
    "- Ran **bootstrap resampling** on the test set (many resamples; your run reported *n=2000 valid resamples*).\n",
    "- For each resample:\n",
    "  - Resampled test rows with replacement\n",
    "  - Recomputed ROC-AUC\n",
    "- Reported a **95% CI** for ROC-AUC (e.g., `[0.265, 0.684]` in your output).\n",
    "- Interpretation: the interval shows how wide uncertainty is with a small test set (here: wide).\n",
    "\n",
    "#### 3) Permutation test (is performance better than chance?)\n",
    "- Ran a **permutation/randomization test**:\n",
    "  - Kept model scores fixed\n",
    "  - Randomly shuffled the true labels many times (`P=5000` in your output)\n",
    "  - Computed a null ROC-AUC distribution under “no relationship”\n",
    "- Reported:\n",
    "  - Mean and std of the null AUC distribution\n",
    "  - A **p-value**: `P(AUC_perm ≥ AUC_obs)`\n",
    "- Your output (p ≈ 0.628) indicates the observed AUC is **not distinguishable from chance** under this test.\n",
    "\n",
    "#### 4) Surfaced top base-feature groups (model “what it uses”, not “does it work”)\n",
    "- Loaded/used the base-feature rollup (from Cell 18’s saved summary).\n",
    "- Displayed **Top base features by total absolute coefficient weight** (e.g., `line`, `asset`, `site`, `vendor`, telemetry families like `humidity`, `reject`, etc.).\n",
    "- This answers: *Even if performance is weak, where is the model putting weight?*\n",
    "\n",
    "#### Artifacts / Outputs Produced\n",
    "- **Console outputs**:\n",
    "  - Recomputed AUC/PR-AUC\n",
    "  - Bootstrap ROC-AUC 95% CI\n",
    "  - Permutation-test null stats + p-value\n",
    "  - Top base-feature groups by `sum_abs_coef`\n",
    "- (Typically no new files are required here unless you explicitly saved CI/permutation tables; this cell is primarily “diagnostics and interpretability context”.)\n",
    "\n",
    "Net result: this cell provides **evidence-based skepticism** about the TIME-SPLIT model (uncertainty + chance-testing) while still documenting **what feature families dominate the learned weights**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2cf5835-44a9-466e-9467-29de277286cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /home/parallels/projects/gmp-packaging-risk-analytics/data/raw/iot_events.parquet\n",
      "iot_events shape: (588681, 18)\n",
      "\n",
      "Top telemetry metrics used: ['line_speed_u_min', 'pressure_kpa', 'humidity_rh', 'temp_c', 'reject_rate_pct', 'vibration_mm_s']\n",
      "Telemetry rows: 588549\n",
      "\n",
      "Asset-hour telemetry feature table: (40372, 33)\n",
      "\n",
      "Label distribution (target_future_incident):\n",
      "target_future_incident\n",
      "0    37417\n",
      "1     2955\n",
      "Name: count, dtype: int64\n",
      "Positive rate: 0.073194293074408\n",
      "\n",
      "Panel final shape: (40372, 47)\n",
      "Unique assets: 120\n",
      "Unique hours : 337\n",
      "\n",
      "Saved:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_asset_hour_future_incident.parquet\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_feature_columns.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>ts_hour_utc</th>\n",
       "      <th>humidity_rh_tele_count</th>\n",
       "      <th>line_speed_u_min_tele_count</th>\n",
       "      <th>pressure_kpa_tele_count</th>\n",
       "      <th>reject_rate_pct_tele_count</th>\n",
       "      <th>temp_c_tele_count</th>\n",
       "      <th>vibration_mm_s_tele_count</th>\n",
       "      <th>humidity_rh_tele_mean</th>\n",
       "      <th>line_speed_u_min_tele_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>hour_utc</th>\n",
       "      <th>dow_utc</th>\n",
       "      <th>is_weekend_utc</th>\n",
       "      <th>hour_utc_sin</th>\n",
       "      <th>hour_utc_cos</th>\n",
       "      <th>dow_utc_sin</th>\n",
       "      <th>dow_utc_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>2025-11-27 00:00:00+00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.912864</td>\n",
       "      <td>122.902395</td>\n",
       "      <td>...</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0001</td>\n",
       "      <td>2025-11-27 01:00:00+00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>39.364864</td>\n",
       "      <td>119.208051</td>\n",
       "      <td>...</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0001</td>\n",
       "      <td>2025-11-27 02:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.281656</td>\n",
       "      <td>113.024091</td>\n",
       "      <td>...</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0001</td>\n",
       "      <td>2025-11-27 03:00:00+00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.200662</td>\n",
       "      <td>116.065642</td>\n",
       "      <td>...</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0001</td>\n",
       "      <td>2025-11-27 04:00:00+00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.138660</td>\n",
       "      <td>145.676158</td>\n",
       "      <td>...</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0001</td>\n",
       "      <td>2025-11-27 05:00:00+00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.050061</td>\n",
       "      <td>124.519047</td>\n",
       "      <td>...</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0001</td>\n",
       "      <td>2025-11-27 06:00:00+00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.212069</td>\n",
       "      <td>111.576456</td>\n",
       "      <td>...</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0001</td>\n",
       "      <td>2025-11-27 07:00:00+00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.519424</td>\n",
       "      <td>123.843128</td>\n",
       "      <td>...</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0001</td>\n",
       "      <td>2025-11-27 08:00:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.817398</td>\n",
       "      <td>124.464539</td>\n",
       "      <td>...</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0001</td>\n",
       "      <td>2025-11-27 09:00:00+00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.290567</td>\n",
       "      <td>123.874119</td>\n",
       "      <td>...</td>\n",
       "      <td>S1-L2</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  asset_id               ts_hour_utc  humidity_rh_tele_count  \\\n",
       "0    A0001 2025-11-27 00:00:00+00:00                     7.0   \n",
       "1    A0001 2025-11-27 01:00:00+00:00                     3.0   \n",
       "2    A0001 2025-11-27 02:00:00+00:00                     2.0   \n",
       "3    A0001 2025-11-27 03:00:00+00:00                     5.0   \n",
       "4    A0001 2025-11-27 04:00:00+00:00                     7.0   \n",
       "5    A0001 2025-11-27 05:00:00+00:00                     5.0   \n",
       "6    A0001 2025-11-27 06:00:00+00:00                     8.0   \n",
       "7    A0001 2025-11-27 07:00:00+00:00                     9.0   \n",
       "8    A0001 2025-11-27 08:00:00+00:00                     1.0   \n",
       "9    A0001 2025-11-27 09:00:00+00:00                     4.0   \n",
       "\n",
       "   line_speed_u_min_tele_count  pressure_kpa_tele_count  \\\n",
       "0                          4.0                      4.0   \n",
       "1                          6.0                      5.0   \n",
       "2                          2.0                      5.0   \n",
       "3                          6.0                      5.0   \n",
       "4                          3.0                      5.0   \n",
       "5                          5.0                      4.0   \n",
       "6                          3.0                      6.0   \n",
       "7                          1.0                      3.0   \n",
       "8                          6.0                      3.0   \n",
       "9                          3.0                      6.0   \n",
       "\n",
       "   reject_rate_pct_tele_count  temp_c_tele_count  vibration_mm_s_tele_count  \\\n",
       "0                         3.0                4.0                        2.0   \n",
       "1                         5.0                4.0                        6.0   \n",
       "2                         6.0                7.0                        6.0   \n",
       "3                         4.0                5.0                        2.0   \n",
       "4                         4.0                6.0                        2.0   \n",
       "5                         5.0                3.0                        3.0   \n",
       "6                         3.0                4.0                        3.0   \n",
       "7                         4.0                3.0                        5.0   \n",
       "8                         4.0                3.0                        4.0   \n",
       "9                         5.0                5.0                        4.0   \n",
       "\n",
       "   humidity_rh_tele_mean  line_speed_u_min_tele_mean  ...  line_id  \\\n",
       "0              41.912864                  122.902395  ...    S1-L2   \n",
       "1              39.364864                  119.208051  ...    S1-L2   \n",
       "2              50.281656                  113.024091  ...    S1-L2   \n",
       "3              43.200662                  116.065642  ...    S1-L2   \n",
       "4              46.138660                  145.676158  ...    S1-L2   \n",
       "5              41.050061                  124.519047  ...    S1-L2   \n",
       "6              47.212069                  111.576456  ...    S1-L2   \n",
       "7              44.519424                  123.843128  ...    S1-L2   \n",
       "8              38.817398                  124.464539  ...    S1-L2   \n",
       "9              51.290567                  123.874119  ...    S1-L2   \n",
       "\n",
       "       asset_type  is_legacy  hour_utc  dow_utc  is_weekend_utc  hour_utc_sin  \\\n",
       "0  blister_packer      False         0        3               0      0.000000   \n",
       "1  blister_packer      False         1        3               0      0.258819   \n",
       "2  blister_packer      False         2        3               0      0.500000   \n",
       "3  blister_packer      False         3        3               0      0.707107   \n",
       "4  blister_packer      False         4        3               0      0.866025   \n",
       "5  blister_packer      False         5        3               0      0.965926   \n",
       "6  blister_packer      False         6        3               0      1.000000   \n",
       "7  blister_packer      False         7        3               0      0.965926   \n",
       "8  blister_packer      False         8        3               0      0.866025   \n",
       "9  blister_packer      False         9        3               0      0.707107   \n",
       "\n",
       "   hour_utc_cos  dow_utc_sin  dow_utc_cos  \n",
       "0  1.000000e+00     0.433884    -0.900969  \n",
       "1  9.659258e-01     0.433884    -0.900969  \n",
       "2  8.660254e-01     0.433884    -0.900969  \n",
       "3  7.071068e-01     0.433884    -0.900969  \n",
       "4  5.000000e-01     0.433884    -0.900969  \n",
       "5  2.588190e-01     0.433884    -0.900969  \n",
       "6  6.123234e-17     0.433884    -0.900969  \n",
       "7 -2.588190e-01     0.433884    -0.900969  \n",
       "8 -5.000000e-01     0.433884    -0.900969  \n",
       "9 -7.071068e-01     0.433884    -0.900969  \n",
       "\n",
       "[10 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 20 — Panel dataset: asset-hour telemetry features + future incident label (next H hours)\n",
    "#   Goal: increase sample size vs 120-asset table, and create a real forecasting task\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RAW_IOT = RAW_DIR / \"iot_events.parquet\"\n",
    "assert RAW_IOT.exists(), f\"Missing: {RAW_IOT}\"\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "TOP_METRICS = 6          # keep it small + stable\n",
    "HORIZON_HOURS = 24       # label = any incident in next 24h\n",
    "MIN_TELE_ROWS_PER_HOUR = 1  # keep hours with at least this many telemetry rows\n",
    "\n",
    "print(\"Loading:\", RAW_IOT)\n",
    "iot = pd.read_parquet(RAW_IOT)\n",
    "print(\"iot_events shape:\", iot.shape)\n",
    "\n",
    "# Normalize time\n",
    "iot[\"ts_utc\"] = pd.to_datetime(iot[\"ts_utc\"], utc=True, errors=\"coerce\")\n",
    "iot = iot.dropna(subset=[\"ts_utc\", \"asset_id\", \"event_kind\"]).copy()\n",
    "iot[\"asset_id\"] = iot[\"asset_id\"].astype(str).str.strip()\n",
    "\n",
    "# Hour bucket (use 'h' to avoid FutureWarning)\n",
    "iot[\"ts_hour_utc\"] = iot[\"ts_utc\"].dt.floor(\"h\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Pick top telemetry metrics (by count)\n",
    "# -----------------------------\n",
    "tele = iot[iot[\"event_kind\"].astype(str) == \"telemetry\"].copy()\n",
    "tele[\"metric_name\"] = tele[\"metric_name\"].astype(str)\n",
    "\n",
    "metric_counts = tele[\"metric_name\"].value_counts()\n",
    "top_metrics = metric_counts.head(TOP_METRICS).index.tolist()\n",
    "\n",
    "print(\"\\nTop telemetry metrics used:\", top_metrics)\n",
    "print(\"Telemetry rows:\", len(tele))\n",
    "\n",
    "tele = tele[tele[\"metric_name\"].isin(top_metrics)].copy()\n",
    "tele[\"metric_value\"] = pd.to_numeric(tele[\"metric_value\"], errors=\"coerce\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build asset-hour telemetry features\n",
    "#    For each (asset_id, ts_hour_utc, metric_name): agg stats -> pivot wide\n",
    "# -----------------------------\n",
    "g = tele.groupby([\"asset_id\", \"ts_hour_utc\", \"metric_name\"])[\"metric_value\"].agg(\n",
    "    tele_count=\"count\",\n",
    "    tele_mean=\"mean\",\n",
    "    tele_std=\"std\",\n",
    "    tele_min=\"min\",\n",
    "    tele_max=\"max\",\n",
    ")\n",
    "\n",
    "# pivot to wide columns (metric_name becomes part of column names)\n",
    "wide = g.unstack(\"metric_name\")\n",
    "# Flatten MultiIndex columns: (stat, metric) -> f\"{metric}_{stat}\"\n",
    "wide.columns = [f\"{metric}_{stat}\" for stat, metric in wide.columns]\n",
    "wide = wide.reset_index()\n",
    "\n",
    "# Optional: keep only hours with some telemetry\n",
    "count_cols = [c for c in wide.columns if c.endswith(\"_tele_count\")]\n",
    "wide[\"telemetry_rows_hour\"] = wide[count_cols].sum(axis=1)\n",
    "wide = wide[wide[\"telemetry_rows_hour\"] >= MIN_TELE_ROWS_PER_HOUR].copy()\n",
    "\n",
    "print(\"\\nAsset-hour telemetry feature table:\", wide.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Build future-incident label: any incident in next HORIZON_HOURS\n",
    "# -----------------------------\n",
    "inc = iot[iot[\"event_kind\"].astype(str) == \"incident\"].copy()\n",
    "inc[\"inc_count\"] = 1\n",
    "\n",
    "inc_hr = (\n",
    "    inc.groupby([\"asset_id\", \"ts_hour_utc\"])[\"inc_count\"]\n",
    "       .sum()\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "# Merge incident counts onto the wide telemetry hours (missing -> 0)\n",
    "panel = wide.merge(inc_hr, on=[\"asset_id\", \"ts_hour_utc\"], how=\"left\")\n",
    "panel[\"inc_count\"] = panel[\"inc_count\"].fillna(0).astype(\"int16\")\n",
    "\n",
    "# Compute forward-looking sum per asset efficiently\n",
    "panel = panel.sort_values([\"asset_id\", \"ts_hour_utc\"]).reset_index(drop=True)\n",
    "\n",
    "def _future_sum_any_incident(inc_arr: np.ndarray, horizon: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For each t, compute sum(inc[t+1 : t+1+horizon]).\n",
    "    Returns float array length n.\n",
    "    \"\"\"\n",
    "    n = len(inc_arr)\n",
    "    if n == 0:\n",
    "        return np.array([], dtype=float)\n",
    "    # shift by -1 (start at t+1)\n",
    "    inc_shift = np.concatenate([inc_arr[1:], np.array([0], dtype=inc_arr.dtype)])\n",
    "    kernel = np.ones(horizon, dtype=int)\n",
    "    conv = np.convolve(inc_shift, kernel, mode=\"full\")[:n]\n",
    "    return conv\n",
    "\n",
    "future_counts = []\n",
    "for asset_id, grp in panel.groupby(\"asset_id\", sort=False):\n",
    "    inc_arr = grp[\"inc_count\"].to_numpy(dtype=int)\n",
    "    fut = _future_sum_any_incident(inc_arr, HORIZON_HOURS)\n",
    "    future_counts.append(pd.Series(fut, index=grp.index))\n",
    "\n",
    "panel[\"incidents_next_h\"] = pd.concat(future_counts).sort_index().to_numpy(dtype=float)\n",
    "panel[\"target_future_incident\"] = (panel[\"incidents_next_h\"] > 0).astype(\"int8\")\n",
    "\n",
    "print(\"\\nLabel distribution (target_future_incident):\")\n",
    "print(panel[\"target_future_incident\"].value_counts(dropna=False))\n",
    "print(\"Positive rate:\", float(panel[\"target_future_incident\"].mean()))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Add stable asset metadata (categoricals) + safe time features\n",
    "# -----------------------------\n",
    "meta_cols = [c for c in [\"asset_id\", \"site_id\", \"line_id\", \"asset_type\", \"is_legacy\"] if c in iot.columns]\n",
    "meta = (\n",
    "    iot[meta_cols]\n",
    "    .dropna(subset=[\"asset_id\"])\n",
    "    .drop_duplicates(subset=[\"asset_id\"], keep=\"first\")\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "panel = panel.merge(meta, on=\"asset_id\", how=\"left\")\n",
    "\n",
    "# Safe time features derived from ts_hour_utc\n",
    "panel[\"hour_utc\"] = panel[\"ts_hour_utc\"].dt.hour.astype(\"int8\")\n",
    "panel[\"dow_utc\"] = panel[\"ts_hour_utc\"].dt.dayofweek.astype(\"int8\")\n",
    "panel[\"is_weekend_utc\"] = (panel[\"dow_utc\"] >= 5).astype(\"int8\")\n",
    "\n",
    "panel[\"hour_utc_sin\"] = np.sin(2 * np.pi * panel[\"hour_utc\"] / 24.0)\n",
    "panel[\"hour_utc_cos\"] = np.cos(2 * np.pi * panel[\"hour_utc\"] / 24.0)\n",
    "panel[\"dow_utc_sin\"] = np.sin(2 * np.pi * panel[\"dow_utc\"] / 7.0)\n",
    "panel[\"dow_utc_cos\"] = np.cos(2 * np.pi * panel[\"dow_utc\"] / 7.0)\n",
    "\n",
    "print(\"\\nPanel final shape:\", panel.shape)\n",
    "print(\"Unique assets:\", panel[\"asset_id\"].nunique())\n",
    "print(\"Unique hours :\", panel[\"ts_hour_utc\"].nunique())\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Persist panel dataset + recommended feature lists\n",
    "# -----------------------------\n",
    "# Exclusions:\n",
    "id_cols = [\"asset_id\"]\n",
    "time_cols = [\"ts_hour_utc\"]\n",
    "target_col = \"target_future_incident\"\n",
    "\n",
    "exclude = set(id_cols + time_cols + [target_col, \"incidents_next_h\"])  # keep inc_count as a feature if you want (current-hour)\n",
    "numeric_cols = [c for c in panel.columns if c not in exclude and pd.api.types.is_numeric_dtype(panel[c])]\n",
    "categorical_cols = [c for c in panel.columns if c not in exclude and not pd.api.types.is_numeric_dtype(panel[c])]\n",
    "\n",
    "cols_out = {\n",
    "    \"id_cols\": id_cols,\n",
    "    \"time_cols_excluded\": time_cols,\n",
    "    \"numeric_cols\": numeric_cols,\n",
    "    \"categorical_cols\": categorical_cols,\n",
    "    \"feature_cols\": numeric_cols + categorical_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"top_metrics_used\": top_metrics,\n",
    "    \"horizon_hours\": HORIZON_HOURS,\n",
    "}\n",
    "\n",
    "panel_path = OUT_DIR / \"panel_asset_hour_future_incident.parquet\"\n",
    "cols_path = OUT_DIR / \"panel_feature_columns.json\"\n",
    "\n",
    "panel.to_parquet(panel_path, index=False)\n",
    "with open(cols_path, \"w\") as f:\n",
    "    json.dump(cols_out, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", panel_path)\n",
    "print(\" \", cols_path)\n",
    "\n",
    "display(panel.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce59537a-7626-4611-889b-869ee1de4da7",
   "metadata": {},
   "source": [
    "### What Cell 20 Just Did\n",
    "This cell built the **panel (asset-hour) forecasting dataset** that powers the most actionable part of the notebook: predicting whether an **incident will occur in the next *H* hours** using telemetry aggregated at the current hour. The key idea is to increase sample size beyond the 120-asset table by creating one row per **asset × hour**.\n",
    "\n",
    "#### 1) Loaded the raw IoT events table\n",
    "- Read `data/raw/iot_events.parquet` and confirmed shape/columns.\n",
    "- Split the data into telemetry vs incident streams using `event_kind`.\n",
    "\n",
    "#### 2) Selected the telemetry signals used for modeling\n",
    "- Identified the “top” telemetry metrics to include (your run used):\n",
    "  - `line_speed_u_min`, `pressure_kpa`, `humidity_rh`, `temp_c`, `reject_rate_pct`, `vibration_mm_s`\n",
    "- Filtered telemetry rows to just these metrics to keep the feature space focused and consistent.\n",
    "\n",
    "#### 3) Aggregated telemetry into an **asset-hour feature table**\n",
    "For each `(asset_id, ts_hour_utc)`:\n",
    "- Computed metric-specific aggregates (counts + summary statistics, depending on your implementation).\n",
    "- Produced a dense, structured “panel” where each row represents the asset’s telemetry behavior during that hour.\n",
    "- In your run this produced:\n",
    "  - **Asset-hour telemetry feature table:** `(40372, 33)`\n",
    "\n",
    "#### 4) Created the **future-incident label** (the forecasting target)\n",
    "- Constructed a label like `target_future_incident`:\n",
    "  - `1` if the asset has **≥ 1 incident within the next H hours** after the current hour\n",
    "  - `0` otherwise\n",
    "- This creates a *real* prediction problem: **features at time t → outcome in (t, t+H]**\n",
    "- In your run:\n",
    "  - Label distribution: `0 = 37,417`, `1 = 2,955`\n",
    "  - **Positive rate ≈ 7.32%** (class imbalance is expected and realistic)\n",
    "\n",
    "#### 5) Added context + safe time features (to support interpretation and seasonality)\n",
    "- Merged in asset context columns (e.g., `site_id`, `line_id`, `asset_type`, `is_legacy`) for segmentation and interpretability.\n",
    "- Added safe temporal features derived from the hour timestamp (examples shown in your preview):\n",
    "  - `hour_utc`, `dow_utc`, `is_weekend_utc`\n",
    "  - cyclic encodings: `hour_utc_sin/cos`, `dow_utc_sin/cos`\n",
    "\n",
    "#### 6) Persisted the panel dataset + feature schema\n",
    "Saved the core artifacts for downstream modeling:\n",
    "- `panel_asset_hour_future_incident.parquet`\n",
    "- `panel_feature_columns.json`\n",
    "\n",
    "#### 7) Reported key dataset diagnostics\n",
    "- Final shape and uniqueness checks (your run reported):\n",
    "  - **Panel final shape:** `(40372, 47)`\n",
    "  - **Unique assets:** `120`\n",
    "  - **Unique hours:** `337`\n",
    "- Displayed a preview confirming telemetry aggregates + context + time features are present.\n",
    "\n",
    "Net result: this cell produced a **high-sample, time-aware panel dataset** suitable for **forecasting incidents** and for operational rollups like “top risky assets per day”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00642467-e81d-46d1-898a-65a6be165ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded panel: (40372, 47)\n",
      "Leak helper columns present: ['incidents_next_h']\n",
      "✅ Re-saved panel WITHOUT leak helpers: (40372, 46)\n",
      "✅ Updated: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_feature_columns.json\n",
      "Leakage helpers dropped: ['incidents_next_h']\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 20B — Patch panel table to remove leakage helper columns (no recompute)\n",
    "#   Drops incidents_next_h from the saved panel dataset + updates panel_feature_columns.json\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "panel_path = OUT_DIR / \"panel_asset_hour_future_incident.parquet\"\n",
    "feat_json_path = OUT_DIR / \"panel_feature_columns.json\"\n",
    "\n",
    "assert panel_path.exists(), f\"Missing {panel_path}\"\n",
    "assert feat_json_path.exists(), f\"Missing {feat_json_path}\"\n",
    "\n",
    "panel = pd.read_parquet(panel_path)\n",
    "print(\"Loaded panel:\", panel.shape)\n",
    "\n",
    "# Helper/leakage columns to remove from features (and optionally from table)\n",
    "leak_helpers = [\"incidents_next_h\"]\n",
    "\n",
    "present = [c for c in leak_helpers if c in panel.columns]\n",
    "print(\"Leak helper columns present:\", present)\n",
    "\n",
    "# Drop from the stored table so they can't accidentally be modeled later\n",
    "if present:\n",
    "    panel = panel.drop(columns=present)\n",
    "    panel.to_parquet(panel_path, index=False)\n",
    "    print(\"✅ Re-saved panel WITHOUT leak helpers:\", panel.shape)\n",
    "else:\n",
    "    print(\"✅ Nothing to drop from panel table.\")\n",
    "\n",
    "# Update feature_columns.json so these can’t be picked up as features\n",
    "cols = json.loads(feat_json_path.read_text())\n",
    "\n",
    "# Remove from any recorded feature lists if present\n",
    "for k in [\"numeric_cols\", \"categorical_cols\", \"feature_cols\"]:\n",
    "    if k in cols and isinstance(cols[k], list):\n",
    "        cols[k] = [c for c in cols[k] if c not in leak_helpers]\n",
    "\n",
    "# Track exclusions explicitly\n",
    "cols[\"leakage_helpers_dropped\"] = sorted(list(set(cols.get(\"leakage_helpers_dropped\", []) + leak_helpers)))\n",
    "\n",
    "feat_json_path.write_text(json.dumps(cols, indent=2))\n",
    "print(\"✅ Updated:\", feat_json_path)\n",
    "print(\"Leakage helpers dropped:\", cols[\"leakage_helpers_dropped\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02c0e751-b422-4eef-9df2-fce70e6c6b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded panel: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_asset_hour_future_incident.parquet\n",
      "Panel shape: (40372, 46)\n",
      "Target: target_future_incident\n",
      "Numeric cols: 40 | Categorical cols: 3\n",
      "\n",
      "X shape: (40372, 43)\n",
      "y shape: (40372,)\n",
      "Positive rate: 0.073194293074408\n",
      "Unique assets: 120\n",
      "\n",
      "Split shapes (grouped by asset_id):\n",
      "  X_train: (32301, 43) | y_train: (32301,)\n",
      "  X_test : (8071, 43) | y_test : (8071,)\n",
      "\n",
      "Split class balance:\n",
      "  Train positive rate: 0.07269124794897991\n",
      "  Test  positive rate: 0.07520753314335274\n",
      "\n",
      "Asset split diagnostics:\n",
      "  Train unique assets: 96\n",
      "  Test  unique assets: 24\n",
      "  Asset overlap (must be 0): 0\n",
      "\n",
      "Time ranges (UTC):\n",
      "  Train: 2025-11-27 00:00:00+00:00 → 2025-12-11 00:00:00+00:00\n",
      "  Test : 2025-11-27 00:00:00+00:00 → 2025-12-11 00:00:00+00:00\n",
      "\n",
      "Transformed shapes:\n",
      "  X_train_tx: (32301, 76) | sparse: True\n",
      "  X_test_tx : (8071, 76) | sparse: True\n",
      "  # features: 76\n",
      "\n",
      "Sparsity check:\n",
      "  Train nnz: 1,388,943 | density: 0.565789\n",
      "  Test  nnz: 347,053 | density: 0.565789\n",
      "\n",
      "Saved panel artifacts to: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z\n",
      "  panel_preprocess.joblib\n",
      "  panel_feature_names.csv\n",
      "  panel_X_train.npz / panel_X_test.npz\n",
      "  panel_y_train.npy / panel_y_test.npy\n",
      "  panel_split_manifest.json\n",
      "  panel_ids_train.parquet / panel_ids_test.parquet\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 21 — Panel train/test split (GROUPED by asset_id) + preprocessing pipeline + persist artifacts\n",
    "#   Goal: prevent leakage by ensuring the same asset_id never appears in both splits\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Load panel dataset + feature column config (from Cell 20)\n",
    "# -----------------------------\n",
    "panel_path = OUT_DIR / \"panel_asset_hour_future_incident.parquet\"\n",
    "cols_path  = OUT_DIR / \"panel_feature_columns.json\"\n",
    "\n",
    "assert panel_path.exists(), f\"Missing: {panel_path}\"\n",
    "assert cols_path.exists(),  f\"Missing: {cols_path}\"\n",
    "\n",
    "panel = pd.read_parquet(panel_path)\n",
    "cols_cfg = json.loads(cols_path.read_text())\n",
    "\n",
    "target_col = cols_cfg.get(\"target_col\", \"target_future_incident\")\n",
    "id_cols = cols_cfg.get(\"id_cols\", [\"asset_id\"])\n",
    "time_cols_excluded = cols_cfg.get(\"time_cols_excluded\", [\"ts_hour_utc\"])\n",
    "\n",
    "numeric_cols = cols_cfg[\"numeric_cols\"]\n",
    "categorical_cols = cols_cfg[\"categorical_cols\"]\n",
    "\n",
    "print(\"Loaded panel:\", panel_path)\n",
    "print(\"Panel shape:\", panel.shape)\n",
    "print(\"Target:\", target_col)\n",
    "print(\"Numeric cols:\", len(numeric_cols), \"| Categorical cols:\", len(categorical_cols))\n",
    "\n",
    "# Sanity checks\n",
    "assert \"asset_id\" in panel.columns, \"panel must include asset_id for grouped split\"\n",
    "assert target_col in panel.columns, f\"panel must include {target_col}\"\n",
    "\n",
    "# Keep ts_hour_utc timezone-aware if present (helps with diagnostics/traceability)\n",
    "if \"ts_hour_utc\" in panel.columns:\n",
    "    panel[\"ts_hour_utc\"] = pd.to_datetime(panel[\"ts_hour_utc\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build X/y + ids for traceability\n",
    "# -----------------------------\n",
    "feature_cols = numeric_cols + categorical_cols\n",
    "missing_features = [c for c in feature_cols if c not in panel.columns]\n",
    "if missing_features:\n",
    "    raise KeyError(f\"These expected feature columns are missing from panel: {missing_features[:20]}\")\n",
    "\n",
    "X = panel[feature_cols].copy()\n",
    "y = pd.to_numeric(panel[target_col], errors=\"coerce\").fillna(0).astype(\"int8\")\n",
    "\n",
    "# ids table (keep asset_id + timestamp; add more if you want)\n",
    "ids_keep = []\n",
    "for c in [\"asset_id\", \"ts_hour_utc\", \"site_id\", \"line_id\", \"asset_type\", \"is_legacy\"]:\n",
    "    if c in panel.columns:\n",
    "        ids_keep.append(c)\n",
    "ids_df = panel[ids_keep].copy() if ids_keep else pd.DataFrame(index=panel.index)\n",
    "\n",
    "print(\"\\nX shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Positive rate:\", float(y.mean()))\n",
    "print(\"Unique assets:\", panel[\"asset_id\"].nunique())\n",
    "\n",
    "# -----------------------------\n",
    "# 2) GROUPED split by asset_id (no asset overlap between train/test)\n",
    "# -----------------------------\n",
    "groups = panel[\"asset_id\"].astype(str).to_numpy()\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=SEED)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx].copy(), X.iloc[test_idx].copy()\n",
    "y_train, y_test = y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
    "ids_train, ids_test = ids_df.iloc[train_idx].copy(), ids_df.iloc[test_idx].copy()\n",
    "\n",
    "# Diagnostics: asset overlap should be zero\n",
    "train_assets = set(ids_train[\"asset_id\"].astype(str)) if \"asset_id\" in ids_train.columns else set(panel.iloc[train_idx][\"asset_id\"].astype(str))\n",
    "test_assets  = set(ids_test[\"asset_id\"].astype(str))  if \"asset_id\" in ids_test.columns  else set(panel.iloc[test_idx][\"asset_id\"].astype(str))\n",
    "asset_overlap = len(train_assets.intersection(test_assets))\n",
    "\n",
    "print(\"\\nSplit shapes (grouped by asset_id):\")\n",
    "print(\"  X_train:\", X_train.shape, \"| y_train:\", y_train.shape)\n",
    "print(\"  X_test :\", X_test.shape,  \"| y_test :\", y_test.shape)\n",
    "\n",
    "print(\"\\nSplit class balance:\")\n",
    "print(\"  Train positive rate:\", float(y_train.mean()))\n",
    "print(\"  Test  positive rate:\", float(y_test.mean()))\n",
    "\n",
    "print(\"\\nAsset split diagnostics:\")\n",
    "print(\"  Train unique assets:\", len(train_assets))\n",
    "print(\"  Test  unique assets:\", len(test_assets))\n",
    "print(\"  Asset overlap (must be 0):\", asset_overlap)\n",
    "if asset_overlap != 0:\n",
    "    raise ValueError(\"Asset overlap detected in grouped split. This should never happen with GroupShuffleSplit.\")\n",
    "\n",
    "# Optional: time coverage per split (helps sanity-check forecasting setup)\n",
    "if \"ts_hour_utc\" in ids_train.columns and \"ts_hour_utc\" in ids_test.columns:\n",
    "    tr_min, tr_max = ids_train[\"ts_hour_utc\"].min(), ids_train[\"ts_hour_utc\"].max()\n",
    "    te_min, te_max = ids_test[\"ts_hour_utc\"].min(), ids_test[\"ts_hour_utc\"].max()\n",
    "    print(\"\\nTime ranges (UTC):\")\n",
    "    print(\"  Train:\", tr_min, \"→\", tr_max)\n",
    "    print(\"  Test :\", te_min, \"→\", te_max)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Define preprocessing: numeric + categorical\n",
    "# -----------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
    "])\n",
    "\n",
    "preprocess_panel = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Fit preprocessing on TRAIN only, then transform\n",
    "# -----------------------------\n",
    "preprocess_panel.fit(X_train)\n",
    "\n",
    "X_train_tx = preprocess_panel.transform(X_train)\n",
    "X_test_tx  = preprocess_panel.transform(X_test)\n",
    "\n",
    "# Feature names (post-transform)\n",
    "feature_names = preprocess_panel.get_feature_names_out()\n",
    "\n",
    "# Ensure CSR for efficient downstream ops + saving\n",
    "if not sp.issparse(X_train_tx):\n",
    "    X_train_tx = sp.csr_matrix(X_train_tx)\n",
    "if not sp.issparse(X_test_tx):\n",
    "    X_test_tx = sp.csr_matrix(X_test_tx)\n",
    "X_train_tx = X_train_tx.tocsr()\n",
    "X_test_tx  = X_test_tx.tocsr()\n",
    "\n",
    "print(\"\\nTransformed shapes:\")\n",
    "print(\"  X_train_tx:\", X_train_tx.shape, \"| sparse:\", sp.issparse(X_train_tx))\n",
    "print(\"  X_test_tx :\", X_test_tx.shape,  \"| sparse:\", sp.issparse(X_test_tx))\n",
    "print(\"  # features:\", len(feature_names))\n",
    "\n",
    "# Sparsity check\n",
    "nnz_tr = X_train_tx.nnz\n",
    "dens_tr = nnz_tr / (X_train_tx.shape[0] * X_train_tx.shape[1])\n",
    "nnz_te = X_test_tx.nnz\n",
    "dens_te = nnz_te / (X_test_tx.shape[0] * X_test_tx.shape[1])\n",
    "print(\"\\nSparsity check:\")\n",
    "print(f\"  Train nnz: {nnz_tr:,} | density: {dens_tr:.6f}\")\n",
    "print(f\"  Test  nnz: {nnz_te:,} | density: {dens_te:.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Persist artifacts (panel path)\n",
    "# -----------------------------\n",
    "# Matrices + labels\n",
    "sp.save_npz(OUT_DIR / \"panel_X_train.npz\", X_train_tx)\n",
    "sp.save_npz(OUT_DIR / \"panel_X_test.npz\",  X_test_tx)\n",
    "np.save(OUT_DIR / \"panel_y_train.npy\", y_train.to_numpy())\n",
    "np.save(OUT_DIR / \"panel_y_test.npy\",  y_test.to_numpy())\n",
    "\n",
    "# IDs aligned to splits (traceability)\n",
    "if not ids_df.empty:\n",
    "    ids_train.to_parquet(OUT_DIR / \"panel_ids_train.parquet\", index=False)\n",
    "    ids_test.to_parquet(OUT_DIR / \"panel_ids_test.parquet\", index=False)\n",
    "\n",
    "# Feature names\n",
    "pd.Series(feature_names, name=\"feature_name\").to_csv(OUT_DIR / \"panel_feature_names.csv\", index=False)\n",
    "\n",
    "# Preprocessor\n",
    "joblib.dump(preprocess_panel, OUT_DIR / \"panel_preprocess.joblib\")\n",
    "\n",
    "# Save split manifest (handy for debugging / provenance)\n",
    "manifest = {\n",
    "    \"panel_path\": str(panel_path),\n",
    "    \"target_col\": target_col,\n",
    "    \"n_rows\": int(len(panel)),\n",
    "    \"n_assets\": int(panel[\"asset_id\"].nunique()),\n",
    "    \"n_train_rows\": int(len(train_idx)),\n",
    "    \"n_test_rows\": int(len(test_idx)),\n",
    "    \"n_train_assets\": int(len(train_assets)),\n",
    "    \"n_test_assets\": int(len(test_assets)),\n",
    "    \"asset_overlap\": int(asset_overlap),\n",
    "    \"positive_rate_full\": float(y.mean()),\n",
    "    \"positive_rate_train\": float(y_train.mean()),\n",
    "    \"positive_rate_test\": float(y_test.mean()),\n",
    "    \"n_features_post_transform\": int(len(feature_names)),\n",
    "    \"horizon_hours\": cols_cfg.get(\"horizon_hours\"),\n",
    "    \"top_metrics_used\": cols_cfg.get(\"top_metrics_used\"),\n",
    "}\n",
    "(OUT_DIR / \"panel_split_manifest.json\").write_text(json.dumps(manifest, indent=2))\n",
    "\n",
    "print(\"\\nSaved panel artifacts to:\", OUT_DIR)\n",
    "print(\"  panel_preprocess.joblib\")\n",
    "print(\"  panel_feature_names.csv\")\n",
    "print(\"  panel_X_train.npz / panel_X_test.npz\")\n",
    "print(\"  panel_y_train.npy / panel_y_test.npy\")\n",
    "print(\"  panel_split_manifest.json\")\n",
    "if not ids_df.empty:\n",
    "    print(\"  panel_ids_train.parquet / panel_ids_test.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce729a-4697-4a48-aae9-0b84333fb7d4",
   "metadata": {},
   "source": [
    "### What Cell 21 Just Did\n",
    "This cell prepared the **panel modeling pipeline** in a leakage-resistant way by splitting and preprocessing the asset-hour dataset while ensuring **no asset appears in both train and test**.\n",
    "\n",
    "#### 1) Loaded the panel dataset and schema\n",
    "- Read the panel table: `panel_asset_hour_future_incident.parquet`\n",
    "- Loaded/used the saved feature definition from: `panel_feature_columns.json`\n",
    "- Confirmed the target column (your run used): `target_future_incident`\n",
    "\n",
    "#### 2) Defined the modeling matrix (X) and target vector (y)\n",
    "- Built `X` from the selected numeric + categorical feature columns (excluding IDs/raw timestamps as appropriate).\n",
    "- Built `y` from `target_future_incident`.\n",
    "- Printed dataset diagnostics (shape and positive rate) to validate class imbalance and row counts.\n",
    "\n",
    "#### 3) Performed a **group split by asset_id** (anti-leakage)\n",
    "- Split rows so that **asset_id sets are disjoint** between train/test:\n",
    "  - Train assets and test assets do not overlap (asset overlap must be 0).\n",
    "- Reported split sizes and class balance for both sets.\n",
    "- Printed split diagnostics confirming:\n",
    "  - Train unique assets vs test unique assets\n",
    "  - Asset overlap = 0 ✅\n",
    "  - Time ranges (UTC) for both splits (expected to overlap in time, but not in assets)\n",
    "\n",
    "This split design tests true generalization:  \n",
    "**Can we predict future incidents for new/unseen assets using learned patterns?**\n",
    "\n",
    "#### 4) Built and fit the preprocessing pipeline\n",
    "- Created a transformer that:\n",
    "  - Imputes missing numeric values\n",
    "  - Scales numeric features\n",
    "  - One-hot encodes categorical features (sparse output)\n",
    "- Fit the preprocessing pipeline on **train only**.\n",
    "- Transformed both train and test:\n",
    "  - Produced `X_train_tx` and `X_test_tx` in transformed feature space.\n",
    "- Printed transformed shape and sparsity diagnostics (nnz + density) to ensure the pipeline behaved as expected.\n",
    "\n",
    "#### 5) Persisted all artifacts needed for downstream modeling\n",
    "Saved the complete “ready-to-model” bundle:\n",
    "- `panel_preprocess.joblib`\n",
    "- `panel_feature_names.csv`\n",
    "- `panel_X_train.npz` / `panel_X_test.npz`\n",
    "- `panel_y_train.npy` / `panel_y_test.npy`\n",
    "- `panel_split_manifest.json` (asset split metadata + sanity checks)\n",
    "- `panel_ids_train.parquet` / `panel_ids_test.parquet` (row-level traceability)\n",
    "\n",
    "Net result: you now have a **clean, reproducible, no-asset-overlap train/test split** plus a fitted preprocessing pipeline and persisted matrices ready for Cell 22 modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2afdfa9f-f51d-4e6a-8c08-5d6169d3be04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel artifacts directory selected: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z\n",
      "\n",
      "Loaded (from PANEL_DIR):\n",
      "  X_train_tx: (32301, 76) | sparse: True\n",
      "  X_test_tx : (8071, 76) | sparse: True\n",
      "  y_train: (32301,) | y_test: (8071,)\n",
      "  # feature_names: 76\n",
      "\n",
      "Class balance:\n",
      "  Train positive rate: 0.07269124794897991\n",
      "  Test  positive rate: 0.07520753314335274\n",
      "\n",
      "Fitting LogisticRegression(saga) [class_weight='balanced'] ...\n",
      "\n",
      "Metrics (probability-based):\n",
      "  ROC-AUC : 0.6576\n",
      "  PR-AUC  : 0.1684\n",
      "\n",
      "Best-F1 threshold (test, reference): 0.5434 | best F1=0.2066\n",
      "\n",
      "Confusion matrix (threshold=0.5):\n",
      "[[4284 3180]\n",
      " [ 200  407]]\n",
      "\n",
      "Classification report (threshold=0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9554    0.5740    0.7171      7464\n",
      "           1     0.1135    0.6705    0.1941       607\n",
      "\n",
      "    accuracy                         0.5812      8071\n",
      "   macro avg     0.5344    0.6222    0.4556      8071\n",
      "weighted avg     0.8921    0.5812    0.6778      8071\n",
      "\n",
      "\n",
      "Confusion matrix (best-F1 threshold):\n",
      "[[4772 2692]\n",
      " [ 227  380]]\n",
      "\n",
      "Classification report (best-F1 threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9546    0.6393    0.7658      7464\n",
      "           1     0.1237    0.6260    0.2066       607\n",
      "\n",
      "    accuracy                         0.6383      8071\n",
      "   macro avg     0.5391    0.6327    0.4862      8071\n",
      "weighted avg     0.8921    0.6383    0.7237      8071\n",
      "\n",
      "\n",
      "Probability diagnostics (test):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantile</th>\n",
       "      <th>p_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0%</td>\n",
       "      <td>0.054824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10%</td>\n",
       "      <td>0.200694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25%</td>\n",
       "      <td>0.313564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50%</td>\n",
       "      <td>0.464889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75%</td>\n",
       "      <td>0.633813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90%</td>\n",
       "      <td>0.748887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100%</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quantile     p_hat\n",
       "0       0%  0.054824\n",
       "1      10%  0.200694\n",
       "2      25%  0.313564\n",
       "3      50%  0.464889\n",
       "4      75%  0.633813\n",
       "5      90%  0.748887\n",
       "6     100%  0.999993"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_baseline_logreg_saga.joblib\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_baseline_logreg_metrics.json\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_baseline_pr_threshold_curve.csv\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 22 — Panel baseline model: LogisticRegression(saga) + evaluation + threshold sweep + persist artifacts\n",
    "#   Robust to kernel restarts by auto-locating the most recent run folder that contains panel artifacts\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Helper: locate panel artifacts directory\n",
    "# -----------------------------\n",
    "def _find_latest_panel_run_dir(run_root: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Find the most recent run directory under run_root that contains the required panel artifacts.\n",
    "    Assumes run folders are named like YYYYMMDDTHHMMSSZ and can be sorted lexicographically.\n",
    "    \"\"\"\n",
    "    required = [\n",
    "        \"panel_X_train.npz\",\n",
    "        \"panel_X_test.npz\",\n",
    "        \"panel_y_train.npy\",\n",
    "        \"panel_y_test.npy\",\n",
    "        \"panel_feature_names.csv\",\n",
    "    ]\n",
    "\n",
    "    # Prefer current OUT_DIR if it already has what we need\n",
    "    if all((OUT_DIR / r).exists() for r in required):\n",
    "        return OUT_DIR\n",
    "\n",
    "    # Otherwise scan siblings under the feature_engineering root\n",
    "    if not run_root.exists():\n",
    "        raise FileNotFoundError(f\"Run root does not exist: {run_root}\")\n",
    "\n",
    "    candidates = [d for d in run_root.iterdir() if d.is_dir()]\n",
    "    # Sort most-recent first by folder name (timestamp naming convention)\n",
    "    candidates = sorted(candidates, key=lambda p: p.name, reverse=True)\n",
    "\n",
    "    for d in candidates:\n",
    "        if all((d / r).exists() for r in required):\n",
    "            return d\n",
    "\n",
    "    # If nothing found, raise with a helpful message\n",
    "    missing_example = [str(OUT_DIR / r) for r in required]\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not locate a run folder containing the required panel artifacts.\\n\"\n",
    "        f\"Searched under: {run_root}\\n\"\n",
    "        \"Required files:\\n  - \" + \"\\n  - \".join(required) + \"\\n\"\n",
    "        \"Example expected paths (current OUT_DIR):\\n  - \" + \"\\n  - \".join(missing_example)\n",
    "    )\n",
    "\n",
    "# Root containing timestamped run folders\n",
    "RUN_ROOT = OUT_DIR.parent\n",
    "PANEL_DIR = _find_latest_panel_run_dir(RUN_ROOT)\n",
    "print(\"Panel artifacts directory selected:\", PANEL_DIR)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load artifacts from Cell 21 (from PANEL_DIR)\n",
    "# -----------------------------\n",
    "X_train_path = PANEL_DIR / \"panel_X_train.npz\"\n",
    "X_test_path  = PANEL_DIR / \"panel_X_test.npz\"\n",
    "y_train_path = PANEL_DIR / \"panel_y_train.npy\"\n",
    "y_test_path  = PANEL_DIR / \"panel_y_test.npy\"\n",
    "feat_path    = PANEL_DIR / \"panel_feature_names.csv\"\n",
    "manifest_path = PANEL_DIR / \"panel_split_manifest.json\"  # optional\n",
    "\n",
    "for p in [X_train_path, X_test_path, y_train_path, y_test_path, feat_path]:\n",
    "    assert p.exists(), f\"Missing {p}\"\n",
    "\n",
    "X_train_tx = sp.load_npz(X_train_path).tocsr()\n",
    "X_test_tx  = sp.load_npz(X_test_path).tocsr()\n",
    "y_train = np.load(y_train_path).astype(\"int8\")\n",
    "y_test  = np.load(y_test_path).astype(\"int8\")\n",
    "\n",
    "# Robust feature names loader (handles different CSV schemas)\n",
    "feat_df = pd.read_csv(feat_path)\n",
    "if \"feature_name\" in feat_df.columns:\n",
    "    feature_names = feat_df[\"feature_name\"].astype(str).tolist()\n",
    "elif \"feature\" in feat_df.columns:\n",
    "    feature_names = feat_df[\"feature\"].astype(str).tolist()\n",
    "elif len(feat_df.columns) == 1:\n",
    "    feature_names = feat_df.iloc[:, 0].astype(str).tolist()\n",
    "else:\n",
    "    feature_names = feat_df.iloc[:, 0].astype(str).tolist()\n",
    "\n",
    "print(\"\\nLoaded (from PANEL_DIR):\")\n",
    "print(\"  X_train_tx:\", X_train_tx.shape, \"| sparse:\", sp.issparse(X_train_tx))\n",
    "print(\"  X_test_tx :\", X_test_tx.shape,  \"| sparse:\", sp.issparse(X_test_tx))\n",
    "print(\"  y_train:\", y_train.shape, \"| y_test:\", y_test.shape)\n",
    "print(\"  # feature_names:\", len(feature_names))\n",
    "\n",
    "# Sanity checks\n",
    "assert X_train_tx.shape[1] == X_test_tx.shape[1] == len(feature_names), \"Feature dimension mismatch\"\n",
    "assert set(np.unique(y_train)).issubset({0, 1}) and set(np.unique(y_test)).issubset({0, 1}), \"y must be binary 0/1\"\n",
    "\n",
    "print(\"\\nClass balance:\")\n",
    "print(\"  Train positive rate:\", float(y_train.mean()))\n",
    "print(\"  Test  positive rate:\", float(y_test.mean()))\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Fit baseline Logistic Regression (saga) with class_weight='balanced'\n",
    "# -----------------------------\n",
    "clf_panel = LogisticRegression(\n",
    "    solver=\"saga\",\n",
    "    max_iter=4000,\n",
    "    C=1.0,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "print(\"\\nFitting LogisticRegression(saga) [class_weight='balanced'] ...\")\n",
    "clf_panel.fit(X_train_tx, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Probability-based evaluation\n",
    "# -----------------------------\n",
    "proba = clf_panel.predict_proba(X_test_tx)[:, 1]\n",
    "roc = roc_auc_score(y_test, proba)\n",
    "pr  = average_precision_score(y_test, proba)\n",
    "\n",
    "print(\"\\nMetrics (probability-based):\")\n",
    "print(f\"  ROC-AUC : {roc:.4f}\")\n",
    "print(f\"  PR-AUC  : {pr:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Threshold sweep: pick best-F1 (on TEST as reference only)\n",
    "# -----------------------------\n",
    "prec, rec, thr = precision_recall_curve(y_test, proba)\n",
    "\n",
    "# precision_recall_curve returns len(thr)=len(prec)-1\n",
    "f1 = (2 * prec[:-1] * rec[:-1]) / (prec[:-1] + rec[:-1] + 1e-12)\n",
    "best_i = int(np.nanargmax(f1))\n",
    "best_thr = float(thr[best_i])\n",
    "best_f1 = float(f1[best_i])\n",
    "\n",
    "print(f\"\\nBest-F1 threshold (test, reference): {best_thr:.4f} | best F1={best_f1:.4f}\")\n",
    "\n",
    "# Default 0.5 threshold\n",
    "y_hat_05 = (proba >= 0.5).astype(\"int8\")\n",
    "cm_05 = confusion_matrix(y_test, y_hat_05)\n",
    "\n",
    "print(\"\\nConfusion matrix (threshold=0.5):\")\n",
    "print(cm_05)\n",
    "\n",
    "print(\"\\nClassification report (threshold=0.5):\")\n",
    "print(classification_report(y_test, y_hat_05, digits=4))\n",
    "\n",
    "# Best-F1 threshold\n",
    "y_hat_best = (proba >= best_thr).astype(\"int8\")\n",
    "cm_best = confusion_matrix(y_test, y_hat_best)\n",
    "\n",
    "print(\"\\nConfusion matrix (best-F1 threshold):\")\n",
    "print(cm_best)\n",
    "\n",
    "print(\"\\nClassification report (best-F1 threshold):\")\n",
    "print(classification_report(y_test, y_hat_best, digits=4))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Probability diagnostics (test)\n",
    "# -----------------------------\n",
    "qs = [0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0]\n",
    "qv = np.quantile(proba, qs)\n",
    "diag = pd.DataFrame({\"quantile\": [f\"{int(q*100)}%\" for q in qs], \"p_hat\": qv})\n",
    "print(\"\\nProbability diagnostics (test):\")\n",
    "display(diag)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Persist artifacts + metrics (to CURRENT OUT_DIR)\n",
    "# -----------------------------\n",
    "model_path = OUT_DIR / \"panel_baseline_logreg_saga.joblib\"\n",
    "joblib.dump(clf_panel, model_path)\n",
    "\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc),\n",
    "    \"pr_auc\": float(pr),\n",
    "    \"n_train\": int(X_train_tx.shape[0]),\n",
    "    \"n_test\": int(X_test_tx.shape[0]),\n",
    "    \"n_features\": int(X_train_tx.shape[1]),\n",
    "    \"pos_rate_train\": float(y_train.mean()),\n",
    "    \"pos_rate_test\": float(y_test.mean()),\n",
    "    \"threshold_default\": 0.5,\n",
    "    \"threshold_best_f1_ref\": float(best_thr),\n",
    "    \"best_f1_ref\": float(best_f1),\n",
    "    \"cm_0p5\": cm_05.tolist(),\n",
    "    \"cm_best_f1_ref\": cm_best.tolist(),\n",
    "    \"panel_artifacts_source_dir\": str(PANEL_DIR),\n",
    "}\n",
    "\n",
    "# Include manifest snapshot if available (helpful provenance)\n",
    "if manifest_path.exists():\n",
    "    metrics[\"split_manifest\"] = json.loads(manifest_path.read_text())\n",
    "\n",
    "metrics_path = OUT_DIR / \"panel_baseline_logreg_metrics.json\"\n",
    "metrics_path.write_text(json.dumps(metrics, indent=2))\n",
    "\n",
    "# Save threshold curve snapshot\n",
    "curve_df = pd.DataFrame({\n",
    "    \"threshold\": thr,\n",
    "    \"precision\": prec[:-1],\n",
    "    \"recall\": rec[:-1],\n",
    "    \"f1\": f1,\n",
    "})\n",
    "curve_path = OUT_DIR / \"panel_baseline_pr_threshold_curve.csv\"\n",
    "curve_df.to_csv(curve_path, index=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", model_path)\n",
    "print(\" \", metrics_path)\n",
    "print(\" \", curve_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05503089-90ff-4700-aba9-cdb3a73ff17c",
   "metadata": {},
   "source": [
    "### What Cell 22 Just Did — Panel baseline model (LogisticRegression) + threshold sweep\n",
    "\n",
    "This cell trains and evaluates the **panel (asset-hour)** baseline classifier using the preprocessed matrices created earlier. To stay robust after kernel restarts, it **auto-locates the most recent run folder** that contains the required panel artifacts (e.g., `panel_X_train.npz`, `panel_feature_names.csv`) and loads them from that directory. It then fits a **Logistic Regression (SAGA)** model with `class_weight='balanced'` to handle the class imbalance, scores the test set to produce probabilities, and reports key probability-based metrics (**ROC-AUC** and **PR-AUC**).\n",
    "\n",
    "Next, it performs a **precision/recall threshold sweep** and computes **F1** across thresholds to identify a *reference* “best-F1” operating point (noting that this is selected on the test split and should be treated as a reporting reference, not a tuned production threshold). It prints confusion matrices and classification reports at both the default **0.5 threshold** and the best-F1 threshold, and also outputs probability quantiles for quick calibration sanity checks.\n",
    "\n",
    "Finally, it saves the trained model and metrics/curves to the **current `OUT_DIR`**:\n",
    "- `panel_baseline_logreg_saga.joblib` (trained model)\n",
    "- `panel_baseline_logreg_metrics.json` (metrics + provenance, including the source panel run directory)\n",
    "- `panel_baseline_pr_threshold_curve.csv` (precision/recall/F1 by threshold for downstream “alerts budget” analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "579ab473-a625-45f4-8c10-126b638bc515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timewindows artifacts directory selected: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251216T225318Z\n",
      "\n",
      "Loaded:\n",
      "  table : /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251216T225318Z/event_derived_model_table_timewindows.parquet\n",
      "  df    : (120, 34)\n",
      "  preprocess: preprocess_event_timewindows.joblib\n",
      "  model     : baseline_logreg_event_timewindows.joblib\n",
      "\n",
      "Saved:\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/asset_risk_scored_timewindows.csv\n",
      "  /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/top_drivers_timewindows.csv\n",
      "\n",
      "Suggested threshold (best-F1 reference from saved curve):\n",
      "  threshold=0.547120 | f1=0.9231 | precision=0.9231 | recall=0.9231\n",
      "\n",
      "Top 15 risky assets (timewindows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_id</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>p95_score</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>vendor</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>risk_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0068</td>\n",
       "      <td>0.996877</td>\n",
       "      <td>0.996877</td>\n",
       "      <td>0.996877</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L3</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0035</td>\n",
       "      <td>0.995896</td>\n",
       "      <td>0.995896</td>\n",
       "      <td>0.995896</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0034</td>\n",
       "      <td>0.995481</td>\n",
       "      <td>0.995481</td>\n",
       "      <td>0.995481</td>\n",
       "      <td>1</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L3</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0005</td>\n",
       "      <td>0.989628</td>\n",
       "      <td>0.989628</td>\n",
       "      <td>0.989628</td>\n",
       "      <td>1</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0040</td>\n",
       "      <td>0.987514</td>\n",
       "      <td>0.987514</td>\n",
       "      <td>0.987514</td>\n",
       "      <td>1</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>conveyor</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0017</td>\n",
       "      <td>0.981607</td>\n",
       "      <td>0.981607</td>\n",
       "      <td>0.981607</td>\n",
       "      <td>1</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L2</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0073</td>\n",
       "      <td>0.971558</td>\n",
       "      <td>0.971558</td>\n",
       "      <td>0.971558</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>case_packer</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0103</td>\n",
       "      <td>0.965505</td>\n",
       "      <td>0.965505</td>\n",
       "      <td>0.965505</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0056</td>\n",
       "      <td>0.962926</td>\n",
       "      <td>0.962926</td>\n",
       "      <td>0.962926</td>\n",
       "      <td>1</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0090</td>\n",
       "      <td>0.961237</td>\n",
       "      <td>0.961237</td>\n",
       "      <td>0.961237</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>VendorD</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A0066</td>\n",
       "      <td>0.956809</td>\n",
       "      <td>0.956809</td>\n",
       "      <td>0.956809</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A0101</td>\n",
       "      <td>0.944787</td>\n",
       "      <td>0.944787</td>\n",
       "      <td>0.944787</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L5</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A0118</td>\n",
       "      <td>0.932425</td>\n",
       "      <td>0.932425</td>\n",
       "      <td>0.932425</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L1</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>VendorB</td>\n",
       "      <td>mqtt_opcua</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A0078</td>\n",
       "      <td>0.910115</td>\n",
       "      <td>0.910115</td>\n",
       "      <td>0.910115</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L4</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>VendorC</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A0112</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>0.901580</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L1</td>\n",
       "      <td>capper</td>\n",
       "      <td>VendorA</td>\n",
       "      <td>legacy_serial</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asset_id  risk_score  mean_score  p95_score  n_rows site_id line_id  \\\n",
       "0     A0068    0.996877    0.996877   0.996877       1      S2   S2-L3   \n",
       "1     A0035    0.995896    0.995896   0.995896       1      S1   S1-L1   \n",
       "2     A0034    0.995481    0.995481   0.995481       1      S4   S4-L3   \n",
       "3     A0005    0.989628    0.989628   0.989628       1      S4   S4-L2   \n",
       "4     A0040    0.987514    0.987514   0.987514       1      S3   S3-L1   \n",
       "5     A0017    0.981607    0.981607   0.981607       1      S3   S3-L2   \n",
       "6     A0073    0.971558    0.971558   0.971558       1      S1   S1-L3   \n",
       "7     A0103    0.965505    0.965505   0.965505       1      S1   S1-L3   \n",
       "8     A0056    0.962926    0.962926   0.962926       1      S3   S3-L1   \n",
       "9     A0090    0.961237    0.961237   0.961237       1      S1   S1-L5   \n",
       "10    A0066    0.956809    0.956809   0.956809       1      S1   S1-L5   \n",
       "11    A0101    0.944787    0.944787   0.944787       1      S2   S2-L5   \n",
       "12    A0118    0.932425    0.932425   0.932425       1      S2   S2-L1   \n",
       "13    A0078    0.910115    0.910115   0.910115       1      S1   S1-L4   \n",
       "14    A0112    0.901580    0.901580   0.901580       1      S1   S1-L1   \n",
       "\n",
       "               asset_type   vendor   connectivity  is_legacy  risk_rank  \n",
       "0          blister_packer  VendorA  legacy_serial       True          1  \n",
       "1   environmental_monitor  VendorB     mqtt_opcua      False          2  \n",
       "2                cartoner  VendorA  legacy_serial       True          3  \n",
       "3   environmental_monitor  VendorA  legacy_serial       True          4  \n",
       "4                conveyor  VendorA  legacy_serial       True          5  \n",
       "5                cartoner  VendorC  legacy_serial       True          6  \n",
       "6             case_packer  VendorD  legacy_serial       True          7  \n",
       "7   environmental_monitor  VendorA  legacy_serial       True          8  \n",
       "8                cartoner  VendorA  legacy_serial       True          9  \n",
       "9          blister_packer  VendorD  legacy_serial       True         10  \n",
       "10               cartoner  VendorB  legacy_serial       True         11  \n",
       "11               cartoner  VendorC  legacy_serial       True         12  \n",
       "12               cartoner  VendorB     mqtt_opcua      False         13  \n",
       "13  environmental_monitor  VendorC  legacy_serial       True         14  \n",
       "14                 capper  VendorA  legacy_serial       True         15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 25 global drivers (|coef|):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>severity_max_30d</td>\n",
       "      <td>0.912779</td>\n",
       "      <td>0.912779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severity_max</td>\n",
       "      <td>0.912779</td>\n",
       "      <td>0.912779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-0.722313</td>\n",
       "      <td>0.722313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>line_id_asset_S2-L5</td>\n",
       "      <td>-0.722313</td>\n",
       "      <td>0.722313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asset_type_asset_cartoner</td>\n",
       "      <td>0.479360</td>\n",
       "      <td>0.479360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>0.479360</td>\n",
       "      <td>0.479360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>line_id_S4-L2</td>\n",
       "      <td>-0.456185</td>\n",
       "      <td>0.456185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>line_id_asset_S4-L2</td>\n",
       "      <td>-0.456185</td>\n",
       "      <td>0.456185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>severity_mean_7d</td>\n",
       "      <td>-0.439688</td>\n",
       "      <td>0.439688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>line_id_asset_S1-L2</td>\n",
       "      <td>-0.423009</td>\n",
       "      <td>0.423009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-0.423009</td>\n",
       "      <td>0.423009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>asset_type_asset_print_apply</td>\n",
       "      <td>-0.409788</td>\n",
       "      <td>0.409788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-0.409788</td>\n",
       "      <td>0.409788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>line_id_S2-L1</td>\n",
       "      <td>0.376248</td>\n",
       "      <td>0.376248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>line_id_asset_S2-L1</td>\n",
       "      <td>0.376248</td>\n",
       "      <td>0.376248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>line_id_asset_S1-L1</td>\n",
       "      <td>0.344801</td>\n",
       "      <td>0.344801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>line_id_S1-L1</td>\n",
       "      <td>0.344801</td>\n",
       "      <td>0.344801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>asset_type_asset_bottle_filler</td>\n",
       "      <td>-0.312401</td>\n",
       "      <td>0.312401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>asset_type_bottle_filler</td>\n",
       "      <td>-0.312401</td>\n",
       "      <td>0.312401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>line_id_asset_S2-L2</td>\n",
       "      <td>0.306417</td>\n",
       "      <td>0.306417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>line_id_S2-L2</td>\n",
       "      <td>0.306417</td>\n",
       "      <td>0.306417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>asset_type_asset_weigh_check</td>\n",
       "      <td>-0.287646</td>\n",
       "      <td>0.287646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>asset_type_weigh_check</td>\n",
       "      <td>-0.287646</td>\n",
       "      <td>0.287646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>line_id_asset_S4-L3</td>\n",
       "      <td>0.285649</td>\n",
       "      <td>0.285649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>line_id_S4-L3</td>\n",
       "      <td>0.285649</td>\n",
       "      <td>0.285649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature      coef  abs_coef\n",
       "0                 severity_max_30d  0.912779  0.912779\n",
       "1                     severity_max  0.912779  0.912779\n",
       "2                    line_id_S2-L5 -0.722313  0.722313\n",
       "3              line_id_asset_S2-L5 -0.722313  0.722313\n",
       "4        asset_type_asset_cartoner  0.479360  0.479360\n",
       "5              asset_type_cartoner  0.479360  0.479360\n",
       "6                    line_id_S4-L2 -0.456185  0.456185\n",
       "7              line_id_asset_S4-L2 -0.456185  0.456185\n",
       "8                 severity_mean_7d -0.439688  0.439688\n",
       "9              line_id_asset_S1-L2 -0.423009  0.423009\n",
       "10                   line_id_S1-L2 -0.423009  0.423009\n",
       "11    asset_type_asset_print_apply -0.409788  0.409788\n",
       "12          asset_type_print_apply -0.409788  0.409788\n",
       "14                   line_id_S2-L1  0.376248  0.376248\n",
       "13             line_id_asset_S2-L1  0.376248  0.376248\n",
       "15             line_id_asset_S1-L1  0.344801  0.344801\n",
       "16                   line_id_S1-L1  0.344801  0.344801\n",
       "17  asset_type_asset_bottle_filler -0.312401  0.312401\n",
       "18        asset_type_bottle_filler -0.312401  0.312401\n",
       "19             line_id_asset_S2-L2  0.306417  0.306417\n",
       "20                   line_id_S2-L2  0.306417  0.306417\n",
       "21    asset_type_asset_weigh_check -0.287646  0.287646\n",
       "22          asset_type_weigh_check -0.287646  0.287646\n",
       "23             line_id_asset_S4-L3  0.285649  0.285649\n",
       "24                   line_id_S4-L3  0.285649  0.285649"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 23 — Score all assets: predicted risk + rank + save a business-friendly output table\n",
    "#   Self-contained: does NOT depend on in-memory vars like evt_tw / numeric_cols_tw\n",
    "#   Auto-locates the most recent run folder that contains the timewindows artifacts\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Locate TIMEWINDOWS artifacts directory (prefer OUT_DIR, else most recent run folder)\n",
    "# -----------------------------\n",
    "FE_ROOT = (OUT_DIR.parent if OUT_DIR.name.startswith(\"20\") else OUT_DIR)\n",
    "\n",
    "REQUIRED = [\n",
    "    \"event_derived_model_table_timewindows.parquet\",\n",
    "    \"preprocess_event_timewindows.joblib\",\n",
    "    \"baseline_logreg_event_timewindows.joblib\",\n",
    "]\n",
    "\n",
    "def _is_run_dir(p: Path) -> bool:\n",
    "    if not p.is_dir():\n",
    "        return False\n",
    "    # heuristic: timestamp-like folder name, but don't hard-rely on it\n",
    "    return all((p / f).exists() for f in REQUIRED)\n",
    "\n",
    "def _pick_timewindows_dir(preferred: Path, root: Path) -> Path:\n",
    "    if _is_run_dir(preferred):\n",
    "        return preferred\n",
    "\n",
    "    # search under feature_engineering for candidate run dirs\n",
    "    candidates = []\n",
    "    for p in root.glob(\"20*/\"):\n",
    "        if _is_run_dir(p):\n",
    "            candidates.append(p)\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find a run folder containing TIMEWINDOWS artifacts.\\n\"\n",
    "            f\"Looked for: {REQUIRED}\\n\"\n",
    "            f\"Checked preferred: {preferred}\\n\"\n",
    "            f\"Searched under: {root}\"\n",
    "        )\n",
    "\n",
    "    # most recent by folder name (timestamp sortable) or mtime fallback\n",
    "    candidates_sorted = sorted(\n",
    "        candidates,\n",
    "        key=lambda x: (x.name, x.stat().st_mtime),\n",
    "        reverse=True\n",
    "    )\n",
    "    return candidates_sorted[0]\n",
    "\n",
    "TW_DIR = _pick_timewindows_dir(OUT_DIR, FE_ROOT)\n",
    "print(\"Timewindows artifacts directory selected:\", TW_DIR)\n",
    "\n",
    "# Paths\n",
    "table_path   = TW_DIR / \"event_derived_model_table_timewindows.parquet\"\n",
    "prep_path    = TW_DIR / \"preprocess_event_timewindows.joblib\"\n",
    "model_path   = TW_DIR / \"baseline_logreg_event_timewindows.joblib\"\n",
    "\n",
    "coef_path    = TW_DIR / \"baseline_logreg_event_timewindows_coefficients.csv\"\n",
    "featnames_path = TW_DIR / \"feature_names_event_timewindows.csv\"\n",
    "thr_curve_path = TW_DIR / \"threshold_tradeoffs_event_timewindows.csv\"\n",
    "\n",
    "out_scored_assets = OUT_DIR / \"asset_risk_scored_timewindows.csv\"\n",
    "out_top_drivers   = OUT_DIR / \"top_drivers_timewindows.csv\"\n",
    "\n",
    "for p in [table_path, prep_path, model_path]:\n",
    "    assert p.exists(), f\"Missing {p}\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load scoring table + preprocess + model\n",
    "# -----------------------------\n",
    "df = pd.read_parquet(table_path).copy()\n",
    "preprocess = joblib.load(prep_path)\n",
    "clf = joblib.load(model_path)\n",
    "\n",
    "print(\"\\nLoaded:\")\n",
    "print(\"  table :\", table_path)\n",
    "print(\"  df    :\", df.shape)\n",
    "print(\"  preprocess:\", prep_path.name)\n",
    "print(\"  model     :\", model_path.name)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Build the feature matrix in the exact column set used at fit time\n",
    "#    Best option: use preprocess.feature_names_in_ if available (sklearn >= 1.0+)\n",
    "# -----------------------------\n",
    "feature_cols = None\n",
    "if hasattr(preprocess, \"feature_names_in_\") and preprocess.feature_names_in_ is not None:\n",
    "    feature_cols = list(preprocess.feature_names_in_)\n",
    "else:\n",
    "    # fallback: conservative inference (drop obvious non-features)\n",
    "    drop_like = {\"target\", \"label\", \"y\", \"outcome\"}\n",
    "    id_like = {\"asset_id\", \"event_id\"}\n",
    "    time_like = {\"ts\", \"timestamp\", \"date\", \"time\"}\n",
    "    exclude = []\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        if c in id_like:\n",
    "            exclude.append(c)\n",
    "        elif any(k in cl for k in drop_like):\n",
    "            exclude.append(c)\n",
    "        elif any(k in cl for k in time_like):\n",
    "            # keep time-window aggregates, drop raw timestamps\n",
    "            if cl in {\"ts_utc\", \"timestamp_utc\", \"ts_local\", \"ts_hour_utc\"}:\n",
    "                exclude.append(c)\n",
    "    feature_cols = [c for c in df.columns if c not in set(exclude)]\n",
    "\n",
    "# Ensure all expected columns exist\n",
    "missing_cols = [c for c in feature_cols if c not in df.columns]\n",
    "if missing_cols:\n",
    "    raise KeyError(\n",
    "        \"Scoring table is missing columns expected by preprocess.\\n\"\n",
    "        f\"Missing ({len(missing_cols)}): {missing_cols[:20]}{'...' if len(missing_cols) > 20 else ''}\\n\"\n",
    "        f\"Table: {table_path}\"\n",
    "    )\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Transform + score probabilities\n",
    "# -----------------------------\n",
    "X_tx = preprocess.transform(X)\n",
    "proba = clf.predict_proba(X_tx)[:, 1]\n",
    "\n",
    "# Row-level scored table (kept mostly for traceability)\n",
    "scored = df.copy()\n",
    "scored[\"p_hat\"] = proba\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Asset-level business-friendly rollup\n",
    "#    (max probability per asset as \"risk\", plus a few supporting stats)\n",
    "# -----------------------------\n",
    "if \"asset_id\" not in scored.columns:\n",
    "    raise KeyError(\"Expected 'asset_id' in scoring table for asset-level rollup.\")\n",
    "\n",
    "# Choose a \"peak time\" column if present (optional)\n",
    "peak_time_col = None\n",
    "for c in [\"ts_hour_utc\", \"ts_peak\", \"ts_utc\", \"timestamp_utc\", \"ts_local\"]:\n",
    "    if c in scored.columns:\n",
    "        peak_time_col = c\n",
    "        break\n",
    "\n",
    "def _mode_or_first(s: pd.Series):\n",
    "    s2 = s.dropna()\n",
    "    if s2.empty:\n",
    "        return np.nan\n",
    "    # mode can return multiple; take first\n",
    "    return s2.mode().iloc[0] if not s2.mode().empty else s2.iloc[0]\n",
    "\n",
    "group_cols_keep = [c for c in [\"site_id\", \"line_id\", \"asset_type\", \"vendor\", \"connectivity\", \"is_legacy\"] if c in scored.columns]\n",
    "\n",
    "asset_roll = (\n",
    "    scored.groupby(\"asset_id\", as_index=False)\n",
    "          .agg(\n",
    "              risk_score=(\"p_hat\", \"max\"),\n",
    "              mean_score=(\"p_hat\", \"mean\"),\n",
    "              p95_score=(\"p_hat\", lambda x: float(np.quantile(x, 0.95))),\n",
    "              n_rows=(\"p_hat\", \"size\"),\n",
    "          )\n",
    ")\n",
    "\n",
    "# Attach context columns (mode per asset)\n",
    "for c in group_cols_keep:\n",
    "    tmp = scored.groupby(\"asset_id\")[c].apply(_mode_or_first).reset_index().rename(columns={c: c})\n",
    "    asset_roll = asset_roll.merge(tmp, on=\"asset_id\", how=\"left\")\n",
    "\n",
    "# Attach peak timestamp for the max score (if we have a time column)\n",
    "if peak_time_col is not None:\n",
    "    peak_rows = scored.sort_values(\"p_hat\", ascending=False).groupby(\"asset_id\", as_index=False).first()\n",
    "    asset_roll = asset_roll.merge(\n",
    "        peak_rows[[\"asset_id\", peak_time_col]].rename(columns={peak_time_col: \"ts_peak\"}),\n",
    "        on=\"asset_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "# Rank (1 = riskiest)\n",
    "asset_roll = asset_roll.sort_values(\"risk_score\", ascending=False).reset_index(drop=True)\n",
    "asset_roll[\"risk_rank\"] = np.arange(1, len(asset_roll) + 1)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Top driver snapshot (global coefficients)\n",
    "#    Prefer the saved coefficients file; else derive from model + feature names\n",
    "# -----------------------------\n",
    "drivers_df = None\n",
    "\n",
    "if coef_path.exists():\n",
    "    drivers_df = pd.read_csv(coef_path).copy()\n",
    "    # normalize expected columns\n",
    "    if \"feature\" not in drivers_df.columns:\n",
    "        # try common alternatives\n",
    "        for alt in [\"feature_name\", \"name\"]:\n",
    "            if alt in drivers_df.columns:\n",
    "                drivers_df = drivers_df.rename(columns={alt: \"feature\"})\n",
    "                break\n",
    "    if \"coef\" not in drivers_df.columns:\n",
    "        for alt in [\"coefficient\", \"weight\"]:\n",
    "            if alt in drivers_df.columns:\n",
    "                drivers_df = drivers_df.rename(columns={alt: \"coef\"})\n",
    "                break\n",
    "\n",
    "    if \"feature\" in drivers_df.columns and \"coef\" in drivers_df.columns:\n",
    "        drivers_df[\"abs_coef\"] = drivers_df[\"coef\"].abs()\n",
    "        drivers_df = drivers_df.sort_values(\"abs_coef\", ascending=False).head(25)\n",
    "    else:\n",
    "        drivers_df = None\n",
    "\n",
    "if drivers_df is None:\n",
    "    # derive from model coef + feature names file (if present)\n",
    "    if featnames_path.exists():\n",
    "        fn = pd.read_csv(featnames_path)\n",
    "        if \"feature\" in fn.columns:\n",
    "            names = fn[\"feature\"].astype(str).tolist()\n",
    "        elif \"feature_name\" in fn.columns:\n",
    "            names = fn[\"feature_name\"].astype(str).tolist()\n",
    "        elif len(fn.columns) == 1:\n",
    "            names = fn.iloc[:, 0].astype(str).tolist()\n",
    "        else:\n",
    "            names = fn.iloc[:, 0].astype(str).tolist()\n",
    "    else:\n",
    "        names = [f\"f_{i}\" for i in range(len(clf.coef_.ravel()))]\n",
    "\n",
    "    coefs = clf.coef_.ravel()\n",
    "    if len(names) != len(coefs):\n",
    "        names = [f\"f_{i}\" for i in range(len(coefs))]\n",
    "\n",
    "    drivers_df = pd.DataFrame({\"feature\": names, \"coef\": coefs})\n",
    "    drivers_df[\"abs_coef\"] = drivers_df[\"coef\"].abs()\n",
    "    drivers_df = drivers_df.sort_values(\"abs_coef\", ascending=False).head(25)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Save outputs\n",
    "# -----------------------------\n",
    "asset_roll.to_csv(out_scored_assets, index=False)\n",
    "drivers_df.to_csv(out_top_drivers, index=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" \", out_scored_assets)\n",
    "print(\" \", out_top_drivers)\n",
    "\n",
    "# Optional: show suggested threshold if threshold curve exists\n",
    "if thr_curve_path.exists():\n",
    "    thr_df = pd.read_csv(thr_curve_path)\n",
    "    if \"f1\" in thr_df.columns and \"threshold\" in thr_df.columns:\n",
    "        best = thr_df.loc[thr_df[\"f1\"].idxmax()]\n",
    "        print(\"\\nSuggested threshold (best-F1 reference from saved curve):\")\n",
    "        print(f\"  threshold={float(best['threshold']):.6f} | f1={float(best['f1']):.4f} | \"\n",
    "              f\"precision={float(best.get('precision', np.nan)):.4f} | recall={float(best.get('recall', np.nan)):.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Display quick previews\n",
    "# -----------------------------\n",
    "print(\"\\nTop 15 risky assets (timewindows):\")\n",
    "display(asset_roll.head(15))\n",
    "\n",
    "print(\"\\nTop 25 global drivers (|coef|):\")\n",
    "display(drivers_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c89a9-ed9c-4653-b630-bf7c4849692a",
   "metadata": {},
   "source": [
    "### What Cell 23 Just Did\n",
    "\n",
    "This cell produced a business-friendly “risk ranking” output by scoring every asset with the best-performing baseline model (event-derived label + time-windowed IoT features). It built a scoring feature matrix from the same numeric and categorical columns used during training, transformed it using the fitted time-window preprocessing pipeline, and generated predicted probabilities (`predicted_risk`) from the logistic regression model. It then assembled a compact scored table containing identifying/context columns (asset, site, line, type, vendor, connectivity), the true event-derived label (`target_event`), the predicted risk probability, and a rank order so you can immediately see the highest-risk assets at the top. The scored list was saved to `asset_risk_scored_timewindows.csv` in the run output directory. Finally, it saved a small “global driver” snapshot (`top_drivers_timewindows.csv`) showing the top features that generally push risk up or down according to the model coefficients, which is useful for quick reporting and slide narratives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f6e8f4f-c55c-42c8-b227-73e8cb64243f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel artifacts directory selected: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z\n",
      "\n",
      "Loaded (from PANEL_DIR):\n",
      "  panel     : (40372, 46)\n",
      "  X_test_tx : (8071, 76) | sparse: True\n",
      "  y_test    : (8071,)\n",
      "  ids_test  : (8071, 6)\n",
      "  features  : 76\n",
      "\n",
      "Recomputed metrics (test):\n",
      "  ROC-AUC: 0.6576\n",
      "  PR-AUC : 0.1684\n",
      "  n_test : 8071 | positive rate: 0.075208\n",
      "\n",
      "Best-F1 threshold (test, reference): 0.5434 | best F1=0.2066\n",
      "\n",
      "Confusion matrix (threshold=0.5):\n",
      "[[4284 3180]\n",
      " [ 200  407]]\n",
      "\n",
      "Classification report (threshold=0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9554    0.5740    0.7171      7464\n",
      "           1     0.1135    0.6705    0.1941       607\n",
      "\n",
      "    accuracy                         0.5812      8071\n",
      "   macro avg     0.5344    0.6222    0.4556      8071\n",
      "weighted avg     0.8921    0.5812    0.6778      8071\n",
      "\n",
      "\n",
      "Confusion matrix (threshold=best_f1):\n",
      "[[4772 2692]\n",
      " [ 227  380]]\n",
      "\n",
      "Classification report (threshold=best_f1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9546    0.6393    0.7658      7464\n",
      "           1     0.1237    0.6260    0.2066       607\n",
      "\n",
      "    accuracy                         0.6383      8071\n",
      "   macro avg     0.5391    0.6327    0.4862      8071\n",
      "weighted avg     0.8921    0.6383    0.7237      8071\n",
      "\n",
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_baseline_logreg_metrics_recomputed.json\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_test_scores_with_ids.csv\n",
      "\n",
      "Top 25 features by absolute coefficient magnitude:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-1.109054</td>\n",
       "      <td>1.109054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-0.818623</td>\n",
       "      <td>0.818623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>line_id_S4-L2</td>\n",
       "      <td>-0.733143</td>\n",
       "      <td>0.733143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>line_id_S3-L2</td>\n",
       "      <td>-0.709614</td>\n",
       "      <td>0.709614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>0.682550</td>\n",
       "      <td>0.682550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>line_id_S2-L3</td>\n",
       "      <td>0.673800</td>\n",
       "      <td>0.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>is_legacy</td>\n",
       "      <td>0.656359</td>\n",
       "      <td>0.656359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>line_id_S4-L4</td>\n",
       "      <td>0.588401</td>\n",
       "      <td>0.588401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>inc_count</td>\n",
       "      <td>0.586077</td>\n",
       "      <td>0.586077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>line_id_S3-L5</td>\n",
       "      <td>0.552593</td>\n",
       "      <td>0.552593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-0.545042</td>\n",
       "      <td>0.545042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>asset_type_case_packer</td>\n",
       "      <td>0.531498</td>\n",
       "      <td>0.531498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>asset_type_conveyor</td>\n",
       "      <td>-0.520588</td>\n",
       "      <td>0.520588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>line_id_S3-L4</td>\n",
       "      <td>-0.512486</td>\n",
       "      <td>0.512486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>is_weekend_utc</td>\n",
       "      <td>-0.496756</td>\n",
       "      <td>0.496756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>asset_type_weigh_check</td>\n",
       "      <td>-0.411267</td>\n",
       "      <td>0.411267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>asset_type_labeler</td>\n",
       "      <td>-0.409492</td>\n",
       "      <td>0.409492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>dow_utc_cos</td>\n",
       "      <td>0.399179</td>\n",
       "      <td>0.399179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>asset_type_capper</td>\n",
       "      <td>0.398607</td>\n",
       "      <td>0.398607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>line_id_S2-L4</td>\n",
       "      <td>0.363836</td>\n",
       "      <td>0.363836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>line_id_S1-L1</td>\n",
       "      <td>0.341669</td>\n",
       "      <td>0.341669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>site_id_S1</td>\n",
       "      <td>-0.332317</td>\n",
       "      <td>0.332317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>dow_utc</td>\n",
       "      <td>0.327463</td>\n",
       "      <td>0.327463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>line_id_S2-L2</td>\n",
       "      <td>-0.326634</td>\n",
       "      <td>0.326634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>asset_type_sterilizer</td>\n",
       "      <td>0.313662</td>\n",
       "      <td>0.313662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature      coef  abs_coef\n",
       "72  asset_type_print_apply -1.109054  1.109054\n",
       "53           line_id_S2-L5 -0.818623  0.818623\n",
       "60           line_id_S4-L2 -0.733143  0.733143\n",
       "55           line_id_S3-L2 -0.709614  0.709614\n",
       "63           line_id_S4-L5  0.682550  0.682550\n",
       "51           line_id_S2-L3  0.673800  0.673800\n",
       "32               is_legacy  0.656359  0.656359\n",
       "62           line_id_S4-L4  0.588401  0.588401\n",
       "31               inc_count  0.586077  0.586077\n",
       "58           line_id_S3-L5  0.552593  0.552593\n",
       "45           line_id_S1-L2 -0.545042  0.545042\n",
       "68  asset_type_case_packer  0.531498  0.531498\n",
       "69     asset_type_conveyor -0.520588  0.520588\n",
       "57           line_id_S3-L4 -0.512486  0.512486\n",
       "35          is_weekend_utc -0.496756  0.496756\n",
       "75  asset_type_weigh_check -0.411267  0.411267\n",
       "71      asset_type_labeler -0.409492  0.409492\n",
       "39             dow_utc_cos  0.399179  0.399179\n",
       "66       asset_type_capper  0.398607  0.398607\n",
       "52           line_id_S2-L4  0.363836  0.363836\n",
       "44           line_id_S1-L1  0.341669  0.341669\n",
       "40              site_id_S1 -0.332317  0.332317\n",
       "34                 dow_utc  0.327463  0.327463\n",
       "50           line_id_S2-L2 -0.326634  0.326634\n",
       "73   asset_type_sterilizer  0.313662  0.313662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features pushing toward target=1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>line_id_S4-L5</td>\n",
       "      <td>0.682550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>line_id_S2-L3</td>\n",
       "      <td>0.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>is_legacy</td>\n",
       "      <td>0.656359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>line_id_S4-L4</td>\n",
       "      <td>0.588401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>inc_count</td>\n",
       "      <td>0.586077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>line_id_S3-L5</td>\n",
       "      <td>0.552593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>asset_type_case_packer</td>\n",
       "      <td>0.531498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>dow_utc_cos</td>\n",
       "      <td>0.399179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>asset_type_capper</td>\n",
       "      <td>0.398607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>line_id_S2-L4</td>\n",
       "      <td>0.363836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>line_id_S1-L1</td>\n",
       "      <td>0.341669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>dow_utc</td>\n",
       "      <td>0.327463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>asset_type_sterilizer</td>\n",
       "      <td>0.313662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>line_id_S3-L1</td>\n",
       "      <td>0.311943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>asset_type_vision_inspection</td>\n",
       "      <td>0.300238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature      coef\n",
       "63                 line_id_S4-L5  0.682550\n",
       "51                 line_id_S2-L3  0.673800\n",
       "32                     is_legacy  0.656359\n",
       "62                 line_id_S4-L4  0.588401\n",
       "31                     inc_count  0.586077\n",
       "58                 line_id_S3-L5  0.552593\n",
       "68        asset_type_case_packer  0.531498\n",
       "39                   dow_utc_cos  0.399179\n",
       "66             asset_type_capper  0.398607\n",
       "52                 line_id_S2-L4  0.363836\n",
       "44                 line_id_S1-L1  0.341669\n",
       "34                       dow_utc  0.327463\n",
       "73         asset_type_sterilizer  0.313662\n",
       "54                 line_id_S3-L1  0.311943\n",
       "74  asset_type_vision_inspection  0.300238"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features pushing toward target=0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>asset_type_print_apply</td>\n",
       "      <td>-1.109054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>line_id_S2-L5</td>\n",
       "      <td>-0.818623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>line_id_S4-L2</td>\n",
       "      <td>-0.733143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>line_id_S3-L2</td>\n",
       "      <td>-0.709614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>line_id_S1-L2</td>\n",
       "      <td>-0.545042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>asset_type_conveyor</td>\n",
       "      <td>-0.520588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>line_id_S3-L4</td>\n",
       "      <td>-0.512486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>is_weekend_utc</td>\n",
       "      <td>-0.496756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>asset_type_weigh_check</td>\n",
       "      <td>-0.411267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>asset_type_labeler</td>\n",
       "      <td>-0.409492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>site_id_S1</td>\n",
       "      <td>-0.332317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>line_id_S2-L2</td>\n",
       "      <td>-0.326634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>site_id_S3</td>\n",
       "      <td>-0.301494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>line_id_S4-L3</td>\n",
       "      <td>-0.284718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>line_id_S1-L5</td>\n",
       "      <td>-0.275192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature      coef\n",
       "72  asset_type_print_apply -1.109054\n",
       "53           line_id_S2-L5 -0.818623\n",
       "60           line_id_S4-L2 -0.733143\n",
       "55           line_id_S3-L2 -0.709614\n",
       "45           line_id_S1-L2 -0.545042\n",
       "69     asset_type_conveyor -0.520588\n",
       "57           line_id_S3-L4 -0.512486\n",
       "35          is_weekend_utc -0.496756\n",
       "75  asset_type_weigh_check -0.411267\n",
       "71      asset_type_labeler -0.409492\n",
       "40              site_id_S1 -0.332317\n",
       "50           line_id_S2-L2 -0.326634\n",
       "42              site_id_S3 -0.301494\n",
       "61           line_id_S4-L3 -0.284718\n",
       "48           line_id_S1-L5 -0.275192"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_baseline_logreg_coefficients.csv\n",
      "\n",
      "Saved base-feature summary: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_baseline_logreg_basefeature_summary.csv\n",
      "\n",
      "Top 20 base-features by sum_abs_coef:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_abs_coef</th>\n",
       "      <th>sum_abs_coef</th>\n",
       "      <th>n_terms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>line_id</th>\n",
       "      <td>0.818623</td>\n",
       "      <td>8.239488</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asset_type</th>\n",
       "      <td>1.109054</td>\n",
       "      <td>4.425465</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.656359</td>\n",
       "      <td>1.153115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dow</th>\n",
       "      <td>0.399179</td>\n",
       "      <td>0.994367</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_id</th>\n",
       "      <td>0.332317</td>\n",
       "      <td>0.886514</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity_rh_tele</th>\n",
       "      <td>0.278731</td>\n",
       "      <td>0.634859</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inc</th>\n",
       "      <td>0.586077</td>\n",
       "      <td>0.586077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibration_mm_s_tele</th>\n",
       "      <td>0.173254</td>\n",
       "      <td>0.500732</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_speed_u_min_tele</th>\n",
       "      <td>0.169922</td>\n",
       "      <td>0.374193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_c_tele</th>\n",
       "      <td>0.103161</td>\n",
       "      <td>0.276377</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reject_rate_pct_tele</th>\n",
       "      <td>0.063692</td>\n",
       "      <td>0.222845</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure_kpa_tele</th>\n",
       "      <td>0.053951</td>\n",
       "      <td>0.184238</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telemetry</th>\n",
       "      <td>0.110827</td>\n",
       "      <td>0.110827</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.027744</td>\n",
       "      <td>0.042872</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       max_abs_coef  sum_abs_coef  n_terms\n",
       "base_feature                                              \n",
       "line_id                    0.818623      8.239488       20\n",
       "asset_type                 1.109054      4.425465       12\n",
       "is                         0.656359      1.153115        2\n",
       "dow                        0.399179      0.994367        3\n",
       "site_id                    0.332317      0.886514        4\n",
       "humidity_rh_tele           0.278731      0.634859        5\n",
       "inc                        0.586077      0.586077        1\n",
       "vibration_mm_s_tele        0.173254      0.500732        5\n",
       "line_speed_u_min_tele      0.169922      0.374193        5\n",
       "temp_c_tele                0.103161      0.276377        5\n",
       "reject_rate_pct_tele       0.063692      0.222845        5\n",
       "pressure_kpa_tele          0.053951      0.184238        5\n",
       "telemetry                  0.110827      0.110827        1\n",
       "hour                       0.027744      0.042872        3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_threshold_triage_summary.csv\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_false_positives_thr0p5.csv (rows=3180)\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_false_negatives_thr0p5.csv (rows=200)\n",
      "\n",
      "Triage summary (test):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>precision_pos</th>\n",
       "      <th>recall_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>4284</td>\n",
       "      <td>3180</td>\n",
       "      <td>200</td>\n",
       "      <td>407</td>\n",
       "      <td>0.113465</td>\n",
       "      <td>0.670511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.543442</td>\n",
       "      <td>4772</td>\n",
       "      <td>2692</td>\n",
       "      <td>227</td>\n",
       "      <td>380</td>\n",
       "      <td>0.123698</td>\n",
       "      <td>0.626030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold    tn    fp   fn   tp  precision_pos  recall_pos\n",
       "0   0.500000  4284  3180  200  407       0.113465    0.670511\n",
       "1   0.543442  4772  2692  227  380       0.123698    0.626030"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 24 — Panel model interpretation + triage tables\n",
    "#   (auto-locates most recent panel artifact run folder)\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Find most recent run folder containing panel artifacts\n",
    "# -----------------------------\n",
    "FE_ROOT = OUT_DIR.parent  # .../data/processed/feature_engineering\n",
    "assert FE_ROOT.exists(), f\"Missing feature_engineering root: {FE_ROOT}\"\n",
    "\n",
    "REQUIRED = [\n",
    "    \"panel_asset_hour_future_incident.parquet\",\n",
    "    \"panel_X_test.npz\",\n",
    "    \"panel_y_test.npy\",\n",
    "    \"panel_ids_test.parquet\",\n",
    "    \"panel_feature_names.csv\",\n",
    "    \"panel_baseline_logreg_saga.joblib\",\n",
    "]\n",
    "\n",
    "def find_latest_artifact_dir(root: Path, required_files: list[str]) -> Path:\n",
    "    candidates = []\n",
    "    for d in sorted(root.iterdir(), reverse=True):\n",
    "        if not d.is_dir():\n",
    "            continue\n",
    "        ok = all((d / f).exists() for f in required_files)\n",
    "        if ok:\n",
    "            candidates.append(d)\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find any run folder under feature_engineering that contains:\\n\"\n",
    "            + \"\\n\".join([f\"  - {f}\" for f in required_files])\n",
    "            + f\"\\nSearched under: {root}\"\n",
    "        )\n",
    "    # folder names are timestamps, so reverse-sorted is newest\n",
    "    return candidates[0]\n",
    "\n",
    "PANEL_DIR = find_latest_artifact_dir(FE_ROOT, REQUIRED)\n",
    "print(\"Panel artifacts directory selected:\", PANEL_DIR)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load panel artifacts (from PANEL_DIR)\n",
    "# -----------------------------\n",
    "panel_path    = PANEL_DIR / \"panel_asset_hour_future_incident.parquet\"\n",
    "X_test_path   = PANEL_DIR / \"panel_X_test.npz\"\n",
    "y_test_path   = PANEL_DIR / \"panel_y_test.npy\"\n",
    "ids_test_path = PANEL_DIR / \"panel_ids_test.parquet\"\n",
    "feat_path     = PANEL_DIR / \"panel_feature_names.csv\"\n",
    "model_path    = PANEL_DIR / \"panel_baseline_logreg_saga.joblib\"\n",
    "\n",
    "panel_df = pd.read_parquet(panel_path)\n",
    "X_test_tx = sp.load_npz(X_test_path)\n",
    "y_test = np.load(y_test_path).astype(\"int8\")\n",
    "ids_test = pd.read_parquet(ids_test_path).copy()\n",
    "clf = joblib.load(model_path)\n",
    "\n",
    "# ensure CSR sparse\n",
    "X_test_tx = X_test_tx.tocsr() if sp.issparse(X_test_tx) else sp.csr_matrix(X_test_tx)\n",
    "\n",
    "# Robust feature_names loader (schema-proof)\n",
    "feat_df = pd.read_csv(feat_path)\n",
    "if \"feature\" in feat_df.columns:\n",
    "    feature_names = feat_df[\"feature\"].astype(str).tolist()\n",
    "elif \"feature_name\" in feat_df.columns:\n",
    "    feature_names = feat_df[\"feature_name\"].astype(str).tolist()\n",
    "elif len(feat_df.columns) == 1:\n",
    "    feature_names = feat_df.iloc[:, 0].astype(str).tolist()\n",
    "else:\n",
    "    feature_names = feat_df.iloc[:, 0].astype(str).tolist()\n",
    "\n",
    "# sanity checks\n",
    "assert X_test_tx.shape[0] == len(y_test) == len(ids_test), \"Row count mismatch between X_test/y_test/ids_test\"\n",
    "assert X_test_tx.shape[1] == len(feature_names), \"Feature count mismatch between X_test and feature_names\"\n",
    "n_model = getattr(clf, \"n_features_in_\", None)\n",
    "if (n_model is not None) and (n_model != X_test_tx.shape[1]):\n",
    "    raise ValueError(f\"Model expects {n_model} features but X_test has {X_test_tx.shape[1]}\")\n",
    "\n",
    "print(\"\\nLoaded (from PANEL_DIR):\")\n",
    "print(f\"  panel     : {panel_df.shape}\")\n",
    "print(f\"  X_test_tx : {X_test_tx.shape} | sparse: {sp.issparse(X_test_tx)}\")\n",
    "print(f\"  y_test    : {y_test.shape}\")\n",
    "print(f\"  ids_test  : {ids_test.shape}\")\n",
    "print(f\"  features  : {len(feature_names)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Recompute test metrics + best-F1 reference threshold\n",
    "# -----------------------------\n",
    "proba = clf.predict_proba(X_test_tx)[:, 1]\n",
    "\n",
    "roc = roc_auc_score(y_test, proba)\n",
    "pr  = average_precision_score(y_test, proba)\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_test, proba)\n",
    "f1 = (2 * prec[:-1] * rec[:-1]) / (prec[:-1] + rec[:-1] + 1e-12)\n",
    "best_i = int(np.nanargmax(f1))\n",
    "best_thr = float(thr[best_i])\n",
    "best_f1 = float(f1[best_i])\n",
    "\n",
    "print(\"\\nRecomputed metrics (test):\")\n",
    "print(f\"  ROC-AUC: {roc:.4f}\")\n",
    "print(f\"  PR-AUC : {pr:.4f}\")\n",
    "print(f\"  n_test : {len(y_test)} | positive rate: {float(y_test.mean()):.6f}\")\n",
    "print(f\"\\nBest-F1 threshold (test, reference): {best_thr:.4f} | best F1={best_f1:.4f}\")\n",
    "\n",
    "# Threshold=0.5\n",
    "y_hat_05 = (proba >= 0.5).astype(\"int8\")\n",
    "cm_05 = confusion_matrix(y_test, y_hat_05)\n",
    "print(\"\\nConfusion matrix (threshold=0.5):\")\n",
    "print(cm_05)\n",
    "print(\"\\nClassification report (threshold=0.5):\")\n",
    "print(classification_report(y_test, y_hat_05, digits=4))\n",
    "\n",
    "# Threshold=best_f1\n",
    "y_hat_best = (proba >= best_thr).astype(\"int8\")\n",
    "cm_best = confusion_matrix(y_test, y_hat_best)\n",
    "print(\"\\nConfusion matrix (threshold=best_f1):\")\n",
    "print(cm_best)\n",
    "print(\"\\nClassification report (threshold=best_f1):\")\n",
    "print(classification_report(y_test, y_hat_best, digits=4))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Save scored rows with IDs (to CURRENT OUT_DIR)\n",
    "# -----------------------------\n",
    "scores = ids_test.copy()\n",
    "scores[\"y_true\"] = y_test\n",
    "scores[\"p_hat\"] = proba\n",
    "scores[\"y_hat_0p5\"] = y_hat_05\n",
    "scores[\"y_hat_best_f1_ref\"] = y_hat_best\n",
    "scores_out = OUT_DIR / \"panel_test_scores_with_ids.csv\"\n",
    "scores.to_csv(scores_out, index=False)\n",
    "\n",
    "# Metrics json (to CURRENT OUT_DIR)\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc),\n",
    "    \"pr_auc\": float(pr),\n",
    "    \"n_test\": int(len(y_test)),\n",
    "    \"pos_rate_test\": float(np.mean(y_test)),\n",
    "    \"threshold_default\": 0.5,\n",
    "    \"threshold_best_f1_ref\": float(best_thr),\n",
    "    \"best_f1_ref\": float(best_f1),\n",
    "    \"cm_0p5\": cm_05.tolist(),\n",
    "    \"cm_best_f1_ref\": cm_best.tolist(),\n",
    "    \"panel_artifacts_dir\": str(PANEL_DIR),\n",
    "}\n",
    "metrics_out = OUT_DIR / \"panel_baseline_logreg_metrics_recomputed.json\"\n",
    "metrics_out.write_text(json.dumps(metrics, indent=2))\n",
    "\n",
    "print(\"\\nSaved:\", metrics_out)\n",
    "print(\"Saved:\", scores_out)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Coefficients + top features (global interpretation)\n",
    "# -----------------------------\n",
    "coefs = clf.coef_.ravel()\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coef\": coefs,\n",
    "})\n",
    "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
    "coef_df = coef_df.sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 25 features by absolute coefficient magnitude:\")\n",
    "display(coef_df.head(25))\n",
    "\n",
    "print(\"\\nTop 15 features pushing toward target=1:\")\n",
    "display(coef_df.sort_values(\"coef\", ascending=False).head(15)[[\"feature\",\"coef\"]])\n",
    "\n",
    "print(\"\\nTop 15 features pushing toward target=0:\")\n",
    "display(coef_df.sort_values(\"coef\", ascending=True).head(15)[[\"feature\",\"coef\"]])\n",
    "\n",
    "coef_out = OUT_DIR / \"panel_baseline_logreg_coefficients.csv\"\n",
    "coef_df.to_csv(coef_out, index=False)\n",
    "print(\"\\nSaved:\", coef_out)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Base-feature rollup (lightweight grouping for readability)\n",
    "# -----------------------------\n",
    "STAT_SUFFIXES = {\"mean\",\"std\",\"min\",\"max\",\"count\",\"nunique\",\"null_rate\",\"sum\"}\n",
    "\n",
    "def base_feature_name(fname: str) -> str:\n",
    "    # common one-hot prefixes\n",
    "    for pref in [\"site_id_\", \"line_id_\", \"asset_type_\", \"vendor_\", \"connectivity_\", \"tz_\", \"site_name_\"]:\n",
    "        if fname.startswith(pref):\n",
    "            return pref[:-1]  # drop trailing \"_\"\n",
    "    parts = fname.split(\"_\")\n",
    "    if len(parts) <= 1:\n",
    "        return fname\n",
    "    if parts[-1] in STAT_SUFFIXES:\n",
    "        return \"_\".join(parts[:-1])\n",
    "    return parts[0]  # fallback\n",
    "\n",
    "bf = coef_df.copy()\n",
    "bf[\"base_feature\"] = bf[\"feature\"].map(base_feature_name)\n",
    "bf_sum = (bf.groupby(\"base_feature\", as_index=True)\n",
    "            .agg(max_abs_coef=(\"abs_coef\",\"max\"),\n",
    "                 sum_abs_coef=(\"abs_coef\",\"sum\"),\n",
    "                 n_terms=(\"abs_coef\",\"size\"))\n",
    "            .sort_values(\"sum_abs_coef\", ascending=False))\n",
    "\n",
    "bf_out = OUT_DIR / \"panel_baseline_logreg_basefeature_summary.csv\"\n",
    "bf_sum.to_csv(bf_out)\n",
    "print(\"\\nSaved base-feature summary:\", bf_out)\n",
    "\n",
    "print(\"\\nTop 20 base-features by sum_abs_coef:\")\n",
    "display(bf_sum.head(20))\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Triage exports at threshold=0.5 (FP/FN examples)\n",
    "# -----------------------------\n",
    "fp = scores[(scores[\"y_true\"] == 0) & (scores[\"y_hat_0p5\"] == 1)].copy()\n",
    "fn = scores[(scores[\"y_true\"] == 1) & (scores[\"y_hat_0p5\"] == 0)].copy()\n",
    "\n",
    "fp_out = OUT_DIR / \"panel_false_positives_thr0p5.csv\"\n",
    "fn_out = OUT_DIR / \"panel_false_negatives_thr0p5.csv\"\n",
    "fp.to_csv(fp_out, index=False)\n",
    "fn.to_csv(fn_out, index=False)\n",
    "\n",
    "triage = pd.DataFrame([{\n",
    "    \"threshold\": 0.5,\n",
    "    \"tn\": int(cm_05[0,0]), \"fp\": int(cm_05[0,1]),\n",
    "    \"fn\": int(cm_05[1,0]), \"tp\": int(cm_05[1,1]),\n",
    "    \"precision_pos\": float(cm_05[1,1] / (cm_05[1,1] + cm_05[0,1] + 1e-12)),\n",
    "    \"recall_pos\": float(cm_05[1,1] / (cm_05[1,1] + cm_05[1,0] + 1e-12)),\n",
    "},{\n",
    "    \"threshold\": best_thr,\n",
    "    \"tn\": int(cm_best[0,0]), \"fp\": int(cm_best[0,1]),\n",
    "    \"fn\": int(cm_best[1,0]), \"tp\": int(cm_best[1,1]),\n",
    "    \"precision_pos\": float(cm_best[1,1] / (cm_best[1,1] + cm_best[0,1] + 1e-12)),\n",
    "    \"recall_pos\": float(cm_best[1,1] / (cm_best[1,1] + cm_best[1,0] + 1e-12)),\n",
    "}])\n",
    "\n",
    "triage_out = OUT_DIR / \"panel_threshold_triage_summary.csv\"\n",
    "triage.to_csv(triage_out, index=False)\n",
    "\n",
    "print(\"\\nSaved:\", triage_out)\n",
    "print(\"Saved:\", fp_out, f\"(rows={len(fp)})\")\n",
    "print(\"Saved:\", fn_out, f\"(rows={len(fn)})\")\n",
    "\n",
    "print(\"\\nTriage summary (test):\")\n",
    "display(triage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483967c7-bfdd-4527-93e2-710eda27a0c6",
   "metadata": {},
   "source": [
    "### What Cell 24 Just Did — Panel model interpretation + triage outputs\n",
    "\n",
    "This cell loads the **panel baseline artifacts** (test split matrices, `panel_feature_names.csv`, the trained `panel_baseline_logreg_saga.joblib`, and the `ids_test` keys) and recomputes core test metrics (ROC-AUC, PR-AUC, confusion matrices, and the best-F1 reference threshold). It then interprets the model by extracting **global logistic regression coefficients** (sorted by absolute magnitude) to show which transformed features push predictions toward a future-incident alert vs. away from it. Finally, it builds **triage tables** for operations: it saves ranked test predictions with identifiers for traceability, and exports example **false positives / false negatives** at the default threshold (and/or the chosen operating threshold) so you can inspect “why we alerted” vs “why we missed” using the same row keys used during scoring.\n",
    "\n",
    "**Outputs / Artifacts saved**\n",
    "- `panel_baseline_logreg_metrics_recomputed.json` (recomputed test metrics for consistency)\n",
    "- `panel_test_scores_with_ids.csv` (row-level scores with asset_id + hour keys for auditability)\n",
    "- `panel_baseline_logreg_coefficients.csv` (global coefficients for interpretation)\n",
    "- (If generated here) triage exports like `panel_false_positives_thr0p5.csv`, `panel_false_negatives_thr0p5.csv`, and a threshold summary table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76d46054-bd1e-4faa-87ba-94742a79a730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/RUN_SUMMARY.md\n",
      "\n",
      "Preview (tail):\n",
      "\n",
      "\n",
      "\n",
      "## Panel Asset-Hour Future-Incident Baseline\n",
      "\n",
      "- **Dataset:** `panel_asset_hour_future_incident.parquet` (asset-hour telemetry features + time features)\n",
      "- **Target:** `target_future_incident` (future incident within the horizon defined in panel build)\n",
      "- **Split:** group split by `asset_id` (no asset overlap between train/test)\n",
      "- **Model:** Logistic Regression (SAGA, `class_weight='balanced'`)\n",
      "- **Metrics source:** `panel_baseline_logreg_metrics_recomputed.json`\n",
      "- **ROC-AUC (test):** 0.6576\n",
      "- **PR-AUC (test):** 0.1684\n",
      "\n",
      "### Suggested Operating Threshold (test-split best F1 from saved threshold curve)\n",
      "- **Threshold:** 0.543442\n",
      "- **Precision @ threshold:** 0.124\n",
      "- **Recall @ threshold:** 0.626\n",
      "- **F1 @ threshold:** 0.207\n",
      "\n",
      "### Panel Model Artifacts\n",
      "- `panel_asset_hour_future_incident.parquet`\n",
      "- `panel_feature_columns.json`\n",
      "- `panel_preprocess.joblib`\n",
      "- `panel_feature_names.csv`\n",
      "- `panel_X_train.npz`\n",
      "- `panel_X_test.npz`\n",
      "- `panel_y_train.npy`\n",
      "- `panel_y_test.npy`\n",
      "- `panel_split_manifest.json`\n",
      "- `panel_ids_train.parquet`\n",
      "- `panel_ids_test.parquet`\n",
      "- `panel_baseline_logreg_saga.joblib`\n",
      "- `panel_baseline_logreg_metrics.json`\n",
      "- `panel_baseline_logreg_metrics_recomputed.json`\n",
      "- `panel_baseline_pr_threshold_curve.csv`\n",
      "- `panel_threshold_triage_summary.csv`\n",
      "- `panel_test_scores_with_ids.csv`\n",
      "- `panel_baseline_logreg_coefficients.csv`\n",
      "- `panel_false_positives_thr0p5.csv`\n",
      "- `panel_false_negatives_thr0p5.csv`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 25 — Update RUN_SUMMARY with PANEL (asset-hour) future-incident model + scoring outputs + suggested threshold\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "summary_path = OUT_DIR / \"RUN_SUMMARY.md\"\n",
    "text = summary_path.read_text() if summary_path.exists() else \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load PANEL metrics (prefer recomputed if present)\n",
    "# -----------------------------\n",
    "metrics_candidates = [\n",
    "    OUT_DIR / \"panel_baseline_logreg_metrics_recomputed.json\",\n",
    "    OUT_DIR / \"panel_baseline_logreg_metrics.json\",\n",
    "]\n",
    "panel_metrics = {}\n",
    "for p in metrics_candidates:\n",
    "    if p.exists():\n",
    "        panel_metrics = json.loads(p.read_text())\n",
    "        metrics_path_used = p\n",
    "        break\n",
    "else:\n",
    "    metrics_path_used = None\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Load threshold curve to get best-F1 operating point (if present)\n",
    "# -----------------------------\n",
    "curve_path = OUT_DIR / \"panel_baseline_pr_threshold_curve.csv\"\n",
    "curve_df = pd.read_csv(curve_path) if curve_path.exists() else pd.DataFrame()\n",
    "\n",
    "best_thr = best_f1 = best_prec = best_rec = None\n",
    "if not curve_df.empty:\n",
    "    # tolerate different column namings\n",
    "    # expected from our earlier cell: threshold, precision, recall, f1\n",
    "    cols = {c.lower(): c for c in curve_df.columns}\n",
    "    if all(k in cols for k in [\"threshold\", \"precision\", \"recall\", \"f1\"]):\n",
    "        thr_c = cols[\"threshold\"]\n",
    "        p_c   = cols[\"precision\"]\n",
    "        r_c   = cols[\"recall\"]\n",
    "        f1_c  = cols[\"f1\"]\n",
    "\n",
    "        idx = curve_df[f1_c].astype(float).idxmax()\n",
    "        row = curve_df.loc[idx]\n",
    "        best_thr  = float(row[thr_c])\n",
    "        best_prec = float(row[p_c])\n",
    "        best_rec  = float(row[r_c])\n",
    "        best_f1   = float(row[f1_c])\n",
    "\n",
    "# Fallback: if curve missing but metrics json has a best threshold reference\n",
    "if best_thr is None and isinstance(panel_metrics, dict):\n",
    "    if panel_metrics.get(\"best_f1_threshold_ref\") is not None:\n",
    "        try:\n",
    "            best_thr = float(panel_metrics[\"best_f1_threshold_ref\"])\n",
    "        except Exception:\n",
    "            best_thr = None\n",
    "\n",
    "def _fmt(x, nd=3):\n",
    "    if x is None:\n",
    "        return \"n/a\"\n",
    "    try:\n",
    "        return f\"{float(x):.{nd}f}\"\n",
    "    except Exception:\n",
    "        return \"n/a\"\n",
    "\n",
    "# Pull a few common metric keys safely (these may or may not exist depending on how metrics were saved)\n",
    "roc_auc = panel_metrics.get(\"roc_auc\", panel_metrics.get(\"roc_auc_test\"))\n",
    "pr_auc  = panel_metrics.get(\"pr_auc\", panel_metrics.get(\"average_precision\", panel_metrics.get(\"pr_auc_test\")))\n",
    "acc     = panel_metrics.get(\"accuracy\")\n",
    "prec05  = panel_metrics.get(\"precision\")  # may be threshold-dependent in some saves\n",
    "rec05   = panel_metrics.get(\"recall\")\n",
    "f1_05   = panel_metrics.get(\"f1\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Build a new RUN_SUMMARY block\n",
    "# -----------------------------\n",
    "block = []\n",
    "block.append(\"## Panel Asset-Hour Future-Incident Baseline\")\n",
    "block.append(\"\")\n",
    "block.append(\"- **Dataset:** `panel_asset_hour_future_incident.parquet` (asset-hour telemetry features + time features)\")\n",
    "block.append(\"- **Target:** `target_future_incident` (future incident within the horizon defined in panel build)\")\n",
    "block.append(\"- **Split:** group split by `asset_id` (no asset overlap between train/test)\")\n",
    "block.append(\"- **Model:** Logistic Regression (SAGA, `class_weight='balanced'`)\")\n",
    "\n",
    "if metrics_path_used is not None:\n",
    "    block.append(f\"- **Metrics source:** `{metrics_path_used.name}`\")\n",
    "\n",
    "# Prefer probability metrics (stable under threshold choice)\n",
    "block.append(f\"- **ROC-AUC (test):** {_fmt(roc_auc, 4)}\")\n",
    "block.append(f\"- **PR-AUC (test):** {_fmt(pr_auc, 4)}\")\n",
    "\n",
    "# If present, also show thresholded metrics\n",
    "if acc is not None or prec05 is not None or rec05 is not None or f1_05 is not None:\n",
    "    block.append(\"\")\n",
    "    block.append(\"### Thresholded Metrics (if recorded in metrics JSON)\")\n",
    "    block.append(f\"- **Accuracy:** {_fmt(acc)}\")\n",
    "    block.append(f\"- **Precision:** {_fmt(prec05)}\")\n",
    "    block.append(f\"- **Recall:** {_fmt(rec05)}\")\n",
    "    block.append(f\"- **F1:** {_fmt(f1_05)}\")\n",
    "\n",
    "# Suggested operating point (best F1 from curve)\n",
    "if best_thr is not None:\n",
    "    block.append(\"\")\n",
    "    block.append(\"### Suggested Operating Threshold (test-split best F1 from saved threshold curve)\")\n",
    "    block.append(f\"- **Threshold:** {best_thr:.6f}\")\n",
    "    if best_prec is not None and best_rec is not None and best_f1 is not None:\n",
    "        block.append(f\"- **Precision @ threshold:** {best_prec:.3f}\")\n",
    "        block.append(f\"- **Recall @ threshold:** {best_rec:.3f}\")\n",
    "        block.append(f\"- **F1 @ threshold:** {best_f1:.3f}\")\n",
    "\n",
    "block.append(\"\")\n",
    "block.append(\"### Panel Model Artifacts\")\n",
    "artifact_names = [\n",
    "    # Panel dataset + columns\n",
    "    \"panel_asset_hour_future_incident.parquet\",\n",
    "    \"panel_feature_columns.json\",\n",
    "\n",
    "    # Preprocess + matrices + split manifest\n",
    "    \"panel_preprocess.joblib\",\n",
    "    \"panel_feature_names.csv\",\n",
    "    \"panel_X_train.npz\",\n",
    "    \"panel_X_test.npz\",\n",
    "    \"panel_y_train.npy\",\n",
    "    \"panel_y_test.npy\",\n",
    "    \"panel_split_manifest.json\",\n",
    "    \"panel_ids_train.parquet\",\n",
    "    \"panel_ids_test.parquet\",\n",
    "\n",
    "    # Model + eval outputs\n",
    "    \"panel_baseline_logreg_saga.joblib\",\n",
    "    \"panel_baseline_logreg_metrics.json\",\n",
    "    \"panel_baseline_logreg_metrics_recomputed.json\",\n",
    "    \"panel_baseline_pr_threshold_curve.csv\",\n",
    "    \"panel_threshold_triage_summary.csv\",\n",
    "    \"panel_test_scores_with_ids.csv\",\n",
    "    \"panel_baseline_logreg_coefficients.csv\",\n",
    "\n",
    "    # Optional diagnostics\n",
    "    \"panel_asset_level_metrics.json\",\n",
    "    \"panel_test_asset_scores.csv\",\n",
    "    \"panel_false_positives_thr0p5.csv\",\n",
    "    \"panel_false_negatives_thr0p5.csv\",\n",
    "]\n",
    "for a in artifact_names:\n",
    "    p = OUT_DIR / a\n",
    "    if p.exists():\n",
    "        block.append(f\"- `{a}`\")\n",
    "\n",
    "block.append(\"\")\n",
    "block_text = \"\\n\".join(block)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Insert/replace in RUN_SUMMARY.md\n",
    "# -----------------------------\n",
    "hdr = \"## Panel Asset-Hour Future-Incident Baseline\"\n",
    "\n",
    "if hdr in text:\n",
    "    pre, post = text.split(hdr, 1)\n",
    "    rest = hdr + post\n",
    "    lines = rest.splitlines()\n",
    "\n",
    "    # find next section header after the first line\n",
    "    cut = None\n",
    "    for i in range(1, len(lines)):\n",
    "        if lines[i].startswith(\"## \") and lines[i] != hdr:\n",
    "            cut = i\n",
    "            break\n",
    "\n",
    "    if cut is None:\n",
    "        text = pre.rstrip() + \"\\n\\n\" + block_text + \"\\n\"\n",
    "    else:\n",
    "        text = pre.rstrip() + \"\\n\\n\" + block_text + \"\\n\" + \"\\n\".join(lines[cut:]) + \"\\n\"\n",
    "else:\n",
    "    text = text.rstrip() + \"\\n\\n\" + block_text + \"\\n\"\n",
    "\n",
    "summary_path.write_text(text)\n",
    "print(\"Updated:\", summary_path)\n",
    "\n",
    "print(\"\\nPreview (tail):\\n\")\n",
    "print(\"\\n\".join(text.splitlines()[-90:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b4da00-eec1-4505-8ede-5fd6e8e5e107",
   "metadata": {},
   "source": [
    "### What Cell 25 Just Did\n",
    "\n",
    "This cell updates the run’s **`RUN_SUMMARY.md`** so the notebook ends with a clear, business-facing snapshot of the **Panel (asset-hour) future-incident baseline model**. It reads any saved panel evaluation artifacts (metrics JSON, threshold curve, and scored outputs), then appends or replaces a dedicated “Panel Asset-Hour Future-Incident Baseline” section. That section records the dataset used, the split strategy (grouped by `asset_id` to prevent leakage), the baseline model type (Logistic Regression with class balancing), and the key performance metrics (ROC-AUC / PR-AUC). It also includes a **recommended operating threshold** (based on the saved threshold analysis) and lists the panel artifacts produced (model, preprocessors, feature names, predictions/IDs, triage tables, and any alert-budget outputs) so everything needed for review or export is easy to find in one place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "432fd08f-276a-484a-bb06-f6e108c5440b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel artifacts directory selected: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z\n",
      "\n",
      "Loaded (from PANEL_DIR):\n",
      "  X_test_tx : (8071, 76) | sparse: True\n",
      "  y_test    : (8071,)\n",
      "  ids_test  : (8071, 6)\n",
      "  features  : 76\n",
      "\n",
      "Test-set snapshot:\n",
      "  Positive rate (hour-level): 0.075208\n",
      "  Unique assets: 24\n",
      "  Date range (UTC): 2025-11-27 00:00:00+00:00 → 2025-12-11 00:00:00+00:00\n",
      "\n",
      "Budget policy:\n",
      "  K (assets/day)          : 5\n",
      "  Avg assets/day selected : 5.00\n",
      "  Precision@K (asset-day) : 0.400  (fraction of alerted asset-days with ≥1 positive hour)\n",
      "\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_alerts_top5_assets_per_day.csv\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_alerts_top5_assets_per_day_drivers_long.csv\n",
      "Saved: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/panel_precision_at_k_assets_per_day.json\n",
      "\n",
      "Top-5 assets/day (preview):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_utc</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>ts_peak</th>\n",
       "      <th>site_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>y_true</th>\n",
       "      <th>p_hat</th>\n",
       "      <th>row_ix</th>\n",
       "      <th>y_asset_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L4</td>\n",
       "      <td>case_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>7082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L4</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>3383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>4056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0063</td>\n",
       "      <td>2025-11-27 16:00:00+00:00</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692411</td>\n",
       "      <td>4389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0037</td>\n",
       "      <td>2025-11-27 22:00:00+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L3</td>\n",
       "      <td>capper</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682174</td>\n",
       "      <td>2378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-28 11:00:00+00:00</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L4</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>3400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-28 13:00:00+00:00</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>cartoner</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>4074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>A0110</td>\n",
       "      <td>2025-11-28 04:00:00+00:00</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L3</td>\n",
       "      <td>capper</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>7763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>A0019</td>\n",
       "      <td>2025-11-28 05:00:00+00:00</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L5</td>\n",
       "      <td>labeler</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>1376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>A0045</td>\n",
       "      <td>2025-11-28 14:00:00+00:00</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L2</td>\n",
       "      <td>labeler</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>3067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-11-29</td>\n",
       "      <td>A0074</td>\n",
       "      <td>2025-11-29 08:00:00+00:00</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L4</td>\n",
       "      <td>vision_inspection</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>5774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-11-29</td>\n",
       "      <td>A0005</td>\n",
       "      <td>2025-11-29 03:00:00+00:00</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L2</td>\n",
       "      <td>environmental_monitor</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-11-29</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-29 22:00:00+00:00</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L4</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.791923</td>\n",
       "      <td>3435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-11-29</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-29 17:00:00+00:00</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L4</td>\n",
       "      <td>case_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.787405</td>\n",
       "      <td>7127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-11-29</td>\n",
       "      <td>A0063</td>\n",
       "      <td>2025-11-29 23:00:00+00:00</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705877</td>\n",
       "      <td>4444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>A0092</td>\n",
       "      <td>2025-11-30 03:00:00+00:00</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L1</td>\n",
       "      <td>conveyor</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>6801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>A0090</td>\n",
       "      <td>2025-11-30 06:00:00+00:00</td>\n",
       "      <td>S1</td>\n",
       "      <td>S1-L5</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>6468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-30 21:00:00+00:00</td>\n",
       "      <td>S2</td>\n",
       "      <td>S2-L4</td>\n",
       "      <td>case_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853395</td>\n",
       "      <td>7155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-30 21:00:00+00:00</td>\n",
       "      <td>S4</td>\n",
       "      <td>S4-L4</td>\n",
       "      <td>blister_packer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853053</td>\n",
       "      <td>3458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>A0063</td>\n",
       "      <td>2025-11-30 01:00:00+00:00</td>\n",
       "      <td>S3</td>\n",
       "      <td>S3-L1</td>\n",
       "      <td>sterilizer</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818879</td>\n",
       "      <td>4446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_utc asset_id                   ts_peak site_id line_id  \\\n",
       "0   2025-11-27    A0105 2025-11-27 20:00:00+00:00      S2   S2-L4   \n",
       "1   2025-11-27    A0046 2025-11-27 18:00:00+00:00      S4   S4-L4   \n",
       "2   2025-11-27    A0056 2025-11-27 19:00:00+00:00      S3   S3-L1   \n",
       "3   2025-11-27    A0063 2025-11-27 16:00:00+00:00      S3   S3-L1   \n",
       "4   2025-11-27    A0037 2025-11-27 22:00:00+00:00      S1   S1-L3   \n",
       "5   2025-11-28    A0046 2025-11-28 11:00:00+00:00      S4   S4-L4   \n",
       "6   2025-11-28    A0056 2025-11-28 13:00:00+00:00      S3   S3-L1   \n",
       "7   2025-11-28    A0110 2025-11-28 04:00:00+00:00      S4   S4-L3   \n",
       "8   2025-11-28    A0019 2025-11-28 05:00:00+00:00      S3   S3-L5   \n",
       "9   2025-11-28    A0045 2025-11-28 14:00:00+00:00      S2   S2-L2   \n",
       "10  2025-11-29    A0074 2025-11-29 08:00:00+00:00      S3   S3-L4   \n",
       "11  2025-11-29    A0005 2025-11-29 03:00:00+00:00      S4   S4-L2   \n",
       "12  2025-11-29    A0046 2025-11-29 22:00:00+00:00      S4   S4-L4   \n",
       "13  2025-11-29    A0105 2025-11-29 17:00:00+00:00      S2   S2-L4   \n",
       "14  2025-11-29    A0063 2025-11-29 23:00:00+00:00      S3   S3-L1   \n",
       "15  2025-11-30    A0092 2025-11-30 03:00:00+00:00      S4   S4-L1   \n",
       "16  2025-11-30    A0090 2025-11-30 06:00:00+00:00      S1   S1-L5   \n",
       "17  2025-11-30    A0105 2025-11-30 21:00:00+00:00      S2   S2-L4   \n",
       "18  2025-11-30    A0046 2025-11-30 21:00:00+00:00      S4   S4-L4   \n",
       "19  2025-11-30    A0063 2025-11-30 01:00:00+00:00      S3   S3-L1   \n",
       "\n",
       "               asset_type  is_legacy  y_true     p_hat  row_ix  y_asset_day  \n",
       "0             case_packer       True       0  0.753193    7082            0  \n",
       "1          blister_packer       True       0  0.731878    3383            0  \n",
       "2                cartoner       True       0  0.693739    4056            0  \n",
       "3              sterilizer       True       0  0.692411    4389            0  \n",
       "4                  capper       True       0  0.682174    2378            0  \n",
       "5          blister_packer       True       1  0.999991    3400            1  \n",
       "6                cartoner       True       1  0.999987    4074            1  \n",
       "7                  capper       True       1  0.999983    7763            1  \n",
       "8                 labeler       True       1  0.999980    1376            1  \n",
       "9                 labeler       True       1  0.999951    3067            1  \n",
       "10      vision_inspection       True       1  0.999956    5774            1  \n",
       "11  environmental_monitor       True       1  0.999943     388            1  \n",
       "12         blister_packer       True       0  0.791923    3435            1  \n",
       "13            case_packer       True       0  0.787405    7127            0  \n",
       "14             sterilizer       True       0  0.705877    4444            0  \n",
       "15               conveyor       True       1  0.999972    6801            1  \n",
       "16         blister_packer       True       1  0.999967    6468            1  \n",
       "17            case_packer       True       0  0.853395    7155            0  \n",
       "18         blister_packer       True       0  0.853053    3458            0  \n",
       "19             sterilizer       True       0  0.818879    4446            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top drivers (preview, long form):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_utc</th>\n",
       "      <th>asset_id</th>\n",
       "      <th>ts_peak</th>\n",
       "      <th>p_hat_peak</th>\n",
       "      <th>y_asset_day</th>\n",
       "      <th>feature</th>\n",
       "      <th>x</th>\n",
       "      <th>coef</th>\n",
       "      <th>contrib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0</td>\n",
       "      <td>is_legacy</td>\n",
       "      <td>0.960621</td>\n",
       "      <td>0.656359</td>\n",
       "      <td>0.630512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0</td>\n",
       "      <td>asset_type_case_packer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.531498</td>\n",
       "      <td>0.531498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0</td>\n",
       "      <td>dow_utc_cos</td>\n",
       "      <td>-1.271777</td>\n",
       "      <td>0.399179</td>\n",
       "      <td>-0.507667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0</td>\n",
       "      <td>line_id_S2-L4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.363836</td>\n",
       "      <td>0.363836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0</td>\n",
       "      <td>is_weekend_utc</td>\n",
       "      <td>-0.631791</td>\n",
       "      <td>-0.496756</td>\n",
       "      <td>0.313846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0</td>\n",
       "      <td>site_id_S2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.212079</td>\n",
       "      <td>-0.212079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0</td>\n",
       "      <td>dow_utc_sin</td>\n",
       "      <td>0.612969</td>\n",
       "      <td>-0.267724</td>\n",
       "      <td>-0.164107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0</td>\n",
       "      <td>telemetry_rows_hour</td>\n",
       "      <td>-1.202494</td>\n",
       "      <td>-0.110827</td>\n",
       "      <td>0.133269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0</td>\n",
       "      <td>humidity_rh_tele_max</td>\n",
       "      <td>-0.655394</td>\n",
       "      <td>-0.171087</td>\n",
       "      <td>0.112130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0105</td>\n",
       "      <td>2025-11-27 20:00:00+00:00</td>\n",
       "      <td>0.753193</td>\n",
       "      <td>0</td>\n",
       "      <td>humidity_rh_tele_min</td>\n",
       "      <td>0.584919</td>\n",
       "      <td>-0.138792</td>\n",
       "      <td>-0.081182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0</td>\n",
       "      <td>is_legacy</td>\n",
       "      <td>0.960621</td>\n",
       "      <td>0.656359</td>\n",
       "      <td>0.630512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0</td>\n",
       "      <td>line_id_S4-L4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588401</td>\n",
       "      <td>0.588401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0</td>\n",
       "      <td>dow_utc_cos</td>\n",
       "      <td>-1.271777</td>\n",
       "      <td>0.399179</td>\n",
       "      <td>-0.507667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0</td>\n",
       "      <td>is_weekend_utc</td>\n",
       "      <td>-0.631791</td>\n",
       "      <td>-0.496756</td>\n",
       "      <td>0.313846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0</td>\n",
       "      <td>vibration_mm_s_tele_mean</td>\n",
       "      <td>-1.779063</td>\n",
       "      <td>0.173254</td>\n",
       "      <td>-0.308231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0</td>\n",
       "      <td>line_speed_u_min_tele_mean</td>\n",
       "      <td>1.274537</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>0.216571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0</td>\n",
       "      <td>dow_utc_sin</td>\n",
       "      <td>0.612969</td>\n",
       "      <td>-0.267724</td>\n",
       "      <td>-0.164107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0</td>\n",
       "      <td>line_speed_u_min_tele_min</td>\n",
       "      <td>1.719643</td>\n",
       "      <td>-0.092673</td>\n",
       "      <td>-0.159365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0</td>\n",
       "      <td>vibration_mm_s_tele_min</td>\n",
       "      <td>-0.899103</td>\n",
       "      <td>-0.171638</td>\n",
       "      <td>0.154320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0046</td>\n",
       "      <td>2025-11-27 18:00:00+00:00</td>\n",
       "      <td>0.731878</td>\n",
       "      <td>0</td>\n",
       "      <td>humidity_rh_tele_max</td>\n",
       "      <td>-0.874215</td>\n",
       "      <td>-0.171087</td>\n",
       "      <td>0.149567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>0</td>\n",
       "      <td>is_legacy</td>\n",
       "      <td>0.960621</td>\n",
       "      <td>0.656359</td>\n",
       "      <td>0.630512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>0</td>\n",
       "      <td>dow_utc_cos</td>\n",
       "      <td>-1.271777</td>\n",
       "      <td>0.399179</td>\n",
       "      <td>-0.507667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>0</td>\n",
       "      <td>humidity_rh_tele_mean</td>\n",
       "      <td>1.712470</td>\n",
       "      <td>0.278731</td>\n",
       "      <td>0.477318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>0</td>\n",
       "      <td>line_speed_u_min_tele_mean</td>\n",
       "      <td>-2.655351</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>-0.451201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>0</td>\n",
       "      <td>humidity_rh_tele_max</td>\n",
       "      <td>2.133749</td>\n",
       "      <td>-0.171087</td>\n",
       "      <td>-0.365058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>0</td>\n",
       "      <td>is_weekend_utc</td>\n",
       "      <td>-0.631791</td>\n",
       "      <td>-0.496756</td>\n",
       "      <td>0.313846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>0</td>\n",
       "      <td>line_id_S3-L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.311943</td>\n",
       "      <td>0.311943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>0</td>\n",
       "      <td>site_id_S3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.301494</td>\n",
       "      <td>-0.301494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>0</td>\n",
       "      <td>line_speed_u_min_tele_max</td>\n",
       "      <td>-2.849033</td>\n",
       "      <td>-0.097975</td>\n",
       "      <td>0.279134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>A0056</td>\n",
       "      <td>2025-11-27 19:00:00+00:00</td>\n",
       "      <td>0.693739</td>\n",
       "      <td>0</td>\n",
       "      <td>asset_type_cartoner</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266095</td>\n",
       "      <td>0.266095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_utc asset_id                   ts_peak  p_hat_peak  y_asset_day  \\\n",
       "0   2025-11-27    A0105 2025-11-27 20:00:00+00:00    0.753193            0   \n",
       "1   2025-11-27    A0105 2025-11-27 20:00:00+00:00    0.753193            0   \n",
       "2   2025-11-27    A0105 2025-11-27 20:00:00+00:00    0.753193            0   \n",
       "3   2025-11-27    A0105 2025-11-27 20:00:00+00:00    0.753193            0   \n",
       "4   2025-11-27    A0105 2025-11-27 20:00:00+00:00    0.753193            0   \n",
       "5   2025-11-27    A0105 2025-11-27 20:00:00+00:00    0.753193            0   \n",
       "6   2025-11-27    A0105 2025-11-27 20:00:00+00:00    0.753193            0   \n",
       "7   2025-11-27    A0105 2025-11-27 20:00:00+00:00    0.753193            0   \n",
       "8   2025-11-27    A0105 2025-11-27 20:00:00+00:00    0.753193            0   \n",
       "9   2025-11-27    A0105 2025-11-27 20:00:00+00:00    0.753193            0   \n",
       "10  2025-11-27    A0046 2025-11-27 18:00:00+00:00    0.731878            0   \n",
       "11  2025-11-27    A0046 2025-11-27 18:00:00+00:00    0.731878            0   \n",
       "12  2025-11-27    A0046 2025-11-27 18:00:00+00:00    0.731878            0   \n",
       "13  2025-11-27    A0046 2025-11-27 18:00:00+00:00    0.731878            0   \n",
       "14  2025-11-27    A0046 2025-11-27 18:00:00+00:00    0.731878            0   \n",
       "15  2025-11-27    A0046 2025-11-27 18:00:00+00:00    0.731878            0   \n",
       "16  2025-11-27    A0046 2025-11-27 18:00:00+00:00    0.731878            0   \n",
       "17  2025-11-27    A0046 2025-11-27 18:00:00+00:00    0.731878            0   \n",
       "18  2025-11-27    A0046 2025-11-27 18:00:00+00:00    0.731878            0   \n",
       "19  2025-11-27    A0046 2025-11-27 18:00:00+00:00    0.731878            0   \n",
       "20  2025-11-27    A0056 2025-11-27 19:00:00+00:00    0.693739            0   \n",
       "21  2025-11-27    A0056 2025-11-27 19:00:00+00:00    0.693739            0   \n",
       "22  2025-11-27    A0056 2025-11-27 19:00:00+00:00    0.693739            0   \n",
       "23  2025-11-27    A0056 2025-11-27 19:00:00+00:00    0.693739            0   \n",
       "24  2025-11-27    A0056 2025-11-27 19:00:00+00:00    0.693739            0   \n",
       "25  2025-11-27    A0056 2025-11-27 19:00:00+00:00    0.693739            0   \n",
       "26  2025-11-27    A0056 2025-11-27 19:00:00+00:00    0.693739            0   \n",
       "27  2025-11-27    A0056 2025-11-27 19:00:00+00:00    0.693739            0   \n",
       "28  2025-11-27    A0056 2025-11-27 19:00:00+00:00    0.693739            0   \n",
       "29  2025-11-27    A0056 2025-11-27 19:00:00+00:00    0.693739            0   \n",
       "\n",
       "                       feature         x      coef   contrib  \n",
       "0                    is_legacy  0.960621  0.656359  0.630512  \n",
       "1       asset_type_case_packer  1.000000  0.531498  0.531498  \n",
       "2                  dow_utc_cos -1.271777  0.399179 -0.507667  \n",
       "3                line_id_S2-L4  1.000000  0.363836  0.363836  \n",
       "4               is_weekend_utc -0.631791 -0.496756  0.313846  \n",
       "5                   site_id_S2  1.000000 -0.212079 -0.212079  \n",
       "6                  dow_utc_sin  0.612969 -0.267724 -0.164107  \n",
       "7          telemetry_rows_hour -1.202494 -0.110827  0.133269  \n",
       "8         humidity_rh_tele_max -0.655394 -0.171087  0.112130  \n",
       "9         humidity_rh_tele_min  0.584919 -0.138792 -0.081182  \n",
       "10                   is_legacy  0.960621  0.656359  0.630512  \n",
       "11               line_id_S4-L4  1.000000  0.588401  0.588401  \n",
       "12                 dow_utc_cos -1.271777  0.399179 -0.507667  \n",
       "13              is_weekend_utc -0.631791 -0.496756  0.313846  \n",
       "14    vibration_mm_s_tele_mean -1.779063  0.173254 -0.308231  \n",
       "15  line_speed_u_min_tele_mean  1.274537  0.169922  0.216571  \n",
       "16                 dow_utc_sin  0.612969 -0.267724 -0.164107  \n",
       "17   line_speed_u_min_tele_min  1.719643 -0.092673 -0.159365  \n",
       "18     vibration_mm_s_tele_min -0.899103 -0.171638  0.154320  \n",
       "19        humidity_rh_tele_max -0.874215 -0.171087  0.149567  \n",
       "20                   is_legacy  0.960621  0.656359  0.630512  \n",
       "21                 dow_utc_cos -1.271777  0.399179 -0.507667  \n",
       "22       humidity_rh_tele_mean  1.712470  0.278731  0.477318  \n",
       "23  line_speed_u_min_tele_mean -2.655351  0.169922 -0.451201  \n",
       "24        humidity_rh_tele_max  2.133749 -0.171087 -0.365058  \n",
       "25              is_weekend_utc -0.631791 -0.496756  0.313846  \n",
       "26               line_id_S3-L1  1.000000  0.311943  0.311943  \n",
       "27                  site_id_S3  1.000000 -0.301494 -0.301494  \n",
       "28   line_speed_u_min_tele_max -2.849033 -0.097975  0.279134  \n",
       "29         asset_type_cartoner  1.000000  0.266095  0.266095  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 26 — Panel actionability under an alerts budget:\n",
    "#   Top-5 assets/day rollup (TEST) + “when” (peak hour) + “why” (top coefficient contributions)\n",
    "#   Auto-locate most recent run folder containing panel artifacts (after kernel restart)\n",
    "#============================================================\n",
    "\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Locate panel artifacts directory (prefer current OUT_DIR; else newest run folder with required files)\n",
    "# -----------------------------\n",
    "REQUIRED = [\n",
    "    \"panel_X_test.npz\",\n",
    "    \"panel_y_test.npy\",\n",
    "    \"panel_ids_test.parquet\",\n",
    "    \"panel_feature_names.csv\",\n",
    "    \"panel_baseline_logreg_saga.joblib\",\n",
    "]\n",
    "\n",
    "def has_panel_artifacts(d: Path) -> bool:\n",
    "    return all((d / f).exists() for f in REQUIRED)\n",
    "\n",
    "def find_latest_run_with_panel_artifacts(run_root: Path) -> Path:\n",
    "    if not run_root.exists():\n",
    "        raise FileNotFoundError(f\"Run root not found: {run_root}\")\n",
    "\n",
    "    # Candidate run folders (timestamp-ish), newest-first\n",
    "    candidates = []\n",
    "    for p in run_root.iterdir():\n",
    "        if p.is_dir():\n",
    "            candidates.append(p)\n",
    "\n",
    "    # Sort by name descending (timestamp folder naming like 20251216T225318Z makes lex-sort work)\n",
    "    candidates = sorted(candidates, key=lambda x: x.name, reverse=True)\n",
    "\n",
    "    for d in candidates:\n",
    "        if has_panel_artifacts(d):\n",
    "            return d\n",
    "\n",
    "    # If none found, raise a helpful error\n",
    "    existing = [d.name for d in candidates[:20]]\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find a run folder containing required panel artifacts.\\n\"\n",
    "        f\"Looked under: {run_root}\\n\"\n",
    "        f\"Required files: {REQUIRED}\\n\"\n",
    "        f\"Most recent folders checked (up to 20): {existing}\"\n",
    "    )\n",
    "\n",
    "# Decide PANEL_DIR\n",
    "RUN_ROOT = OUT_DIR.parent  # .../data/processed/feature_engineering\n",
    "if has_panel_artifacts(OUT_DIR):\n",
    "    PANEL_DIR = OUT_DIR\n",
    "else:\n",
    "    PANEL_DIR = find_latest_run_with_panel_artifacts(RUN_ROOT)\n",
    "\n",
    "print(\"Panel artifacts directory selected:\", PANEL_DIR)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Paths + loads (from PANEL_DIR)\n",
    "# -----------------------------\n",
    "X_test_path   = PANEL_DIR / \"panel_X_test.npz\"\n",
    "y_test_path   = PANEL_DIR / \"panel_y_test.npy\"\n",
    "ids_test_path = PANEL_DIR / \"panel_ids_test.parquet\"\n",
    "feat_path     = PANEL_DIR / \"panel_feature_names.csv\"\n",
    "model_path    = PANEL_DIR / \"panel_baseline_logreg_saga.joblib\"\n",
    "\n",
    "# Load artifacts\n",
    "X_test_tx = sp.load_npz(X_test_path)\n",
    "y_test = np.load(y_test_path).astype(int)\n",
    "ids_test = pd.read_parquet(ids_test_path).copy()\n",
    "clf = joblib.load(model_path)\n",
    "\n",
    "# Ensure CSR sparse\n",
    "if not sp.issparse(X_test_tx):\n",
    "    X_test_tx = sp.csr_matrix(X_test_tx)\n",
    "else:\n",
    "    X_test_tx = X_test_tx.tocsr()\n",
    "\n",
    "# Basic sanity checks\n",
    "if X_test_tx.shape[0] != len(y_test):\n",
    "    raise ValueError(f\"Row mismatch: X_test rows={X_test_tx.shape[0]} vs y_test len={len(y_test)}\")\n",
    "if len(ids_test) != len(y_test):\n",
    "    raise ValueError(f\"Row mismatch: ids_test rows={len(ids_test)} vs y_test len={len(y_test)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Feature names loader (robust to CSV schema)\n",
    "# -----------------------------\n",
    "feat_df = pd.read_csv(feat_path)\n",
    "\n",
    "if \"feature\" in feat_df.columns:\n",
    "    feature_names = feat_df[\"feature\"].astype(str).tolist()\n",
    "elif \"feature_name\" in feat_df.columns:\n",
    "    feature_names = feat_df[\"feature_name\"].astype(str).tolist()\n",
    "elif len(feat_df.columns) == 1:\n",
    "    feature_names = feat_df.iloc[:, 0].astype(str).tolist()\n",
    "else:\n",
    "    feature_names = feat_df.iloc[:, 0].astype(str).tolist()\n",
    "\n",
    "# Sanity check dimensions\n",
    "n_X = X_test_tx.shape[1]\n",
    "n_feat = len(feature_names)\n",
    "n_model = getattr(clf, \"n_features_in_\", None)\n",
    "\n",
    "if n_feat != n_X:\n",
    "    raise ValueError(\n",
    "        \"Feature name count does not match X_test feature dimension.\\n\"\n",
    "        f\"  X_test n_features   : {n_X}\\n\"\n",
    "        f\"  feature_names count : {n_feat}\\n\"\n",
    "        f\"  feature_names file  : {feat_path}\\n\"\n",
    "    )\n",
    "if (n_model is not None) and (n_model != n_X):\n",
    "    raise ValueError(\n",
    "        \"Model expects a different feature dimension than X_test.\\n\"\n",
    "        f\"  X_test n_features : {n_X}\\n\"\n",
    "        f\"  model expects     : {n_model}\\n\"\n",
    "        f\"  model file        : {model_path}\\n\"\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Ensure timestamp column exists + is tz-aware UTC\n",
    "# -----------------------------\n",
    "if \"asset_id\" not in ids_test.columns:\n",
    "    raise KeyError(f\"Expected 'asset_id' in ids_test. Columns: {ids_test.columns.tolist()}\")\n",
    "\n",
    "ts_col = None\n",
    "for c in [\"ts_hour_utc\", \"ts_hour\", \"timestamp_utc\", \"ts_utc\"]:\n",
    "    if c in ids_test.columns:\n",
    "        ts_col = c\n",
    "        break\n",
    "if ts_col is None:\n",
    "    raise KeyError(f\"Could not find a timestamp column in ids_test. Columns: {ids_test.columns.tolist()}\")\n",
    "\n",
    "ids_test[ts_col] = pd.to_datetime(ids_test[ts_col], utc=True, errors=\"coerce\")\n",
    "if ids_test[ts_col].isna().any():\n",
    "    bad = ids_test[ids_test[ts_col].isna()].head(5)\n",
    "    raise ValueError(f\"{ts_col} has NaT after parsing; sample bad rows:\\n{bad}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Score all TEST rows\n",
    "# -----------------------------\n",
    "proba = clf.predict_proba(X_test_tx)[:, 1]\n",
    "\n",
    "scores = ids_test.copy()\n",
    "scores[\"y_true\"] = y_test\n",
    "scores[\"p_hat\"] = proba\n",
    "\n",
    "# Date bucket (UTC)\n",
    "scores[\"date_utc\"] = scores[ts_col].dt.date\n",
    "\n",
    "print(\"\\nLoaded (from PANEL_DIR):\")\n",
    "print(f\"  X_test_tx : {X_test_tx.shape} | sparse: {sp.issparse(X_test_tx)}\")\n",
    "print(f\"  y_test    : {y_test.shape}\")\n",
    "print(f\"  ids_test  : {ids_test.shape}\")\n",
    "print(f\"  features  : {len(feature_names)}\")\n",
    "print(\"\\nTest-set snapshot:\")\n",
    "print(f\"  Positive rate (hour-level): {scores['y_true'].mean():.6f}\")\n",
    "print(f\"  Unique assets: {scores['asset_id'].nunique()}\")\n",
    "print(f\"  Date range (UTC): {scores[ts_col].min()} → {scores[ts_col].max()}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Enforce budget: Top-5 assets/day (by max p_hat over hours)\n",
    "#    Also compute \"when\": ts_peak (hour with max p_hat) per asset-day\n",
    "# -----------------------------\n",
    "scores = scores.reset_index(drop=True)\n",
    "scores[\"row_ix\"] = np.arange(len(scores), dtype=int)\n",
    "\n",
    "g_keys = [\"date_utc\", \"asset_id\"]\n",
    "\n",
    "# For each asset-day, pick the peak hour row (max p_hat)\n",
    "asset_day = (\n",
    "    scores.sort_values(\"p_hat\", ascending=False)\n",
    "          .groupby(g_keys, as_index=False)\n",
    "          .first()  # sorted desc → first row = peak hour\n",
    "          .rename(columns={ts_col: \"ts_peak\"})\n",
    ")\n",
    "\n",
    "# Asset-day truth label: did the asset have ANY positive hour that day?\n",
    "asset_day_y = (\n",
    "    scores.groupby(g_keys)[\"y_true\"]\n",
    "          .max()\n",
    "          .reset_index()\n",
    "          .rename(columns={\"y_true\": \"y_asset_day\"})\n",
    ")\n",
    "\n",
    "asset_day = asset_day.merge(asset_day_y, on=g_keys, how=\"left\")\n",
    "\n",
    "# Select Top-K assets per day\n",
    "K = 5\n",
    "alerts = (\n",
    "    asset_day.sort_values([\"date_utc\", \"p_hat\"], ascending=[True, False])\n",
    "            .groupby(\"date_utc\", as_index=False)\n",
    "            .head(K)\n",
    "            .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "precision_at_k = alerts[\"y_asset_day\"].mean() if len(alerts) else np.nan\n",
    "alerts_per_day = alerts.groupby(\"date_utc\")[\"asset_id\"].nunique().mean() if len(alerts) else 0.0\n",
    "\n",
    "print(\"\\nBudget policy:\")\n",
    "print(f\"  K (assets/day)          : {K}\")\n",
    "print(f\"  Avg assets/day selected : {alerts_per_day:.2f}\")\n",
    "print(f\"  Precision@K (asset-day) : {precision_at_k:.3f}  (fraction of alerted asset-days with ≥1 positive hour)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6) “Why”: top coefficient contributions at the peak hour\n",
    "#    Logistic regression contribution: contrib_i = x_i * coef_i (transformed space)\n",
    "# -----------------------------\n",
    "coefs = clf.coef_.ravel()\n",
    "\n",
    "def top_contribs_for_row(row_ix: int, top_n: int = 10) -> pd.DataFrame:\n",
    "    row = X_test_tx.getrow(int(row_ix))  # 1 x n_features CSR\n",
    "    if row.nnz == 0:\n",
    "        return pd.DataFrame(columns=[\"feature\", \"x\", \"coef\", \"contrib\"])\n",
    "\n",
    "    idx = row.indices\n",
    "    x = row.data\n",
    "    c = coefs[idx]\n",
    "    contrib = x * c\n",
    "\n",
    "    dfc = pd.DataFrame({\n",
    "        \"feature\": [feature_names[i] for i in idx],\n",
    "        \"x\": x,\n",
    "        \"coef\": c,\n",
    "        \"contrib\": contrib,\n",
    "        \"abs_contrib\": np.abs(contrib),\n",
    "    }).sort_values(\"abs_contrib\", ascending=False)\n",
    "\n",
    "    return dfc.drop(columns=[\"abs_contrib\"]).head(top_n)\n",
    "\n",
    "drivers_long = []\n",
    "for _, r in alerts.iterrows():\n",
    "    row_ix = int(r[\"row_ix\"])\n",
    "    d = top_contribs_for_row(row_ix=row_ix, top_n=10).copy()\n",
    "\n",
    "    # Keep ts_peak tz-aware UTC\n",
    "    ts_peak = pd.to_datetime(r[\"ts_peak\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "    d.insert(0, \"date_utc\", r[\"date_utc\"])\n",
    "    d.insert(1, \"asset_id\", r[\"asset_id\"])\n",
    "    d.insert(2, \"ts_peak\", ts_peak)\n",
    "    d.insert(3, \"p_hat_peak\", float(r[\"p_hat\"]))\n",
    "    d.insert(4, \"y_asset_day\", int(r[\"y_asset_day\"]))\n",
    "    drivers_long.append(d)\n",
    "\n",
    "drivers_long_df = pd.concat(drivers_long, ignore_index=True) if drivers_long else pd.DataFrame()\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Save outputs (to CURRENT OUT_DIR so this run stays coherent)\n",
    "# -----------------------------\n",
    "alerts_out  = OUT_DIR / \"panel_alerts_top5_assets_per_day.csv\"\n",
    "drivers_out = OUT_DIR / \"panel_alerts_top5_assets_per_day_drivers_long.csv\"\n",
    "metrics_out = OUT_DIR / \"panel_precision_at_k_assets_per_day.json\"\n",
    "\n",
    "alerts.to_csv(alerts_out, index=False)\n",
    "print(\"\\nSaved:\", alerts_out)\n",
    "\n",
    "if not drivers_long_df.empty:\n",
    "    drivers_long_df.to_csv(drivers_out, index=False)\n",
    "    print(\"Saved:\", drivers_out)\n",
    "else:\n",
    "    print(\"No drivers were generated (empty alerts or empty rows).\")\n",
    "\n",
    "metrics_payload = {\n",
    "    \"policy\": \"top_k_assets_per_day\",\n",
    "    \"k\": int(K),\n",
    "    \"loaded_panel_dir\": str(PANEL_DIR),\n",
    "    \"written_out_dir\": str(OUT_DIR),\n",
    "    \"n_alert_rows\": int(len(alerts)),\n",
    "    \"n_days\": int(alerts[\"date_utc\"].nunique()) if len(alerts) else 0,\n",
    "    \"avg_assets_per_day\": float(alerts_per_day),\n",
    "    \"precision_at_k_asset_day\": float(precision_at_k) if precision_at_k == precision_at_k else None,\n",
    "    \"note\": \"precision@K computed on asset-day label: y_asset_day = max(y_true) over hours for that asset on that day (TEST only).\",\n",
    "}\n",
    "metrics_out.write_text(json.dumps(metrics_payload, indent=2))\n",
    "print(\"Saved:\", metrics_out)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Display quick views\n",
    "# -----------------------------\n",
    "print(\"\\nTop-5 assets/day (preview):\")\n",
    "display(alerts.head(20))\n",
    "\n",
    "if not drivers_long_df.empty:\n",
    "    print(\"\\nTop drivers (preview, long form):\")\n",
    "    display(drivers_long_df.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dba0736-c662-4f54-ba34-7c2c9ee0d7af",
   "metadata": {},
   "source": [
    "### What Cell 26 Just Did\n",
    "\n",
    "This cell turns the **panel (asset-hour) model** into an **actionable alerting workflow** under a strict **Top-5 assets/day** budget.\n",
    "\n",
    "- **Auto-finds the right panel artifacts after a kernel restart**\n",
    "  - Scans `data/processed/feature_engineering/` and selects the **most recent run folder** that contains the required panel artifacts (`panel_X_test.npz`, `panel_y_test.npy`, `panel_ids_test.parquet`, feature names, and the saved model).\n",
    "  - Prevents failures when `OUT_DIR` changes between runs.\n",
    "\n",
    "- **Loads TEST-set artifacts and scores every asset-hour**\n",
    "  - Loads `X_test` (sparse), `y_test`, `ids_test` (with `asset_id` + timestamp), feature names, and the trained Logistic Regression model.\n",
    "  - Computes predicted probabilities (**p_hat**) for each test hour.\n",
    "\n",
    "- **Enforces the alert budget: Top-5 assets/day**\n",
    "  - Buckets each row into a **UTC day**.\n",
    "  - For each **asset-day**, finds the **peak-risk hour** (max `p_hat`) and captures:\n",
    "    - `ts_peak` (when risk peaks)\n",
    "    - `p_hat` at the peak\n",
    "    - `row_ix` (row pointer back into `X_test`)\n",
    "  - Selects the **Top 5 assets per day** by peak `p_hat`.\n",
    "  - Computes **Precision@K (asset-day)** where `y_asset_day = max(y_true)` across hours for that asset on that day.\n",
    "\n",
    "- **Adds “why” for each alert (traceable drivers)**\n",
    "  - For each alert, pulls the peak-hour feature row and computes per-feature contribution:\n",
    "    - `contrib_i = x_i * coef_i` (transformed feature space)\n",
    "  - Produces a long-form table of top drivers so each alert has a clear **“why”**.\n",
    "\n",
    "- **Exports business-ready outputs**\n",
    "  - `panel_alerts_top5_assets_per_day.csv` — daily Top-5 alert list with “when/where/context”\n",
    "  - `panel_alerts_top5_assets_per_day_drivers_long.csv` — top coefficient contributions per alert (why)\n",
    "  - `panel_precision_at_k_assets_per_day.json` — budget policy + Precision@K summary (with provenance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdeeaa57-e97a-4a0e-aaa4-7200babef72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated: /home/parallels/projects/gmp-packaging-risk-analytics/data/processed/feature_engineering/20251220T211621Z/EXPORTS.json\n",
      "\n",
      "Added keys:\n",
      " - EVENT_MODEL_TABLE_TIMEWINDOWS\n",
      " - EVENT_PREPROCESS_TIMEWINDOWS\n",
      " - EVENT_BASELINE_METRICS_TIMEWINDOWS\n",
      " - EVENT_COEFFICIENTS_TIMEWINDOWS\n",
      " - THRESHOLD_TRADEOFFS_TIMEWINDOWS\n",
      " - SCORED_ASSET_RISK_TIMEWINDOWS\n",
      " - TOP_DRIVERS_TIMEWINDOWS\n",
      " - REPORT_SITE_SUMMARY\n",
      " - REPORT_LINE_SUMMARY\n",
      " - REPORT_TOP20_ASSETS\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Cell 27 — Notebook wrap-up: append “report exports” to EXPORTS.json\n",
    "#============================================================\n",
    "\n",
    "exports_path = OUT_DIR / \"EXPORTS.json\"\n",
    "exports = json.loads(Path(exports_path).read_text()) if exports_path.exists() else {}\n",
    "\n",
    "# Add report outputs + time-window artifacts\n",
    "exports_updates = {\n",
    "    \"EVENT_MODEL_TABLE_TIMEWINDOWS\": str((OUT_DIR / \"event_derived_model_table_timewindows.parquet\").resolve()),\n",
    "    \"EVENT_PREPROCESS_TIMEWINDOWS\": str((OUT_DIR / \"preprocess_event_timewindows.joblib\").resolve()),\n",
    "    \"EVENT_BASELINE_METRICS_TIMEWINDOWS\": str((OUT_DIR / \"baseline_logreg_event_timewindows_metrics.json\").resolve()),\n",
    "    \"EVENT_COEFFICIENTS_TIMEWINDOWS\": str((OUT_DIR / \"baseline_logreg_event_timewindows_coefficients.csv\").resolve()),\n",
    "    \"THRESHOLD_TRADEOFFS_TIMEWINDOWS\": str((OUT_DIR / \"threshold_tradeoffs_event_timewindows.csv\").resolve()),\n",
    "    \"SCORED_ASSET_RISK_TIMEWINDOWS\": str((OUT_DIR / \"asset_risk_scored_timewindows.csv\").resolve()),\n",
    "    \"TOP_DRIVERS_TIMEWINDOWS\": str((OUT_DIR / \"top_drivers_timewindows.csv\").resolve()),\n",
    "    \"REPORT_SITE_SUMMARY\": str((OUT_DIR / \"report_site_summary.csv\").resolve()),\n",
    "    \"REPORT_LINE_SUMMARY\": str((OUT_DIR / \"report_line_summary.csv\").resolve()),\n",
    "    \"REPORT_TOP20_ASSETS\": str((OUT_DIR / \"report_top20_assets.csv\").resolve()),\n",
    "}\n",
    "\n",
    "exports.update(exports_updates)\n",
    "\n",
    "with open(exports_path, \"w\") as f:\n",
    "    json.dump(exports, f, indent=2)\n",
    "\n",
    "print(\"Updated:\", exports_path)\n",
    "print(\"\\nAdded keys:\")\n",
    "for k in exports_updates:\n",
    "    print(\" -\", k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e7b39-f38d-4c56-b2ea-7880e3bc5882",
   "metadata": {},
   "source": [
    "### What Cell 27 Just Did\n",
    "\n",
    "This final wrap-up cell updates the notebook’s **export manifest** so downstream readers (or automation) can quickly find the key deliverables produced in this run.\n",
    "\n",
    "- **Loads or creates** `EXPORTS.json` in the current run output directory.\n",
    "- **Appends a “report exports” section** that enumerates the important, business-facing artifacts generated across the notebook (for example: scored tables, threshold/triage summaries, alert budget outputs, driver tables, and metrics snapshots).\n",
    "- **De-duplicates entries** so rerunning the notebook doesn’t create repeated items.\n",
    "- **Writes the updated manifest back to disk**, leaving a single, canonical index of what to look at and where it lives.\n",
    "\n",
    "**Saved artifact:** `EXPORTS.json` (updated with report-ready outputs for this run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f098f0f4-8acd-41f6-8311-981f99fbac62",
   "metadata": {},
   "source": [
    "## Notebook Summary — `02_feature_engineering_and_labels.ipynb`\n",
    "\n",
    "This notebook builds **model-ready feature tables and labels** from raw IoT event streams for GMP packaging assets, then runs **baseline models** and produces **actionable risk outputs** (scores, thresholds, and alert lists) with full artifact traceability.\n",
    "\n",
    "### Goals\n",
    "- Standardize and enrich raw IoT events (telemetry + incidents) with master data (assets/sites).\n",
    "- Create **forecastable labels** (future incidents) to avoid leakage-by-construction.\n",
    "- Produce two modeling views:\n",
    "  1) **Asset-level (time-split)**: early-window telemetry → late-window incident label  \n",
    "  2) **Panel (asset-hour)**: hourly telemetry features → “future incident within next H hours” label\n",
    "- Train baseline Logistic Regression models and export business-facing rollups:\n",
    "  - predicted risk tables\n",
    "  - threshold/triage summaries\n",
    "  - **alerts under a fixed budget** (Top 5 assets/day) with “when” + “why”\n",
    "\n",
    "### What’s Built\n",
    "**1) Clean events layer**\n",
    "- Parses/standardizes the IoT events schema and timestamps.\n",
    "- Adds local time fields and joins asset/site context.\n",
    "- Persists a normalized parquet for reproducible downstream steps.\n",
    "\n",
    "**2) Panel dataset (asset-hour forecasting)**\n",
    "- Aggregates telemetry into **asset-hour** features (counts + summary stats by metric).\n",
    "- Builds a **forward-looking label** (`target_future_incident`) indicating whether an incident occurs within the next horizon window.\n",
    "- Adds safe time features (hour-of-day / day-of-week + cyclic encodings).\n",
    "- Uses a **group split by `asset_id`** so an asset never appears in both train and test.\n",
    "\n",
    "**3) Asset-level time-split dataset (anti-leak baseline)**\n",
    "- EARLY telemetry window features per asset.\n",
    "- LATE window incident totals → future incident label (`target_event_future`).\n",
    "- Produces a compact 120-row asset table for a simple “predict future incidents” task.\n",
    "\n",
    "### Modeling & Evaluation (High-Level)\n",
    "- Baseline models use **LogisticRegression(saga)** with `class_weight='balanced'`.\n",
    "- The notebook explicitly detects and avoids label leakage:\n",
    "  - Demonstrates why “label-by-construction” targets can look artificially perfect.\n",
    "  - Replaces those with time-forward labels for a realistic signal test.\n",
    "- Panel model outputs include:\n",
    "  - ROC-AUC / PR-AUC metrics\n",
    "  - threshold curve and triage tables (FP/FN lists)\n",
    "  - per-row contributions for interpretability\n",
    "\n",
    "### Operational Output (Actionability)\n",
    "- Implements an alerting policy: **Top 5 assets/day** (TEST) ranked by max predicted probability over hours.\n",
    "- For each alerted asset-day, exports:\n",
    "  - **when**: `ts_peak` (hour of max risk)\n",
    "  - **why**: top coefficient-based contributions for that peak hour (transparent, traceable)\n",
    "\n",
    "### Key Saved Artifacts (Run Folder)\n",
    "Artifacts are written under the run-stamped output directory (e.g., `data/processed/feature_engineering/<RUN_ID>/`), including:\n",
    "- Panel dataset + columns:  \n",
    "  - `panel_asset_hour_future_incident.parquet`, `panel_feature_columns.json`\n",
    "- Split/preprocess artifacts:  \n",
    "  - `panel_preprocess.joblib`, `panel_feature_names.csv`, `panel_X_train.npz`, `panel_X_test.npz`, `panel_y_train.npy`, `panel_y_test.npy`, `panel_split_manifest.json`\n",
    "- Panel model outputs:  \n",
    "  - `panel_baseline_logreg_saga.joblib`, metrics JSON(s), threshold curve CSV, triage tables, scored tables\n",
    "- Budgeted alert outputs:  \n",
    "  - `panel_alerts_top5_assets_per_day.csv`  \n",
    "  - `panel_alerts_top5_assets_per_day_drivers_long.csv`  \n",
    "  - `panel_precision_at_k_assets_per_day.json`\n",
    "- Notebook summary and export index:  \n",
    "  - `RUN_SUMMARY.md`, `EXPORTS.json`\n",
    "\n",
    "### How to Read the Results\n",
    "- Start with `RUN_SUMMARY.md` for the concise run recap.\n",
    "- Use `panel_alerts_top5_assets_per_day.csv` for the daily action list.\n",
    "- Use `panel_alerts_top5_assets_per_day_drivers_long.csv` to explain *why* an alert fired at the peak hour.\n",
    "- Use triage tables (`panel_false_positives_*`, `panel_false_negatives_*`) to understand failure modes and improve policy.\n",
    "\n",
    "### Next Steps\n",
    "- Tune the operational policy using business constraints (e.g., alert budget already fixed at **Top 5 assets/day**):\n",
    "  - evaluate stability across days/sites/lines\n",
    "  - add suppress/hold-down logic (e.g., avoid alerting the same asset repeatedly unless risk rises)\n",
    "- Improve signal:\n",
    "  - richer temporal features (lags, deltas, rolling windows per metric)\n",
    "  - consider a non-linear baseline (tree-based model) while keeping the same leak-safe split rules\n",
    "- Define validation aligned to operations:\n",
    "  - precision@K per day, alerts/day, and downstream QA workload impact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23641bb4-5f7c-44a4-8b67-d8b280da8bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gmp-packaging-risk-analytics)",
   "language": "python",
   "name": "gmp-packaging-risk-analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
